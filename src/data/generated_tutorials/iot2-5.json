{
  "title": "5",
  "slug": "iot2-5",
  "description": "Module from iot2.pdf: 5",
  "tags": [
    "iot2",
    "Elite"
  ],
  "content": "# 5\n\n\nData Acquiring, Organising, \n\nProcessing and Analytics \n\nLearning Objectives \n\nLO 5.1 \nApply the data-acquiring and data-storage functions for IoT/M2M devices data and \nmessages \nLO 5.2 \nClassify ways of organising data \nLO 5.3 \nSummarise the transactions on stored data, functions for business processes and \nbusiness intelligence, and the concepts of IoT applications\u2014integration and services \narchitecture \nLO 5.4 \nIdentify the functions and usage of data analytics and data visualisations for IoT \napplications and business processes \nLO 5.5 \nExplain knowledge discovery, knowledge management and knowledge-management \nreference architecture \n\nRecall from Previous Chapters \n\nLessons for IoT/M2M architectural layers and functions learnt in previous chapters, are\u2014devices \ncommunicate, first over a local network or WPAN and then send the physical layer data to data- \nadaptation and gateway layer. The gateway connects to the Internet, and communicates the data \npackets. The packets communicate over the Internet through a set of routers. Application and \napplication-support layers use the acquired and collected data for IoT applications. Applications \ncan also control and monitor the functions of devices. The application messages, commands and \ndata communicates to devices through the gateway using the Internet. \n\n156 \nInternet of Things: Architecture and Design Principles \n\n5.1 \nINTRODUCTION \n\nHaving learnt about devices, device s- network data, messages and packet communication \nto the Internet, let us understand the functions required for applications, services and \nbusiness processes at application-support and application layers. These functions are \ndata acquiring, data storage, data transactions, analytics, results visualisations, IoT \napplications integration, services, processes, intelligence, knowledge discovery and \nknowledge management. \n\nLet us first discuss the following terms and their meanings used in IoT application \nlayers. \n\nApplication refers to application software or a collection of software components. An \napplication enables a user to perform a group of coordinated activities, functions and \ntasks. Streetlights control and monitoring is an example of an application. Software for \ntracking and inventory control are other examples of applications. Tracking applications \nuse tags and locations data of the RFIDs. \n\nAn application enables a user to withdraw cash using an Automatic Teller Machine \n(ATM). An umbrella sending warning messages for weather (Example 1.1), a waste \ncontainer management, health monitoring, traffic lights control, synchronisation and \nmonitoring are other examples of IoT applications. \n\nService denotes a mechanism, which enables the provisioning of access to one or more \ncapabilities. An interface for the service provides the access to capabilities. The access to \neach capability is consistent with constraints and policies, which a service-description \nspecifies. Examples of service capabilities are automotive maintenance service capabilities \nor service capabilities for the Automatic Chocolate Vending Machines (ACVMs) for timely \nfilling of chocolates into the machines. \n\nService consists of a set of related software components and their functionalities. The \nset is reused for one or more purposes. Usage of the set is consistent with the controls, \nconstraints and policies which are specified in the service description for each service. A \nservice also associates a Service Level Agreement (SLA). \n\nA service consists of a collection of self-contained, distinct and reusable components. It \nprovides logically grouped and encapsulated functionalities. Traffic lights synchronising \nservice, automobile maintenance service, devices location, detection and tracking service, \nhome security-breach detection and management service, waste containers substitution \nservice, and health-alerts service are the examples of IoT services. \n\nService Oriented Architecture (SOA) is a software architecture model, which consists of \nservices, messages, operations and processes. SOA components are distributed over a \nnetwork or the Internet in a high-level business entity. New business applications and \napplications integration architecture in an enterprise can be developed using an SOA. \n\nData Acquiring, Organising, Processing and Analytics \n157 \n\nMessage means a communicating entity or object. \n\nOperation means action or set of actions. For example, actions during a bank transaction. \n\nTransaction (trans + action) refers to two inter-related sets of operations or actions or \ninstructions. For example, a transaction may be access to sales data to select and get the \nannual sales in a specific year in return. One operation is access to sales data and other \nis annual sales in return. Another example of a transaction is a query transaction with a \nDatabase Management System (DBMS). \n\nQuery is a command for getting select values from a database which in return transfer \nthe answer to the query after its processing. A query example is command to ACVMs \ndatabase for providing sales data of ACVMs on Sundays near city gardens in a specific \nfestival period in a year. Another example is query to service center database for providing \nthe list of automobile components needing replacement that have completed expected \nservice-life in a specific vehicle. \n\nQuery Processing is a group of structured activities undertaken to get the results from a \ndata store as per the query. \n\nKey Value Pair (KVP) refers to a set of two linked entities, one is the key, which is a unique \nidentifier for a linked entity and the other is the value, which is either the entity that is \nidentified or a pointer to the location of that entity. A KVP example is birthday-date pair. \nKVP is birthday: July 17, 2000. Birthday is the key for a table and date July 17, 2000 is the \nvalue. KVP applications create the look-up tables, hash tables and the network or device \nconfiguration files. \n\nHash Table (also called hash map) refers to a data structure which maps the KVPs and is \nused to implement an associative array (for example array of KVPs). A hash table may use \nan index (key) which is computed using a hash function and key maps to the value. Index \nis used to get or point to the desired value. \n\nBigtable maps two arbitrary string values into an associated arbitrary byte array. One is \nused as row key and the other as column key. Time stamp associates in three-dimensional \nmapping. Mapping is unlike a relational database but can be considered as a sparse, \ndistributed multi-dimensional sorted map. The table can scale up to 100s to 1000s of \ndistributed computing nodes with ease of adding more nodes. \n\nBusiness Transaction (BT) in database theory, refers to a (business) process that requests \ninformation from or that changes the data in a database .One operation in a BT is a command \n\u2018connect\u2019 that connects a DBMS and database, which in turn also connects with the DBMS. \nSimilarly, BTs are processes using commands \u2018insert\u2019, \u2018delete\u2019, \u2018append\u2019, and \u2018modify\u2019. \n\nProcess means a composition of a group of structured activities or tasks that lead to a \nparticular goal (or that interact to achieve a result). For example, streetlights control \n\n158 \nInternet of Things: Architecture and Design Principles \n\nprocess of the purchase process for an airline ticket. A process specifies activities with \nrelevance rules based on data in the process. \n\nProcess Matrix is a multi-element entity, each element of which relates a set of data or \ninputs to an activity (or subset of activities). \n\nBusiness Process (BP) is an activity or series of activities or a collection of inter-related \nstructured activities, tasks or processes. A BP serves a particular goal or specific result or \nservice or product. The BP is a representation or process matrix or flowchart of a sequence \nof activities with interleaving decision points; interleaving means putting in between. \nDecision point means an instance in a series of activities when decisions are taken for \nfurther activities. \n\nA web 1 definition states, \u201ca BP is a specific event in a chain of structured business \nactivities that typically change the state of data and/or a product and generate some type \nof output\u201d. Examples of BPs include finding the annual sales growth and managing the \nsupplies. Another definition 2 of BP is that \u201cbusiness process is an activity or set of activities \nthat will accomplish a specific organizational goal\u201d. One more definition 3 of BP states, \u201cBP \nis a series of logically related activities or tasks (such as planning, production, or sales) \nperformed together to produce a defined set of results.\u201d \n\nBusiness Intelligence (BI) is a process which enables a business service to extract new facts \nand knowledge, and then undertake better decisions. These new facts and knowledge \nfollow from earlier results of data processing, aggregation and analysis of these results. \n\nExample 5.1 clarifies the meanings of application, service, SOA, BP and BI for an Internet \nconnected chain of ACVMs to enable the understanding of what these terms do mean. \n\nExample 5.1 \n\nProblem \nAssume a connected chain of ACVMs spread all over a city. Each ACVM delivers chocolate at each instance \nas per the user\u2019s choice among one of the 5 flavours, viz. FL1, FL2, FL3, FL4 and FL5. A chosen chocolate \ndelivers on insertion of coins of appropriate amount as per the cost. A display unit displays user interfaces \nand takes part in user interaction when a child wishes to buy and get the chocolate of her/his choice. The \nACVM also displays advertisements for chocolates, news, weather reports and events in the city whenever \nnot in use. Each ACVM connects to the Internet for its management and services. What do application, \nservice, SOA, business process and business intelligence mean in the Internet of ACVMs? \n\nSolution \n\nApplication refers to software that provides for the management of ACVMs. When a new ACVM installs, then \nthe Manager updates the database of machine IDs. The manager programs the ACVMs for the services and \nalso does the diagnosis of each ACVM at regular intervals. This helps in locating the improper functioning \n\n1 http://www.webopedia.com/TERM/B/business_process.html \n2 http://searchcio.techtarget.com/definition/business-process \n3 http://www.businessdictionary.com/definition/business-process.html \n\nData Acquiring, Organising, Processing and Analytics \n159 \n\nACVMs. When the Manager finds a specific ACVM faulty, he/she initiates the required steps. For example, \nsending SMS to owner; informing the ACVM maintenance service which sends a mechanic; informing the \nchocolate-filling service, and so on. \nService refers to software, which initiates filling of the ACVMs with chocolates of distinct flavours. Each \nservice has a service description for usage by a Manager application. Service includes a Service Level \nAgreement (SLA) with the Manager. Service initiates actions on message from the Manager. For example, \nManager periodically delivers the messages for events and alerts for the sell up to the specified threshold \nlevels at each ACVM for each flavour. This enables service to optimally plan the filling of the ACVMs. \n\nACVMs manager can deploy number of services, like collection of coins service. Each service has the \nservice description (desc) and SLA. Service software distinguishes itself from an application due to its \nusages , not only specific to one application but can also be to many applications. A service selection uses \ndesc and enters into an SLA between the service and application. \n\nSOA is architecture models all the ACVM services, their interactions and the initiation of each service on \na distinct message from an application, service or process to another. SOA describes the services, other \ncomponents, their interactions, the sequences of messages, operations and processes. \n\nProcess refers to series of activities such as acquiring data from the ACVMs for the counts of each flavour \nsold during programmed intervals, analysing the acquired data, initiating messages for Fill service for each \nflavour through Fill process. Another series of activities such as acquiring data for the amount collected at \neach of the ACVMs at programmed intervals, analysing the acquired data; and initiating Collect service for \neach flavour through Collect process. \n\nBusiness process refers to series of related processes, such as Fill, Collect and Display at appropriate intervals \nis a business process in ACVMs chain. \nBusiness intelligence is a process which enables the ACVM business service to extract new facts and \nknowledge. This enables the undertaking of better decisions for new option(s) to maximise profits. For \nexample, dropping or reduced loading of the ACVMs with specific flavour(s) in select regions or introducing \nnew alternative flavours or advertising for the flavours getting less favour from the children, or relocating \nACVMs in specific areas or adopting enterprise strategy for intimacy with children such as free chocolate on \nbirthdays or awarding loyalty points. \n\nNew facts and knowledge follows from the earlier acquired results of data processing and aggregation, and \nthe region-wise, segmentation-wise, flavour-wise, week-wise and festival-wise sales analytics. \n\nRefer Oracle\u2019s IoT architecture framework (Figure 1.5). IoT devices connect through \nthe Internet. The data acquires, organises, processes and is analysed for the applications, \nservices, enterprise applications, BPs and BI. The connectivity to the Internet of IoT/ \nM2M devices, such as sensors, streetlights, ATMs, RFIDs and automobiles, is for various \napplications and services. IoT/M2M applications, services and business processes use the \nmessages and data packets received from the devices over the Internet. \n\nFollowing sections describe the data acquiring, organising, analytics, visualisations \nfor IoT applications, services, business processes and knowledge discovery and \nmanagement. \n\n\n![Image](/src/assets/generated_images/iot2_p186_i0.png)\n160 \nInternet of Things: Architecture and Design Principles \n\n5.2 \nDATA ACQUIRING AND STORAGE \n\nFollowing subsections describe devices data , and steps in \nacquiring and storing data for an application, service or \nbusiness process. \n\n5.2.1 Data Generation \n\nData generates at devices that later on , transfers to the Internet through a gateway. Data \ngenerates as follows: \n\n\u25cf Passive devices data : Data generate at the device or system, following the result of \ninteractions. A passive device does not have its own power source. An external source \nhelps such a device to generate and send data. Examples are an RFID (Example 2.2) \nor an ATM debit card (Example 2.3). The device may or may not have an associated \nmicrocontroller, memory and transceiver. A contactless card is an example of the \nformer and a label or barcode is the example of the latter. \n\n\u25cf Active devices data : Data generates at the device or system or following the result of \ninteractions. An active device has its own power source. Examples are active RFID, \nstreetlight sensor (Example 1.2) or wireless sensor node. An active device also has an \nassociated microcontroller, memory and transceiver. \n\n\u25cf Event data : A device can generate data on an event only once. For example, on detection \nof the traffic or on dark ambient conditions, which signals the event. The event on \ndarkness communicates a need for lighting up a group of streetlights (Example 1.2). A \nsystem consisting of security cameras can generate data on an event of security breach \nor on detection of an intrusion. A waste container with associate circuit can generate \ndata in the event of getting it filled up 90% or above. The components and devices in \nan automobile generate data of their performance and functioning. For example, on \nwearing out of a brake lining, a play in steering wheel and reduced air-conditioning \nis felt. The data communicates to the Internet. The communication takes place as and \nwhen the automobile reaches near a Wi-Fi access point. \n\n\u25cf Device real-time data : An ATM generates data and communicates it to the server \ninstantaneously through the Internet. This initiates and enables Online Transactions \nProcessing (OLTP) in real time. \n\n\u25cf Event-driven device data : A device data can generate on an event only once. Examples \nare: (i) a device receives command from Controller or Monitor, and then performs \naction(s) using an actuator. When the action completes, then the device sends an \nacknowledgement; (ii) When an application seeks the status of a device, then the \ndevice communicates the status. \n\n5.2.2 Data Acquisition \n\nData acquisition means acquiring data from IoT or M2M devices. The data communicates \nafter the interactions with a data acquisition system (application). The application interacts \n\nApply the \ndata-acquiring \nand data-storage \nfunctions for IoT/M2M \n\ndevices data and \n\nmessages \n\nLO 5.1 \n\nData Acquiring, Organising, Processing and Analytics \n161 \n\nand communicates with a number of devices for acquiring the needed data. The devices \nsend data on demand or at programmed intervals. Data of devices communicate using the \nnetwork, transport and security layers (Figure 2.1). \n\nAn application can configure the devices for the data when \ndevices have configuration capability. For example, the system can \nconfigure devices to send data at defined periodic intervals. Each \ndevice configuration controls the frequency of data generation. \nFor example, system can configure an umbrella device to acquire weather data from the \nInternet weather service, once each working day in a week (Example 1.1). An ACVM can \nbe configured to communicate the sales data of machine and other information, every \nhour. The ACVM system can be configured to communicate instantaneously in event of \nfault or in case requirement of a specific chocolate flavour needs the Fill service (Example \n5.1). \n\nApplication can configure sending of data after filtering or enriching at the gateway \nat the data-adaptation layer. The gateway in-between application and the devices can \nprovision for one or more of the following functions\u2014transcoding, data management and \ndevice management. Data management may be provisioning of the privacy and security, \nand data integration, compaction and fusion (Section 2.3). \n\nDevice-management software provisions for device ID or address, activation, \nconfiguring (managing device parameters and settings), registering, deregistering, \nattaching, and detaching (Section 2.3.2). \n\nExample 5.2 gives the process of acquiring data from the embedded component devices \nin the automobiles for Automotive Components and Predictive Automotive Maintenance \nSystem (ACPAMS) application. \n\nExample 5.2 \n\nProblem \nInternet of ACPAMS application\u2014How does an ACPAMS application acquire data from the embedded devices \nin the automobile components in a car? \n\nSolution \n\nA number of components, such as engine control system, axle, steering system, brake linings, wipers, \nair conditioners, battery and shockers, need predictive maintenance. Each component embeds computing \nhardware, software and interface to a network in an automobile. Each embedded device in the automobile \ncommunicates to a central computing system using the Controller Area Network (CAN) bus. Consolidated \ndata then communicates thorough the Internet to the ACPAMS center (Example 5.2). \nAn application at the system, first manages each embedded device. This means it allots the device ID \n(address), activates, configures (manages device parameters and settings), registers, deregisters, attaches \nand detaches. System gateway software communicates to a service-centre application. \n\nThe gateway application in event of an automobile in the vicinity of the hotspot, communicates the acquired \ndata aggregated over preset required intervals for each embedded component device. The communication \nis through Wi-Fi (Section 2.2). As and when the automobile happens to be near a Wi-Fi hotspot, the device \ndata communicates to the application. \n\nApplications configure \n\nthe devices for \n\nacquiring data \n\n162 \nInternet of Things: Architecture and Design Principles \n\nThe acquired data stores in the databases at a data store (Section 5.2.6). The application uses analytics \nand advanced analytics at scheduled intervals. The analytics predicts the maintenance needs for each \nautomotive component after predefined intervals (Section 5.5). The application messages the automobile \ndashboard the needed preventive maintenances at regular intervals. \n\nSimilar to the above example, the industrial plants use applications for acquiring data \nfrom machines. Analytics of data enable necessary predictive or prescriptive maintenances \n(Section 5.5.1). \n\n5.2.3 Data Validation \n\nData acquired from the devices does not mean that data are \ncorrect, meaningful or consistent. Data consistency means within \nexpected range data or as per pattern or data not corrupted \nduring transmission. Therefore, data needs validation checks. Data validation software do \nthe validation checks on the acquired data. Validation software applies logic, rules and \nsemantic annotations. The applications or services depend on valid data. Then only the \nanalytics, predictions, prescriptions, diagnosis and decisions can be acceptable. \n\nLarge magnitude of data is acquired from a large number \nof devices, especially, from machines in industrial plants or \nembedded components data from large number of automobiles \nor health devices in ICUs or wireless sensor networks, and so on. \nValidation software, therefore, consumes significant resources. \nAn appropriate strategy needs to be adopted. For example, the \nadopted strategy may be filtering out the invalid data at the gateway or at device itself \nor controlling the frequency of acquiring or cyclically scheduling the set of devices in \nindustrial systems. Data enriches, aggregates, fuses or compacts at the adaptation layer. \n\n5.2.4 Data Categorisation for Storage \n\nServices, business processes and business intelligence use data. Valid, useful and relevant \ndata can be categorised into three categories for storage\u2014data alone, data as well as results \nof processing, only the results of data analytics are stored. Following are three cases for \nstorage: \n\n1. Data which needs to be repeatedly processed, referenced or audited in future, and \n\ntherefore, data alone needs to be stored. \n2. Data which needs processing only once, and the results are used at a later time using \n\nthe analytics, and both the data and results of processing and analytics are stored. \nAdvantages of this case are quick visualisation and reports generation without \nreprocessing. Also the data is available for reference or auditing in future. \n3. Online, real-time or streaming data need to be processed and the results of this \n\nprocessing and analysis need storage. \n\nData must be validated \n\nbefore storing \n\nData aggregation, \n\nadaptation and \nenrichment is done \nbefore communicating \n\nto the Internet \n\nData Acquiring, Organising, Processing and Analytics \n163 \n\nData from large number of devices and sources categorises into a fourth category called \nBig data. Data is stored in databases at a server or in a data warehouse or on a Cloud as \nBig data. \n\n5.2.5 Assembly Software for the Events \n\nA device can generate events. For example, a sensor can generate an event when \ntemperature reaches a preset value or falls below a threshold. A pressure sensor in a boiler \ngenerates an event when pressure exceeds a critical value which warrants attention. \n\nEach event can be assigned an ID. A logic value sets or resets for an event state. Logic 1 \nrefers to an event generated but not yet acted upon. Logic 0 refers to an event generated \nand acted upon or not yet generated. A software component in applications can assemble \nthe events (logic value, event ID and device ID) and can also add Date time stamp. Events \nfrom IoTs and logic-flows assemble using software. \n\n5.2.6 Data Store \n\nA data store is a data repository of a set of objects which integrate into the store. Features \nof data store are: \n\n\u25cf Objects in a data-store are modeled using Classes which are defined by the database \nschemas . \n\n\u25cf A data store is a general concept. It includes data repositories such as database, \nrelational database, flat file, spreadsheet, mail server, web server, directory services \nand VMware \n\n\u25cf A data store may be distributed over multiple nodes. Apache Cassandra is an example \nof distributed data store. \n\n\u25cf A data store may consist of multiple schemas or may consist of data in only one \nscheme. Example of only one scheme data store is a relational database. \nRepository in English means a group, which can be related upon to look for required \nthings, for special information or knowledge. For example, a repository of paintings of \nartists. A database is a repository of data which can be relied upon for reporting, analytics, \nprocess, knowledge discovery and intelligence. A flat file is another repository. \n\nFlat file means a file in which the records have no structural interrelationship \n(Section 5.3). Section 5.5.1 explains the spreadsheet concept. VMware uses data store to \nrefer to a file that stores a virtual machine. \n\n5.2.7 Data Centre Management \n\nA data centre is a facility which has multiple banks of computers, \nservers, large memory systems, high speed network and Internet \nconnectivity. The centre provides data security and protection \nusing advanced tools, full data backups along with data recovery, \nredundant data communication connections and full system power as well as electricity \nsupply backups. \n\nData centre is meant \nfor data storage, data \nsecurity and protection \n\n164 \nInternet of Things: Architecture and Design Principles \n\nLarge industrial units, banks, railways, airlines and units for whom data are the critical \ncomponents use the services of data centres. Data centres also possess a dust free, heating, \nventilation and air conditioning (HVAC), cooling, humidification and dehumidification \nequipment, pressurisation system with a physically highly secure environment. \n\nThe manager of data centre is responsible for all technical and IT issues, operations of \ncomputers and servers, data entries, data security, data quality control, network quality \ncontrol and the management of the services and applications used for data processing. \n\n5.2.8 \nServer Management \n\nServer management means managing services, setup and maintenance of systems of \nall types associated with the server. A server needs to serve around the clock. Server \nmanagement includes managing the following: \n\n\u25cf Short reaction times when the system or network is down \n\n\u25cf High security standards by routinely performing system maintenance and updation \n\n\u25cf Periodic system updates for state-of-the art setups \n\n\u25cf Optimised performance \n\n\u25cf Monitoring of all critical services, with SMS and email notifications \n\n\u25cf Security of systems and protection \n\n\u25cf Maintaining confidentiality and privacy of data \n\n\u25cf High degree of security and integrity and effective protection of data, files and \ndatabases at the organisation \n\n\u25cf Protection of customer data or enterprise internal documents by attackers which \nincludes spam mails, unauthorised use of the access to the server, viruses, malwares \nand worms \n\n\u25cf Strict documentation and audit of all activities. \n\n5.2.9 \nSpatial Storage \n\nConsider goods with RFID tags. When goods move from one place to another, the IDs of \ngoods as well as locations are needed in tracking or inventory control applications. Spatial \nstorage is storage as spatial database which is optimised to store and later on receives \nqueries from the applications. \n\nSuppose a digital map is required for parking slots in a city. Spatial data refers to \ndata which represents objects defined in a geometric space. Points, lines and polygons \nare common geometric objects which can be represented in spatial databases. Spatial \ndatabase can also represent database for 3D objects, topological coverage, linear networks, \ntriangular irregular networks and other complex structures. Additional functionality in \nspatial databases enables efficient processing. \n\nInternet communication by RFIDs, ATMs, vehicles, ambulances, traffic lights, \nstreetlights, waste containers are examples of where spatial database are used. \n\nData Acquiring, Organising, Processing and Analytics \n165 \n\nSpatial database functions optimally for spatial queries. A spatial database can perform \ntypical SQL queries, such as select statements and performs a wide variety of spatial \noperations. Spatial database has the following features: \n\n\u25cf Can perform geometry constructors. For example, creating new geometries \n\n\u25cf Can define a shape using the vertices (points or nodes) \n\n\u25cf Can perform observer functions using queries which replies specific spatial information \nsuch as location of the centre of a geometric object \n\n\u25cf Can perform spatial measurements which mean computing distance between \ngeometries, lengths of lines, areas of polygons and other parameters \n\n\u25cf Can change the existing features to new ones using spatial functions and can predicate \nspatial relationships between geometries using true or false type queries. \n\nReconfirm Your Understanding \n\n\u25cf Data generates from the active or passive devices. Data can generate on events at devices. Data can \nalso generate in real time. \n\n\u25cf An application interacts for data acquisition. It can configure the devices for data when devices have \nconfiguration capability. For example, the devices can be configured to send data at defined periodic \nintervals, on specific events or in real time. \n\n\u25cf Large magnitude of data acquired from a large number of devices, especially, from machines in \nindustrial plants or embedded components data from large number of automobiles or health devices \nin ICUs or wireless sensor networks. Acquired data of the devices needs validation that data are \ncorrect, meaningful or consistent, are within expected ranges or are as per expected patterns and \nhave not become corrupted during transmission. \n\n\u25cf Data storage systems store the data. Data is stored in databases at a server, cloud, warehouse or as \nbig data on the cloud. \n\n\u25cf Data store is a data repository of a set of objects, which integrate into the store. \n\n\u25cf Objects in a data store are modelled using Classes, which the database schemas define. \n\n\u25cf Data store includes database, relational database, flat file, spreadsheet, mail server, web server, \ndirectory services and VMware. Data store may be distributed over multiple nodes. \n\n\u25cf A data store may consist of multiple schemas or may consist of data in only one scheme, such as \nrelational database. \n\n\u25cf Data is stored on a server for short reaction times, optimised performance and high security. \n\n\u25cf A data centre stores data for data security and protection using the advanced tools, full data backups \nalong with data recovery, redundant data communication connections and full system power. Data \nstore requires data centre management or server management. \n\n\u25cf Spatial storage is storage through a spatial database which is optimised to store, enable querying \nof the data objects defined in a geometric space, and which is a database for 2D and 3D objects, \ntopological coverage, linear networks, triangular irregular networks or other complex structures. \n\n\n![Image](/src/assets/generated_images/iot2_p192_i0.png)\n166 \nInternet of Things: Architecture and Design Principles \n\nS elf-Assessment E xercise \n\n1. List the different types of data which is generated at the devices. \n2. What does data acquisition mean? What are the benefits of data acquisition by \n\nan application after data aggregation, compaction or fusion and enrichment \nof data takes place from a number of devices? \n3. What does data validation mean? When does a data acquisition application \n\nconsider data invalid? How can an application compensate for the missing or \ninvalid data? \n4. How does an application or service support software acquired data of \n\nindustrial plant machines? Show diagrammatically the in-between physical \ncum data-link, adaptation, network, transport layers. \n5. What do you mean by data store? What are the different schemas for a data \n\nstore? \n6. List the features of a data centre and the activities of a data centre manager. \n7. What does server management mean? \n8. What does spatial database mean? What are additional data fields that spatial \n\ndata possess? \n\n\u2605 \n\u2605\u2605 \n\n\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\u2605\u2605\u2605 \n\n5.3 \nORGANISING THE DATA \n\nData can be organised in a number of ways. For example, \nobjects, files, data store, database, relational database and \nobject oriented database. Following subsections describe \nthese ways of organising and querying methods. \n\n5.3.1 Databases \n\nRequired data values are organised as database(s) so that select values can be retrieved \nlater. \n\nDatabase \n\nOne popular method of organising data is a database, which is a collection of data. \nThis collection is organised into tables. A table provides a systematic way for access, \nmanagement and update. A single table file is called flat file database. Each record is listed \nin separate row, unrelated to each other. \n\nClassify ways \n\nof organising \n\ndata \n\nLO 5.2 \n\nNote: \n\u2605 Level 1 & Level 2 category \n\n\u2605\u2605 Level 3 & Level 4 category \n\n\u2605\u2605\u2605 Level 5 & Level 6 category \n\nData Acquiring, Organising, Processing and Analytics \n167 \n\nRelational Database \n\nA relational database is a collection of data into multiple tables which relate to each other \nthrough special fields, called keys (primary key, foreign key and unique key). Relational \ndatabases provide flexibility. Examples of relational database are MySQL, PostGreSQL, \nOracle database created using PL/SQL and Microsoft SQL server using T-SQL. \n\nObject Oriented Database (OODB) is a collection of objects, which save the objects in \nobjected oriented design. Examples are ConceptBase or Cache. Example 5.3 shows the \nadvantages of using relational databases. \n\nExample 5.3 \n\nProblem \nRecall Example 5.1. Show the advantages of relational databases taking the example of Internet of ACVMs. \n\nSolution \n\nA Manager application receives ACVMs information. It send requests to ACVMs for the chocolates sold, \nand number required. The request is sent each hour from Manager to Fill service. A Fill service executes \non receipt of the requests from ACVMs for chocolate requirement every hour. Application, service and \nprocess use the common relational database RDBACVM tables. Table 5.1 is for ACVMs information, and \npending service requests Num1, Num 2, Num2, Num 3 and Num 4 for the five flavours available at an ACVM. \nTable 5.2 is for ACVMs Fill Request Information, and Table 5.3 for chocolates Fill service actions (Tables 5.1 \nto 5.3). \n\nTable 5.1 \nRDBAVCM Table A\u2014ACVMs information \n\nMachine \n\nID \n\nRegion \nAddress \nInstallation \n\nDate \n\nMaintenance \n\nSchedule \n\nFill \nService \nAddress \n\nPending \nRequest \nNumber 1 \n\nPending \nRequest \nNumber 2 \n\nPending \nRequest \nNumber 3 \n\nPending \nRequest \nNumber 4 \n\nTable 5.2 \nRDBAVCM Table B\u2014ACVMs fill request information \n\nService \nRequest \nNumber \n\nMachine \n\nID \n\nRequest \n\nReceipt \nDateTime \n\nNumber \nFL1 Request \n\nNumber \n\nFL 2 \nRequest \n\nNumber \n\nFL 3 \nRequest \n\nNumber \n\nFL 4 \nRequest \n\nNumber \n\nFL5 \nRequest \n\nTable 5.3 \nRDBAVCM Table C\u2014ACVMs fill service actions \n\nService \nRequest \nNumber \n\nService \nDateTime \n\nNumber \nFL1 Sent \n\nNumber \n\nFL 2 \nSent \n\nNumber \n\nFL 3 \nSent \n\nNumber \n\nFL 4 \nSent \n\nNumber \n\nFL5 \nSent \n\n168 \nInternet of Things: Architecture and Design Principles \n\nCommon key fields between A, B and C are machine id or service request number. The relationships between \nfields of A, B and C are maintained by RDBMS. For example, when number of each flavour requested equals \nthe number sent to a machine after processing a service request, then corresponding Num in A becomes 0. \nAssume three flat-file databases maintained separately\u2014 A\u2019 for ACVMs information, B\u2019 for ACVMs Fill Service \nRequest Information and database and C\u2019 for Fill Service Process. Then every time a service request raises or \nservice request processes, corresponding fields of A\u2019, B\u2019 and C\u2019 in three flat file separate databases require \nupdate for maintenance of consistency of database in each application, service and process. Further, each \none needs all fields due to no system for the maintenance of the relationships between A\u2019 , B\u2019 and C\u2019 . \n\nDatabase Management System \n\nDatabase Management System (DBMS) is a software system, which contains a set of \nprograms specially designed for creation and management of data stored in a database. \nDatabase transactions can be performed on a database or relational database. \n\nAtomicity, Data Consistency, Data Isolation and Durability (ACID) Rules \n\nThe database transactions must maintain the atomicity, data consistency, data isolation \nand durability during transactions. Let us explain these rules using Example 5.3 as follows: \n\nAtomicity means a transaction must complete in full, treating it as indivisible. When a \nservice request completes, then the pending request field should also be made zero. \n\nConsistency means that data after the transactions should remain consistent. For example, \nsum of chocolates sent should equal the sums of sold and unsold chocolates for each \nflavour after the transactions on the database. \n\nIsolation means transactions between tables 5.1 and 5.2, 5.2 and 5.3 and 5.3 and 5.1 are \nisolated from each other. \n\nDurability means after completion of transactions, the previous transaction cannot be \nrecalled. Only a new transaction can affect any change. \n\nDistributed Database \n\nDistributed Database (DDB) is a collection of logically interrelated databases over a \ncomputer network. Distributed DBMS means a software system that manages a distributed \ndatabase. The features of a distributed database system are: \n\n\u25cf DDB is a collection of databases which are logically related to each other. \n\n\u25cf Cooperation exists between the databases in a transparent manner. Transparent means \nthat each user within the system may access all of the data within all of the databases \nas if they were a single database. \n\n\u25cf DDB should be \u2018location independent\u2019, which means the user is unaware of where \nthe data is located, and it is possible to move the data from one physical location to \nanother without affecting the user. 4 \n\n4 http://www.csee.umbc.edu/portal/help/oracle8/server.815/a67784/ds_ch1.htm \n\nData Acquiring, Organising, Processing and Analytics \n169 \n\nConsistency, Availability and Partition-Tolerance Theorem \n\nConsistency, Availability and Partition-Tolerance Theorem (CAP theorem) is a theorem for \ndistributed computing systems. The theorem states that it is impossible for a distributed \ncomputer system to simultaneously provide all three of the Consistency, Availability, \nPartition tolerance (CAP) guarantees. 5 This is due to the fact that a network failure can \noccur during communication among the distributed computing nodes. Partitioning of a \nnetwork therefore needs to be tolerated. Hence, at all times either there will be consistency \nor availability. \n\nConsistency means \u2018Every read receives the most recent write or an error\u2019. When a message \nor data is sought the network generally issues notification of time-out or read error. During \nan interval of a network failure, the notification may not reach the requesting node(s). \n\nAvailability means \u2018Every request receives a response, without guarantee that it contains \nthe most recent version of the information\u2019. Due to the interval of network failure, it may \nhappen that most recent version of message or data requested may not be available. \n\nPartition tolerance means \u2018The system continues to operate despite an arbitrary number \nof messages being dropped by the network between the nodes\u2019. During the interval of a \nnetwork failure, the network will have two separate set of networked nodes. Since failure \ncan always occur therefore, the partitioning needs to be tolerated. \n\n5.3.2 Query Processing \n\nQuery means an application seeking a specific data set from a database. For example, a \nquery at a relational database at bank server may be for the ATM transactions made in a \nmonth by a specific customer ID (Example 2.3). Other examples are: most-liked chocolate \nflavour in the city by children of age group 6 to 10 (Example 5.1); number of times a vehicle \nvisited at the ACPAMS center (Example 5.2) and service was rendered with satisfaction \nlevel of 5 out of 5. \n\nQuery Processing \n\nQuery processing means using a process and getting the results of the query made from \na database. The process should use a correct as well as efficient execution strategy. Five \nsteps in processing are: \n\n1. Parsing and translation: This step translates the query into an internal form, into \n\na relational algebraic expression and then a Parser, which checks the syntax and \nverifies the relations. \n2. Decomposition to complete the query process into micro-operations using the analysis \n\n(for the number of micro-operations required for the operations), conjunctive and \ndisjunctive normalisation and semantic analysis. \n3. Optimisation which means optimising the cost of processing. The cost means number \n\nof micro-operations generated in processing which is evaluated by calculating the \ncosts of the sets of equivalent expressions. \n\n5 https://en.wikipedia.org/wiki/CAP_theorem \n\n170 \nInternet of Things: Architecture and Design Principles \n\n4. Evaluation plan: A query-execution engine (software) takes a query-evaluation plan \n\nand executes that plan. \n5. Returning the results of the query. \n\nThe process can also be based on a heuristic approach, by performing the selection and \nprojection steps as early as possible and eliminating duplicate operations. \n\nDistributed Query Processing \n\nDistributed Query Processing means query processing operations in distributed databases \non the same system or networked systems. The distributed database system has the ability \nto access remote sites and transmit the queries to other systems. \n\n5.3.3 \nSQL \n\nSQL stands for Structured Query Language. It is a language for viewing or changing \n(update, insert or append or delete) databases. It is a language for data querying, updating, \ninserting, appending and deleting the databases. It is a language for data access control, \nschema creation and modifications. It is also a language for managing the RDBMS. \n\nSQL was originally based upon the tuple relational calculus and relational algebra. SQL \ncan embed within other languages using SQL modules, libraries and pre-compilers. SQL \nfeatures are as follows: \n\n\u25cf Create Schema is a structure that contains descriptions of objects created by a user (base \ntables, views, constraints). The user can describe and define the data for a database. \n\n\u25cf Create Catalog consists of a set of schemas that constitute the description of the database. \n\n\u25cf Use Data Definition Language (DDL) for the commands that depict a database, including \ncreating, altering and dropping tables and establishing constraints. The user can create \nand drop databases and tables, establish foreign keys, create view, stored procedure, \nfunctions in a database. \n\n\u25cf Use Data Manipulation Language (DML) for commands that maintain and query a \ndatabase. The user can manipulate (INSERT, UPDATE or SELECT the data and access \ndata in relational database management systems. \n\n\u25cf Use Data Control Language (DCL) for commands that control a database, including \nadministering privileges and committing data. The user can set (grant or add or \nrevoke) permissions on tables, procedures, and views. \n\n5.3.4 NOSQL \n\nNOSQL stands for No-SQL or Not Only SQL that does not integrate with applications \nthat are based on SQL. NOSQL is used in cloud data store. NOSQL may consist of the \nfollowing: \n\n\u25cf A class of non-relational data storage systems, flexible data models and multiple \nschemas \n\nData Acquiring, Organising, Processing and Analytics \n171 \n\n\u25cf Class consisting of uninterpreted key and value or \u2018the big hash table\u2019. For example in \n[Dynamo (Amazon S3)] \n\n\u25cf Class consisting of unordered keys and using the JSON. For example in PNUTS \n\n\u25cf Class consisting of ordered keys and semi-structured data storage systems. For \nexamples in the BigTable, Hbase and Cassandra (used in Facebook and Apache) \n\n\u25cf Class consisting of JSON (Section 2.3). For example in MongoDb 6 which is widely \nused for NOSQL) \n\n\u25cf Class consisting of name and value in the text. For example in CouchDB \n\n\u25cf May not require a fixed table schema \nNOSQL systems do not use the concept of joins (in distributed data storage systems). \nData written at one node replicates to multiple nodes, therefore identical and distributed \nsystem can be fault-tolerant, and can have partitioning tolerance. CAP theorem is \napplicable. The system offers relaxation in one or more of the ACID and CAP properties. \nOut of the three properties (consistency, availability and partitions), two are at least \npresent for an application. \n\n\u25cf Consistency means all copies have same value like in traditional DBs. \n\n\u25cf Availability means at least one copy available in case a partition becomes inactive or \nfails. For example, in web applications, the other copy in other partition is available. \n\n\u25cf Partition means parts which are active but may not cooperate as in distributed \ndatabases. \n\n5.3.5 \nExtract, Transform and Load \n\nExtract, Transform and Load or ETL is a system which enables the usage of databases \nused, especially the ones stored at a data warehouse. Extract means obtaining data from \nhomogeneous or heterogeneous data sources. Transform means transforming and storing \nthe data in an appropriate structure or format. Load means the structured data load in the \nfinal target database or data store or data warehouse. \n\nAll the three phases can execute in parallel. Data extraction takes longer time. Therefore, \nthe system while pulling data, executes another transformation processes on already \nreceived data and prepares the already transformed data for loading. As soon as data \nare ready for load into the target, the data load starts. It means next phase starts without \nwaiting for the completion of the previous phases. \n\nETL system usages are for integrating data from multiple applications (systems) hosted \nseparately. \n\n5.3.6 \nRelational Time Series Service \n\nTime series data means an array of numbers indexed with time (date-time or a range of \ndate-time). Time series data can be considered as time stamped data. It means data carries \nalong with it the date and time information about the data values. For example, sales of \nchocolates in Internet of ACVMs (Example 5.1) are different on different dates and times. \n\n6 http://www.w3resource.com/mongodb/introduction-mongodb.php MongoDb \n\n172 \nInternet of Things: Architecture and Design Principles \n\nThe sales need indexing with a range between two dates or indexed with date-time. A \ntime series of sales is called sale profile of the ACVMs. A time series of log of chocolate \nsales is called chocolate sales trace. \n\nTime series is any data-set that is accessed in a sequence of time. Software programs and \nan analytics program analyses the set in a time series, meaning analyses in a chronological \norder. IoT devices, such as temperature sensors, wireless sensor network nodes, energy \nmeters, RFID tags, ATMs, ACVMs generate time-stamped or time series data. \n\nTime Series Database (TSDB) is a software system which implements a database that \noptimally handles mathematical operations (profiles, traces, curves), queries or database \ntransactions on time series. \n\nConventional database systems, Relational Database System (RDMS) or flat file \ndatabase software may not be modelled for time series handling and may not therefore \nfunction efficiently for time series data with complex logic or business rules and need of \nhigh transaction throughout time series data. \n\nIBM Informix TimeSeries software expanded database functionality by adding \nefficient storage, faster load of data to enable fast query processing and transactions, fast \nperformance, sophisticated support for managing time series. Server can have built-in \ntime series Informix software for the handling of IoT time series data. \n\n5.3.7 \nReal-Time and Intelligence \n\nDecision on real-time data is fast when query processing in live data (streaming) has \nlow latency. Decision on historical data is fast when interactive query processing has low \nlatency. Low latencies are obtained by various approaches: Massively Parallel Processing \n(MPP), in-memory databases and columnar databases. \n\nTeraData Aster and Pivotal Greenplum are examples of MPP. In-memory and on-store \nboth transaction methods exist for the databases . SAP Hana and QClick view are examples \nof in-memory databases. SAP Sybase IQ and HP Vertica are examples for columnar \ndatabases for faster Analytics. \n\nReconfirm Your Understanding \n\n\u25cf A database is a collection of data which is organised as tables. A relational database is a collection \nof data organised as multiple tables, which relate to each other through special fields. Object \nOriented Database (OODB) is a collection of objects, which saves the objects in objected oriented \ndesign. \n\n\u25cf Database Management System is a software system, which contains a set of programs specially \ndesigned for creation, management and transactions of data stored in a database. \n\n\u25cf Database transaction is the execution of a specific set of operations on a database. Relational \ndatabase transaction is the execution of interrelated instructions using relations. A transaction is a \nsequential execution of a specific set of relational operations on relational database. \n\nData Acquiring, Organising, Processing and Analytics \n173 \n\n\u25cf Database transaction models state that transactions must maintain transaction atomicity, data \nconsistency, data isolation and durability. \n\n\u25cf Query means to an application or service seeking a specific data set from a database. Query processing \nmeans using a process and getting the results of the query made from a database. \n\n\u25cf CAP theorem applies to distributed computing nodes. CAP theorem states that for distributed \ncomputing systems, it is impossible for a distributed computer system to simultaneously provide all \nthree, consistency, availability, partition tolerance (CAP), guarantees. \n\n\u25cf Distributed database is a collection of logically interrelated, cooperating databases over a computer \nnetwork. A distributed database system has the ability to access remote sites and transmit queries. \n\n\u25cf Distributed query processing means query processing operations in distributed databases on same \nsystem or networked systems. \n\n\u25cf SQL is a language for data access control, schema creation and modifications. It is a language \nfor managing the RDBMs. It is a language for data definition, data manipulation and data control \ninstructions. \n\n\u25cf NOSQL stands for Not Only SQL or No-SQL and no integration with applications that are based on \nSQL. It is used in Cloud Data Store. NOSQL consists of classes of non-relational data storage systems, \nflexible data models and multiple schemas. \n\n\u25cf Time series data means an array of numbers indexed with time (date-time or a range of date-time). \n\n\u25cf Decision on real-time data is fast when query processing in live data (streaming) has low latency. \nThe decision on historical data is fast when interactive query processing has low latency. \n\nS elf-Assessment E xercise \n\n1. What does a relational database mean? \n2. List the differences between flat-file and relational databases. \n3. Consider relational database tables, A, B and C. Here is A bank information \n\n(name, address, phone numbers, IFSC code), B is customers\u2019 information \n(IDs, names, addresses, phone numbers, Account Types, Account Numbers) \nand C is Bank Passbook Transactions details (Date of Transaction, Credit, \ndebit, Debit amount, Credit amount and Balance). What will be the keys \nused? How does the data in the tables relate? C relates to which fields in A \nand B. \n4. What are three essential features when using distributed databases? \n5. What does TSDB mean? \n6. What are the features of SQL? \n7. How does SQL differ from NOSQL? \n8. List the differences between time-series database system and RDBMS in \n\nconstruction and usages. \n\n\u2605 \n\u2605\u2605 \n\u2605\u2605\u2605 \n\n\u2605 \n\u2605 \n\u2605 \n\u2605\u2605 \n\u2605\u2605\u2605 \n\n\n![Image](/src/assets/generated_images/iot2_p200_i0.png)\n174 \nInternet of Things: Architecture and Design Principles \n\n5.4  TRANSACTIONS, BUSINESS PROCESSES, \n\nINTEGRATION AND ENTERPRISE \nSYSTEMS \n\nA transaction is a collection of operations that form a single \nlogical unit. For example, a database connect, insertion, \nappend, deletion or modification transactions. Business \ntransactions are transactions related in some way to a business \nactivity. \n\n5.4.1 Online Transactions and Processing \n\nRecall Example 2.3\u2014OLTP means process as soon as data or events generate in real time. \nOLTP is used when requirements are availability, speed, concurrency and recoverability \nin databases for real-time data or events. Example 5.4 gives the uses of OLTP in the \napplication and network domain in Internet of ATMs (ATM of a bank) connected to a \nbank server. \n\nExample 5.4 \n\nProblem \nWhat are the usages of OLTP in the application and network domain in Internet of ATMs (ATM of a bank) \nconnected to a bank server? \n\nSolution \n\nServer applications need processing and update-intensive database management with a high throughput. \nThe requirements in these applications are availability, speed, concurrency and recoverability, and reduced \npaper trails. Therefore, the transactions at ATMs need OLTP. \n\nBatch Transactions Processing \n\nBatch transactions processing means the execution of a series of transactions without \nuser interactions. Transaction jobs are set up so they can be run to completion. Scripts, \ncommand-line arguments, control files, or job control language predefine all input \nparameters. \n\nBatch processing means a transaction process in batches and in an non-interactive way. \nWhen one set of transactions finish, the results are stored and a next batch is taken up. A \ngood example is credit card transactions where the final results at the end of the month \nare used. Another example is chocolate purchase transactions. The final results of sell \nfigures from ACVMs can communicate on the Internet at the end of an hour or day. \n\nSummarise the \ntransactions on \nstored data, functions \n\nfor business- \nprocesses and \nbusiness intelligence, \n\nand the concepts of \n\nIoT applications\u2014 \nintegration and services \n\narchitecture \n\nLO 5.3 \n\nData Acquiring, Organising, Processing and Analytics \n175 \n\nStreaming Transactions Processing \n\nExamples of the streams are log streams, event streams and twitter streams. Query and \ntransactions processing on streaming data need specialised frameworks. Storm from \nTwitter, S4 from Yahoo, SPARK streaming, HStreaming and flume are examples of \nframeworks for real-time streaming computation frameworks. \n\nInteractive Transactions Processing \n\nInteractive transactions processing means the transactions which involve continual \nexchange of information between the computer and a user. For example, user interactions \nduring e-shopping and e-banking. The processing is just the opposite of batch processing. \n\nReal-time Transactions Processing \n\nReal-time transaction processing means that transactions process at the same time \nas the data arrives from the data sources and data store. An example is ATM machine \ntransactions. In-memory, row-format records enable real-time transaction processing. \nRow format means few rows and more columns. The CPU accesses all columns in single \naccesses in SIMD (single instruction multiple data) streams processing. \n\nEvent Stream Processing and Complex Event Processing \n\nEvent Stream Processing (ESP) is a set of technologies, event processing languages, \nComplex Event Processing (CEP), event visualisation, event databases and event-driven \nmiddleware. Apache S4 and Twitter Storm are examples of ESPs. SAP Sybase ESP and \nEsperTechEsper are examples of CEPs. ESP and CEP does the following: \n\n\u25cf Processes tasks on receiving streams of event data \n\n\u25cf Identifies the meaningful pattern from the streams \n\n\u25cf Detects relationships between multiple events \n\n\u25cf Correlates the events data \n\n\u25cf Detects event hierarchies \n\n\u25cf Detects aspects such as timing, causality, subscription membership \n\n\u25cf Builds and manages the event-driven information systems. \n\nComplex Event Processing \n\nCEP has many applications. For example, IoT event processing applications, stocks \nalgorithmic-based trading and location-based services. A CEP application in Eclipse are \nused for capturing a combination of data, timing conditions and efficiently recognise the \ncorresponding events over data streams. \n\n5.4.2 \nBusiness Processes \n\nA business process consists of a series of activities which serves a particular specific \nresult. It is used when an enterprise has a number of interrelated processes which serve \n\n176 \nInternet of Things: Architecture and Design Principles \n\na particular result or goal. The results enable sales, planning and production. The BP is a \nrepresentation or process matrix or flowchart of a sequence of activities with interleaving \ndecision points. \n\nInternet of RFIDs enables a business process called tracking of RFID labelled goods \n(Example 2.2) which also enables inventory control process. \n\nIoT/M2M enables the devices\u2019 data in databases for business processes. The data \nsupports the process. For example, consider a process, streetlights control and management \n(Example 1.2). Each group of streetlights sends data in real time through the gateways. \nThe gateways connect to the Internet. The control and management processes streetlights \nreal time databases and group databases. \n\n5.4.3 \nBusiness Intelligence \n\nBusiness intelligence is a process which enables a business service to extract new facts \nand knowledge and then undertake better decisions. The new facts and knowledge follow \nfrom the earlier results of data processing, aggregation and then analysing those results. \nExample 5.5 shows business intelligence for Internet of ACVMs, whereas Example 5.6 \nshows business processes, intelligence and BP architecture reference model in Automotive \nMaintenance Application at the Service Centre. \n\nExample 5.5 \n\nProblem \nRecall Internet of ACVMs (Example 5.1). What are the new facts and knowledge that follow from the earlier \nresults of business processes? \n\nSolution \n\nConsider Fill service for the ACVMs. The BI extracts the knowledge about the required Fill service frequency \nfrom the facts. Also extract the strategy to service the filling of chocolates in ACVMs in specific areas of \nthe city such that all flavours can be simultaneously dispatched. BI lies in the service to the machines in \nthe area when cost incurred is minimum on one hand and each machine is able to serve on user demand \nany flavour without fail. \n\nExample 5.6 \n\nProblem \nRecall automotive maintenance application at a service centre (Example 5.2). Draw BI/BP architecture for \nautomobile components service process at ACPAMS. \n\nSolution \n\nThe predictive analytics of the acquired data in databases enables the service to extract the knowledge. \nIt gets the prediction of components needing service from the facts. The service to a set of automobile \ncomponents has to be timely and preventive. BI lies in the service to the automobile when components \nare serviced or replaced timely with least number of visits to the service centre. Figure 5.1 shows model \narchitecture for BI and BP at automobile service centre. \n\nData Acquiring, Organising, Processing and Analytics \n177 \n\nGateway and \nSources \nAcquiring Data \nLayers \n\nAdaptation and Enrichment \n\nIoT/M2M Data Sources \nAutomobile Components Layers \n\nOrganised \nData Store \nLayer \n\nBusiness \nAnalytics and \nIntelligence \nApplications \n\nApplications \nSupport for \nAnalytics \n\nAutomobile Specific Database and \nComponent Specific Historical Databases \nAutomobile Components Data Integration \n\nBusiness Intelligence \n\nData Access, SQL, Query Processing, \nR-Descriptive Statistics, Predictive Analytics \n\nService Centre Business Processes \n\nFigure 5.1 Architecture reference model for the business intelligence and business processes at \n\nACPAMS \n\n5.4.4 Distributed Business Process \n\nSeveral times, business processes need to be distributed. Distribution of processes reduces \nthe complexity, communication costs, enables faster responses and smaller processing \nload at the central system. For example, recall Example 1.2, distribution of control process \nfor each group of lights at the gateway itself reduces complexity, communication costs, \nfaster responses and smaller processing load at the central system. \n\nDistributed Business Process System (DBPS) is a collection of logically interrelated \nbusiness processes in an Enterprise network. DBPS means a software system that manages \nthe distributed BPs. DBPS features are: \n\nDBPS is a collection of logically related BPs like DDBS. DBPS exists as cooperation \nbetween the BPs in a transparent manner. Transparent means that each user within the \nsystem may access all of the process decisions within all of the processes as if they were a \nsingle business process. \n\nDBPS should possess \u2018location independence\u2019 which means the enterprise BI is unaware \nof where the BPs are located. It is possible to move the results of analytics and knowledge \nfrom one physical location to another without affecting the user. 1 \n\nExample 5.7 shows distributed business processes in an automobile enterprise. \n\n178 \nInternet of Things: Architecture and Design Principles \n\nExample 5.7 \n\nProblem \nRecall automotive maintenance application at an ACPAMS centre (Examples 5.2 and 5.6). Enterprise business \nintelligence lies in predictive and prescriptive analytics based services to the automobile components, \nwhich are serviced or replaced timely with minimum number of visits to service centres. Draw business \nintelligence and business processes architecture for automobile components service process. \n\nSolution \n\nFigure 5.2 shows model architecture for distributed BI and BP at an automobile enterprise. Two business \nprocesses are at enterprise layer, viz. one at network layer and one at devices and gateway layer. \n\nAdaptation, Data Integration and Enrichment \n\nIoT/M2M Data Sources \nAutomobile Components Device Layers \n\nAutomobile Enterprise \n\nBusiness Process 1 \n\nAnalytics \nAutomobile Specific \n\nDatabase \n\nBusiness Intelligence, Predictive Analytics \n\nAutomobiles Database \nBusiness \nProcess 3 \n\nNetwork Layer Data Access, SQL, \nQuery Processing, \nR-Descriptive Statistics, \nand Component Specific Historical Databases \nBusiness Process 2 \n\nAutomobile Components \n\nDevice and Gateway Layer Business Process 4 \n\nFigure 5.2 Distributed interrelated business intelligence and processes at the enterprise, network, and \n\ndevices and gateway layers \n\nInterrelationships in distributed BPs are: \n\n\u25cf Enterprise layer business process 1 (EBP1) interrelates directly with the device and gateway layer \nBusiness process 4 (DGBP4) thus with the device data, adaptation, data integration and enrichment \nlayer for a specific automobile. EBP1 analytics is with non-historical data. \n\n\u25cf Network layer Business Process 2 (NBP2) interrelates directly with the enterprise layer business process \n3 (EBP3). NBP2 uses the data access, SQL, query processing, R- descriptive statistics and component \nspecific historical databases. NBP 2 has access to data of number of automobiles of same the model \nas one sending data to EBP1. EBP3 analytics is with the other automobile databases and historical \ndatabases, and enables predictive and prescriptive analytics. \n\n\u25cf NBP2 interrelates directly with the DGBP4. This enables updating the database for the NBP2. \n\nData Acquiring, Organising, Processing and Analytics \n179 \n\n5.4.5 \nComplex Applications Integration and Service Oriented Architecture \n\nAn enterprise has number of applications, services and processes. Heterogeneous systems \nhave complexity when integrating them in the enterprise. \n\nFollowing are the standardised business processes, as defined in the Oracle application \nintegration architecture: \n\n\u25cf Integrating and enhancing the existing systems and processes \n\n\u25cf Business intelligence \n\n\u25cf Data security and integrity \n\n\u25cf New business services and products (web services) \n\n\u25cf Collaboration and knowledge management \n\n\u25cf Enterprise architecture and SOA \n\n\u25cf e-commerce \n\n\u25cf External customer services \n\n\u25cf Supply chain automation and analytics results visualisation \n\n\u25cf Data centre optimisation \nIoT applications, services and processes enhance the existing systems in a number of \nenterprises. For example, an automobile enterprise has a number of divisions. Each division \nhas Sales, Customer Relations Management, Automobile Maintenance Services, and \nAccounting. IoT-based services help in business intelligence, processes and systems, such \nas post-sales services and supply chain automation and analytics results in visualisation \nenhancement of the services from an enterprise. \n\nComplex application integration means integration of heterogeneous application \narchitectures and number of processes. SOA consists of services, messages, operations \nand processes. \n\nSOA components distribute over a network or the Internet in a high-level business \nentity. New business applications can be developed using a SOA. \n\n5.4.6 \nIntegration and Enterprise Systems \n\nFigure 5.3 shows complex applications integration architecture and SOA of cloud-based \nIoT services, web services, cloud services and services. \n\nProcess orchestration means a number of business processes running in parallel and a \nnumber of processes running in sequence. The process matrix provides the decision points \nwhich indicate which processes should run in parallel and which in sequence. An SOA \nmodels the number of services and interrelationships. Each service initiates on receipt of \nmessages from a process or service. \n\nThe service discovery and selection software components select the services for \napplication integration. Service orchestration software coordinates the execution of the \nnumber of services, cloud services, cloud IoT services and web services. Services run in \nparallel and a number of processes in sequences. \n\n180 \nInternet of Things: Architecture and Design Principles \n\nWeb Service \nWeb Service \n\nIoT Service \nService \n\nCloud of \nThings \n\nService A \nService B \n\nService Discovery, Selection and Orchestration \n\nCloud \n\nService C \nService D \n\nEnterprise \n\nBusiness Process \n\nDecision Points \nBusiness Process \n\nBusiness Processes Orchestration \n\nBusiness Process \n\nBusiness Process \nBusiness Process \n\nFigure 5.3 Complex applications integration architecture and SOA of cloud-based IoT services, web \n\nservices, cloud services and services \n\nReconfirm Your Understanding \n\n\u25cf A database transaction is a collection of operations that form a single logical unit of database. A \ntransaction means operations such as connect, insertion, append, deletion or modification in a unit \nof database. Business transactions are transactions related in some way to a business activity. \n\n\u25cf OLTP stands for Online Transactions Processing, refers to processing of data or events in real time. \nBatch transaction processing means transaction processing in batches and in a non-interactive \nway. Stream transactions processing on streaming data need specialised frameworks. Real-time \ntransaction processing means that transaction processing is done at the same time as the data \narrives from the data sources and data stores. \n\n\u25cf Complex event processing application uses are for capturing a combination of data, timing conditions \nand efficiently recognising the corresponding events over data streams. \n\n\u25cf A business process consists of a series of activities. The process may consist of a collection of \ninterrelated structured activities or tasks or processes which follow a logical sequence. \n\n\u25cf A process matrix has a number of elements. Each element may represent a series of operations and \nactivities on a given set of inputs that perform a specific task leading to a decision point in the \nprocess. \n\n\n![Image](/src/assets/generated_images/iot2_p207_i0.png)\nData Acquiring, Organising, Processing and Analytics \n181 \n\n\u25cf Business intelligence is a process that enables a business service to extract new facts and knowledge \nand then undertake better decisions. The new facts and knowledge follow from the earlier results of \ndata processing, aggregation and then analysing those results. \n\n\u25cf Distribution of processes reduces complexity, communication costs, and enables faster responses \nand smaller processing load at the central system. \n\n\u25cf Distributed business process system (DBPS) is a collection of logically interrelated business processes \nin an enterprise network. \n\n\u25cf Complex application integration means integration of heterogeneous application architectures and \nnumber of processes. \n\n\u25cf SOA consists of enterprise and service discovery, selection and orchestration layers for services, \nmessages, operations and processes. \n\nS elf-Assessment E xercise \n\n1. What do batch transactions, streaming transactions and real-time transactions \n\nprocessing mean? \n2. List the tasks which event stream processing and complex stream processing \n\ndo. \n3. What does a process matrix mean? \n4. List the steps in tracking a business process in Internet of RFIDs. Draw \n\ndiagrammatically the actions at physical cum data-link, data adaptation, \nnetwork, transport, application-support and application layers. \n5. What is the benefit of device and gateway layer business process in distributed \n\nbusiness processes in automobile enterprise? \n6. List the standardised business processes in the Oracle application integration \n\narchitecture. \n7. Why does OLTP operation run fast in row format? \n8. Draw waste container management business intelligence and business \n\nprocesses architecture for Internet of Waste containers. Assume that each \ncontainer generates an event on getting 90% filled up and communicates the \nevent along with the container ID. \n\n\u2605\u2605 \n\n\u2605 \n\n\u2605 \n\u2605\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\u2605\u2605\u2605 \n\n5.5 \nANALYTICS \n\nOrganised data after acquiring from the devices can be \nused for multiple purposes. Applications usually use the \ndata of devices in two ways\u2014for monitoring, reporting and \nrule-based actions. For example, in Internet of Streetlights \napplications just do that (Example 1.2); for analytics, new \n\nIdentify the \nfunctions and \nusage of data analytics \nand data visualisations \nfor IoT applications and \n\nbusiness processes \n\nLO 5.4 \n\n182 \nInternet of Things: Architecture and Design Principles \n\nfacts and taking decisions based on those facts. For example, Internet of ACVMs can \nuse analytics, new facts are found and those facts enable taking of the decisions for new \noption(s) to maximise the profits from the machines (Example 5.1). \n\nExample 5.8 gives the uses of analytics in the application and network domain in \nInternet of ATMs (ATM of a bank) connected to a bank server. \n\nExample 5.8 \n\nProblem \nWhat are the usages of analytics in the application and network domain in Internet of ATMs connected to \na bank server? \n\nSolution \n\nAn ATM machine generates income from transaction charges, charges for advertisements at the machine \nlocations and idle-state advertisements of bank products and bank services at the display screen. Each \nmachine\u2019s usage is analysed during each hour on a daily basis in each segment. Each machine\u2019s expenses \nand incomes are used for cost-benefit analysis. Analytics enable faster and more accurate scheduling. \nIt enables timely actions, enables optimum scheduling region wise for the cash supply service, special \nscheduling on special days, such as days near dates of receiving salary, festivals and holidays. The analytics \nalso enable each region machines the maintenance, scheduling and ATM location relocation. \n\nAn enterprise creates sections and unit-wise analytics. The analytics enable fact-based \ndecision making in place of intuition-drive decision making. Analytics provides business \nintelligence. It is a key for the success of an enterprise business. \n\nAnalytics require the data to be available and accessible. It uses arithmetic and statistical, \ndata mining and advanced methods, such as machine learning to find new parameters and \ninformation  which add value to the data. Analytics enable building models based on \nselection of right data. Later the models are tested and used for services and processes. \n\n5.5.1 Analytics Phases \n\nAnalytics has three phases before deriving new facts and providing business intelligence. \nThese are: \n\n1. Descriptive analytics enables deriving the additional value from visualisations and \n\nreports. \n2. Predictive analytics is advanced analytics which enables extraction of new facts and \n\nknowledge, and then predicts or forecasts. \n3. Prescriptive analytics enables derivation of the additional value and undertake better \n\ndecisions for new option(s) to maximise the profits. \n\nDescriptive Analytics \n\nDescriptive analytics answers the questions about what happened in the past. Descriptive \nanalytics means finding the aggregates, frequencies of occurrences, mean values (simple \n\nData Acquiring, Organising, Processing and Analytics \n183 \n\nor geometric averages) or variances in values or groupings using selected properties and \nhence applying these. Descriptive analytics enable the following: \n\n\u25cf Actions, such as Online Analytical Processing (OLAP) for the analytics \n\n\u25cf Reporting or generating spreadsheets \n\n\u25cf Visualisations or dashboard displays of the analysed results \n\n\u25cf Creation of indicators, called key performance indicators. \n\nDescriptive Analytics Methods \n\n\u25cf Spreadsheet-based reports and data visualisations: R esults of descriptive analysis \ncan be presented in a spreadsheet format before creating the data visuals for the user. \nSpreadsheet enables user visualisation of what if . For example, if sales of chocolates \nof specific flavour drop by 5% on specific set of ACVMs, how it will influence the \nprofitability? A spreadsheet is a table. The values are in the cells in the rows and \ncolumns. Each value can have a predefined relationship to the other values. For \nexample, a value in cell C j R i (cell at j th column and i th row) can be related to another \ncell or a set of cells through a formula or Boolean relation or statistically analysed \nvalue. \n\n\u25cf Descriptive statistics-based reports and data visualisations: Descriptive analysis \ncan also use descriptive statistics. Statistical analysis means finding peak, minima, \nvariance, probabilities, and statistical parameters. Formulae are used for the data sets \nto enable the data showing variations understandable. \n\n\u25cf Data mining and machine learning methods in analytics: Data mining analysis means \nuse of algorithms which extract hidden or unknown information or patterns from \nlarge amounts of data. Machine learning means modelling of the specific tasks. \n\nR is a programming language and software environment \nfor statistical computing and graphics. The language is also the core of many open \nsource products. Descriptive analytics enable intelligence for further actions. \n\nExample 5.9 \n\nProblem \n\na.  Recapitulate Examples 5.1, 5.3 and 5.5. How are the descriptive analytics used in Internet of ACVMs? \nb. How is the spreadsheet method used in Internet of ACVMs? \n\nSolution \n\na. Descriptive analytics looks at past performance and the performance is evaluated by mining historical \n\ndata. The analytics find the reasons behind past performance or success or failure. Reports for \nmanagement use this type of analysis. For example, report the analysis of the sales in individual areas, \nsales on individual occasions, analysing children preferences, analysing flavour preferences, expenses \nand incomes from individual regions, incomes from various sources, chocolate sales, advertisements \nduring idle state displays at the machines, or chocolate sales on the machines, and so on. \nb. Recall Example 5.3. Spreadsheet design is as follows: A cell in a row is for an ACVM id and another \n\nfor the period under consideration. Five other cells are for the numbers sold during the period for the \n\n184 \nInternet of Things: Architecture and Design Principles \n\nflavours FL1 and FL5. A predefined formula calculates the profitability from the values in the cells and \nvalues of the purchase and sell-prices for each flavour, FL1 and FL5. If a value given in one of the five \ncell changes then new profitability figure automatically calculates using the predefined formulae in \neach row and the summing row. The spreadsheet analytics can be graphically visualised. \n\n\u25cf Online analytical processing (OLAP) in analytics: OLAP enables viewing of analysed \ndata up to the desired granularity. It enables view of rollup (finer granulites data to \ncoarse granulites data) or drill down (coarser granulites data to finer granulites data). \nOLAP enables obtaining summarized information and automated reports from large \nvolume database. Results of queries are based on Metadata. Metadata is data which \ndescribes the data. Pre-storing calculated values provide consistently fast response. \n\nOLAP uses the analysis functions which are not possible to code in SQL. The data \nstructure is designed from the users perspective, using Spreadsheet like formulae. \n\nOLAP is a significant improvement over query systems. OLAP is an interactive \nsystem to show different summaries of multidimensional data by interactively \nselecting the attributes in a multidimensional data cube. 7 \n\nOLAP enables analysing data in multiple dimensions in a structure called data cube. \nEach dimension represents a hierarchy. Each dimension has a dimension attribute \nwhich defines the dimension and summary of measure attribute. \n\nA slice of a data-cube can be viewed when values of multiple dimensions are fixed. \nA dice of a data-cube can be viewed with variable values in multiple dimensions. Slicing \nand dicing functionalities mean selecting specific values for these attributes, which are \nthen displayed on top of the cross-tables. \n\nA slice means a data relationship in the analysed multiple dimensional data. A slice \nof a data relationship between two attributes can be individually visualised. For \nexamples, monthly sales versus flavours sold at the chain of ACVMs in Example 5.1 \nafter the analysis. \n\nA cubical dice has six faces, each face marked distinctly. \nFace 1 has one dot, face 2 two, and so on. Sixth face has six \ndots. Similarly, six different cross referenced tables can be \ncreated during OLAP for three-dimensional structure for \nanalysing data. An n-dimensional structure will have 2- n \nfaces (tables). Each table and corresponding visual gives a \nrelationship between two attributes. The tables are cross referenced. \nOLAP can be one of the three types: multidimensional OLAP (MOLAP), relational \nOLAP (ROLAP) and hybrid OLAP (HOLAP). \n\nExample 5.10 explains multidimensional data-cube analytics. \n\n7 https://en.wikipedia.org/wiki/Online_analytical_processing \n\nDicing is a process \n\nof creating cross \nreferenced tables, each \n\nviewable separately on \nn-dimensional structure \n\nfaces. \n\nData Acquiring, Organising, Processing and Analytics \n185 \n\nExample 5.10 \n\nProblem \nHow are the OLAP used for analytics in Internet of ACVMs (Example 5.1)? \n\nSolution \n\nConsider Internet of ACVMs (Example 5.1). First dimension can be for time intervals, varying in hierarchy from \nhour, day, week, month and year. Second dimension can be number of installed machines with hierarchically \naggregated values from 10s, 50s, 100s, and so on. The third dimension can be number of chocolates sold, \nwith hierarchically aggregated values, 100s, 1000s, 10000s, and so on. Fourth dimension can be number \nof individual chocolate flavours sold, 50s, 100s, 150s, 200s and so on of a specific flavour. Similarly, fifth, \nsixth and other dimensions can be specified for other flavours. \nOLAP uses the following steps: \nIdentify the dimensions, each with an attribute and hierarchy. For example, identifying dimensions: \n1 number of time intervals, 2 number of installed machines, 3 total number of chocolates of all five flavours \nsold. \nAnalyse cross tabulations (Row header with one attribute, column header with another attribute and cell \nhaving the aggregate value or calculated value according to a formula or analysis). For example, table of \nnumber of chocolates sold and time intervals as well as table of number of chocolate sold and number of \nmachines. \nVisualise n -dimensional cube-data; cube means integration of fact table with cross-dimensional tables, \nvisualising the slices and dice faces. \nWhen visualising analysed results, first take a whole, then region wise and then individual ACVMs means \ndrilling down views (from coarse granularity of analysis to finer granularity analysis). Next when visualising \nanalysed results, first consider flavour wise and then as a whole means rolling up views (from finer granularity \nof analysis to coarser granularity analysis). \n\nAdvanced Analytics: Predictive Analytics \n\nPredictive analytics answer the question \u201dWhat will happen?\u201d \nPredictive analytics is advanced analytics. The user interprets \nthe outputs from advanced analytics using descriptive analytics \nmethods, such as data visualisation. For example, output \npredictions are visualised along with the yearly sales growth \nof past five years and predicts next two years sales. Another \nexample, output predictions for the next cycle of automobile sells are visualised along \nyearly cycles of sales growth and fall in past ten years. Visualising can show the effects \nto increased competition for a product in years ahead and take decisions, such as need to \nchange product mix and introducing new car models. \n\nPredictive analytics uses algorithms, such as regression analysis, correlation, \noptimisation, and multivariate statistics, and techniques such as modelling, simulation, \nmachine learning, and neural networks. The software tools make the predictive analytics \neasy to use and understand. The examples are as follows: \n\n\u25cf Predicting trends \n\n\u25cf Undertaking preventive maintenance from earlier models of equipment and device \nfailure rates \n\nPredictive analytics is \n\nadvanced analytics \n\nin which the user \ninterprets the outputs of \n\ndescriptive analytics \n\n186 \nInternet of Things: Architecture and Design Principles \n\n\u25cf Managing the campaign with integrated marketing strategy from previous studies of \neffect of campaigns with respect to media types, regions, targeted age group \n\n\u25cf Predicting by identifying patterns, clusters with similar behaviour \n\n\u25cf Predicting based on anomalous characteristics, anomaly detection \nThe results of predictions need verifications from a domain knowledge, and view from \nmultiple angles. \n\nPrescriptive Analytics \n\nPrescriptive analytics answers not only what is anticipated or what will happen or when \nit will happen, but also why it will happen based on the input from descriptive analytics \nand business rules. This final phase, additionally to the prediction also suggests actions \nfor deriving benefits from predictions, and shows the implications of the decision options \nor the optimal solutions or new resource allocation strategies or risk mitigation strategies. \nPrescriptive analytics suggest best course of actions in the given state or set of inputs and \nrules. \n\n5.5.2 \nEvent Analytics \n\nEvents definable options are unique, non-interaction or interaction options for the events. \nEvent analytics use event data for events tracking and event reporting. An event has the \nfollowing components: \n\n\u25cf Category \u2013an event of chocolate purchase in ACVM example belongs to one category \nand event of reaching predefined threshold of sell for specific chocolate flavour which \nbelongs to other category \n\n\u25cf Action \u2013sending message from ACVM on completing predefined sell is the action taken \non the event \n\n\u25cf Label (optional) \n\n\u25cf Value (optional)\u2013on event, messaging the number of chocolate of that flavour sold or \nremaining . \nEvent analytics generate event reports using event metric, such as event counts for a \ncategory of events, events acted upon, event pending action, rate of new events generation \nin that category. \n\n5.5.3 \nIn-memory Data Processing and Analytics \n\nIn-memory option of row or column formats can be selected in certain databases, for \nexample, Oracle dual format architecture database that enables to run the real-time, ad- \nhoc, analytic queries on IoTs\u2019 data. \n\nIn-memory and On-store Row Format Option (Few Rows and Many Columns) \n\nConsider the transactions of the type, ATM transactions or sales order transactions. Each \nrow has separate record. For example, separate record for each ACVM or each bank \ncustomer or each sales order. The columns have data associated with the record. A row \n\nData Acquiring, Organising, Processing and Analytics \n187 \n\nformat enables quick access of all columns for a record. OLTP operations run fast in the \nrow format. There are fewer rows and more columns. For example, updates, inserting \nnew transactions or querying the transactions of specific amount. A row format can be \noptimized for OLTP operations. The operations access only few rows and need quick \naccess to the columns. \n\nA row format, allowing row data, will be brought into the CPU with a single memory \nreference. Data for each record is together in-memory and on-store. There is a single copy \nof the table on storage. Recall Example 5.1 for Internet of ACVMs. For example, required \nchocolates of each flavour for distinct ACVMs in row format in-memory database enable \nfaster querying. \n\nIn-memory and On-store Column Format Option (Few Columns and More Rows) \n\nConsider analytics of the type, monthly sales of chocolates on the ACVMs, enterprise \nyearly profits. Analytical workloads access few columns but scan the entire data set. \nAnalytics therefore run faster on column format, more rows and few columns. Fast for \nprocessing needs few columns and many rows. They typically require aggregation or \nfusion or compaction also. A columnar format allows for much faster data retrieval when \nonly a few columns in a table are selected because all the data for a column is kept together \nin-memory in column format option. A single memory access will load many column \nvalues into the CPU. It also lends itself to faster filtering and aggregation, making it the \nmost optimised format for analytics. \n\n5.5.4 \nReal-time Analytics Management \n\nReal-time analytics management means ensuring faster OLTP as well as OLAP. Real-time \nanalytics works both as direct querying using an OLTP database and in a data warehouse \nand OLAP on queried results. Queries return fast, databases such as Oracle database \nprovides in-memory row format option large speedups for OLTP applications and in- \nmemory column format option for large speedups for OLAP applications. \n\nExample 5.11 \n\nProblem \nGive example of dual format in-memory architecture of databases. \n\nSolution \n\nIn-memory option of row or column formats can be selected in certain databases. For example, Oracle dual \nformat architecture databases for in-memory columnar as well as row formats. \nOracle\u2019s unique dual format architecture allows data to be stored in both row and column format \nsimultaneously. The Oracle database in-memory option is designed to be completely compatible with \nand transparent to the existing Oracle applications and is trivial to deploy. This eliminates the trade-offs \nrequired in those databases which offer only one format option, format for faster access during OLTP or \nfaster access during analytics. Such databases needs generation of second copy for analytics, thus delaying \ncosts, additional storage costs and synchronisation issues. \n\n188 \nInternet of Things: Architecture and Design Principles \n\nThe Oracle optimiser is in-memory aware. It has been optimized to automatically run analytic queries using \nthe column format, and OLTP queries using the row format. Oracle\u2019s in-memory columnar technology is a \npure in-memory format. The in-memory columnar format does not persist on storage. \n\n5.5.5 Analytics using Big Data in IoT/M2M \n\nBig data means extreme amount of data. Big data also means data \nof high volume, variety and velocity (3Vs) or one which also \nincludes veracity (4Vs). \n\nVolume means data received from number of sources of data, \nincluding data sets with sizes beyond the ability of commonly \nused software tools to acquire, manage and process data within a tolerable elapsed time. \n\nVariety means structured as well as unstructured data in different formats, variety of \ndata on which no SQL (Structured Query Language) applicable. \n\nVelocity means data received with higher rates due to use of number of sources of data. \nVeracity means variation in data quality for analytics. The analytics need the trustable \ndata, filtered data after removing\u2014anomalous data, non-standard and not cross \nreferencing data. \n\nBig data also refers simply to the use of predictive analytics or other certain advanced \nmethods which extract the value from data. Big data seldom relates to just a particular size \nof data set. Extreme amount of data means data with additional information\u2014situational \ninformation. For example, information from analysis of data of time period, festival days, \nholidays, and data of different locations, and contextual information, which means data \ngathered in specific contexts. \n\n5.5.6 \nBig Data Analytics \n\nBig data is multistructured data while RDMS maintain more structured data. The open \nsource software Hadoop and MapReduce are from Apache Software. They enable storage \nand analyse the massive amounts of data. Hadoop File System (HDFS), Mahout, a library \nof machine learning algorithms and HiveQ, a SQL like scripting language software are \nused for Big data analytics in the Hadoop ecosystem. MapReduce is a programming model \nand a core of Hadoop. Large data sets process onto a cluster of nodes using MapReduce. \nSame node runs the algorithm using the data sets at HDFS and processing is at that node \nitself. \n\nHadoop is an open-source framework. The framework stores and processes big data. \nThe clusters of computing nodes process that data using simple programming models. \nProcessing takes place in a distributed environment. The framework scales up from single \nserver to thousands of processing machines and servers, each offering environment of local \nstorage and processing. Hadoop accesses data in sequential manner and performs batch \nprocessing. A new data set results from input data set that also processes sequentially. \n\nBig data is data of high \n\nvolume, variety and \nvelocity, and may also \n\ninclude veracity \n\nData Acquiring, Organising, Processing and Analytics \n189 \n\nHBase is an example of columnar format data storage which enables read or write \naccess in real time for very large tables distributed in Hadoop File System (HDFS). HBase \nis database for big data. Data access is random access. Therefore, it provides fast look-up \nfrom large tables and access latency is small. HBase uses big hash tables. HBase can be \nconsidered similar to Google\u2019s BigTable. \n\n5.5.7 Data Analytics Architecture and Stack \n\nAnalytics architecture consists of the following layers: \n\n\u25cf Data sources layer \n\n\u25cf Data storage and processing layer \n\n\u25cf Data access and query processing layer \n\n\u25cf Data services, reporting and advanced analytics layer \nFigure 5.4 shows an overview of a reference model for analytics architecture. Figure 5.4 \nalso shows on the right-hand side the layers in the reference model. \n\nSources \nAcquiring \nData \nIoT/M2M Data Sources \n\nEnterprise Data Sources \n\nExternal Data Sources \n\nOrganised \nData Store \nLayer \n\nAnalytics \nApplications \n\nAnalytics \nApplications \nSupport \n\nTraditional DataStore/Data Warehouse \n\nEvent Stream Processing \nComplex Event Processing \n\nServices, Reporting, Data Visualisations, OLAP, \nAdvance Analytics (Predictive/Prescriptive Analytics) \n\nData Access, SQL, Query Processing, OLTP, ETL, \n\nR-Descriptive Statistics, In-Memory or On-Store \n\nDatabase Processing, MapReduce and Others \n\nApplications Support Layer \n\nFigure 5.4 \nAnalytics Architecture Reference Model \n\nAnalytical sandbox means analytics tools and analytics environment for predictive \nanalytics on multistructured data. Mesos v0.9 is a resources management platform which \nenable multiple frameworks sharing of cluster of nodes and which is compatible with \nopen analytics stack [data processing (Hive, Hadoop, HBase, Storm), data management \n(HDFS)]. \n\n190 \nInternet of Things: Architecture and Design Principles \n\nBerkeley Data Analytics Stack (BDAS) consists of data processing, data management \nand resource management layers. \n\nApplications, AMP-Genomics and Carat run at the BDAS. Data processing software \ncomponent provides in-memory processing which processes the data efficiently across the \nframeworks. AMP stands for Berkeley\u2019s Algorithms, Machines and Peoples Laboratory. \n\nData processing combines batch , streaming and interactive computations. \nResource management software component provides for sharing the infrastructure \nacross the frameworks. \n\nFigure 5. 5 shows an overview of BDAS architecture which is a reference model for \nanalytics architecture. Figure 5.5 also shows on right-hand side the file system, library of \nmachine learning algorithms and SQL like scripting language software for the Big data \nanalytics in Hadoop ecosystem. \n\nSources \nAcquiring Data \nIoT/M2M Data Sources \n\nEnterprise Data Sources \n\nExternal Data Sources \n\nOrganised \nData Store \nLayer \n\nBusiness \nAnalytics and \nIntelligence \nApplications \n\nAnalytics \nApplications \nSupport \n\nTraditional DataStore/Data Warehouse \n\nEvent Stream Processing \nComplex Event Processing \n\nServices, Reporting, Data Visualisations, OLAP, \nAdvance Analytics (Predictive/Prescriptive Analytics) \n\nData Access, SQL, Query Processing, OLTP, ETL, \n\nR-Descriptive Statistics, In-Memory or On-Store \n\nDatabase Processing, MapReduce and Others \n\nApplications Support Layer \n\nHDFS \n(Hadoop File \nSystem) for \nBig Data \n\nMahout \nDistributed and \nScalable Library of \nMachine Learning \nAlgorithms \n\nHiveQL \n(SQL like \nScripting \nLanguage) \n\nFigure 5.5 \nBerkeley data analytics stack architecture \n\nReconfirm Your Understanding \n\n\u25cf Organised data in database or data store is used for analytics, new facts and decision taking on \nthose facts. Analytics has three phases before deriving new facts and provide business intelligence \u2014 \ndescriptive, predictive and prescriptive analytics. \n\nData Acquiring, Organising, Processing and Analytics \n191 \n\n\u25cf Analytics uses statistical methods to find new parameters, which add value to the data. Analytics \nenable building models based on selection of right data. Later the models are tested and used for \nservices and processes. \n\n\u25cf Analytics architecture consists of the following layers\u2014data sources, data storage and processing, \ndata access and query processing and data services, reporting and advanced analytics layer. \n\n\u25cf Descriptive analytics, statistics, data mining and machine learning are analytics tools. Analytics \nenable the actions, reporting and generating spreadsheet, data visualisations and KPIs. \n\n\u25cf Descriptive analytics looks at past performance. The performance is evaluated from mining the \nhistorical data. \n\n\u25cf OLAP uses following steps\u2014identify the dimensions, each with an attribute and hierarchy, analyse \ncross tabulations. \n\n\u25cf OLAP runs faster on column format, more rows and few columns. OLTP runs faster on row format: \nfew rows and more columns. Dual in-memory formats provide advantage of faster real-time query \nprocessing as well as analytics. \n\n\u25cf OLAP enables viewing of analysed data up to desired granularity, viewing slices and cross-referenced \ntables, each viewable separately on n -dimensional structure faces using dicing functions. \n\n\u25cf Predictive analytics answer the question, \u201dWhat will happen?\u201d Predictive analytics is advanced \nanalytics. The user interprets the outputs from advanced analytics using descriptive analytics \nmethods, such as data visualisation. \n\n\u25cf Prescriptive analytics answers not only what is anticipated or what will happen or when it will \nhappen, but also why it will happen based on the input from descriptive analytics and business \nrules. \n\n\u25cf Event analytics use event data, for events tracking and event reporting. Event analytics generate \nevent reports using event metric (event counts, events acted up on, event pending action, rate of \nnew events generation) in each category of events. \n\n\u25cf Analytics architecture consists of the following layers: Data Sources, Data Storage and Processing, \nData Access and Query Processing, Data Services, Reporting and Advanced Analytics Layers. \n\n\u25cf Berkeley Data Analytics Stack consists of data processing, data management and resource management \nlayers. \n\nS elf-Assessment E xercise \n\n1. List the uses of analytics. \n2. Explain spreadsheet-based reports and data visualisation with example of a \n\ndaily sales database for ACVMs. \n3. List the advantages of descriptive analytics of ACVMs data. \n4. What does OLAP mean? \n5. List the usages of slicing and dicing functionalities at automobile service \n\ncentre in Internet of automotive components. \n6. How do predictive and prescriptive analytics differ? \n7. Why do OLTP operations run faster in row format in-memory database? Why \n\ndo OLAP operations run faster in column format in-memory database? \n\n\u2605 \n\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605 \n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\u2605\u2605 \n\n\n![Image](/src/assets/generated_images/iot2_p218_i0.png)\n192 \nInternet of Things: Architecture and Design Principles \n\n8. What is big data? \n9. How does big data analytics differ from structured RDMS analytics? \n10. How are the analytics architecture layers used in automobile service centre \n\nfor Internet of automotive components? \n11. Explain Berkeley Data Analytics Stack layer software components. \n12. How does analytics lead to business intelligence? \n\n\u2605 \n\u2605 \n\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\n5.6  KNOWLEDGE ACQUIRING, MANAGING \n\nAND STORING PROCESSES \n\nData Information Knowledge Wisdom (DIKW) 8 forms a \npyramid. Information is an enriched set of data values \nwhen considered in a context and that can be queried upon. \nVisualisation of data gives information. Spreadsheet gives \ninformation. Analytics gives information. \n\n\u201cOnly 5% streetlights are switched on in night in Internet of Streetlights\u201d is information \n(Example 1.2). \u201cAll ATMs active\u201d is information (Example 2.3). \u201cAll ACVMs filled with \nchocolates of all five flavours at the moment\u201d is information (Example 5.1). \u201cAn enterprise \nis showing consistent growth and profits in successive five years\u201d is information about the \nfunctioning of an enterprise. \n\nInformation in the given context is an answer to the query or set of queries. The answer \ncomes from processing the data and querying. For example, a balance sheet data is the \nenriched set of data values using the analytics. \u201cIs the data in enterprise balance sheet \nshowing consistent growth in preceding five years?\u201d is querying of the balance sheet. The \nanswer is the information obtained from the balance sheet. \n\nKnowledge, according to an English dictionary is sharable information and understanding \nabout a subject or context. Information that All ACVMs filled at most times gives \nunderstanding and knowledge that \u201cFill service is prompt in attending to the service \nrequests\u201d. Information about the time series data of sale figures for chocolates gives \nunderstanding and knowledge that \u201cACVMs give good sales and profit during festive the \ndays near the gardens.\u201d Knowledge comes from researching gives existing information. \nAn enterprise consistent growth is as a result of installation of new machinery five years \nback, full production during these years and enterprise sales force performance. \n\nIoT data sources continuously generate data, which the applications or processes \nacquire, organise and integrates or enriches using analytics. Knowledge discovery tools \n\n8 J. Rowley, \u201cThe wisdom hierarchy: Representations of the DIKW hierarchy\u201d, Journal of Information Science, 33(2), pp. \n163-19, 2007 \n\nExplain \nknowledge \ndiscovery, knowledge \n\nmanagement \nand knowledge- \nmanagement reference \n\narchitecture \n\nLO 5.5 \n\nData Acquiring, Organising, Processing and Analytics \n193 \n\nprovide the knowledge at particular point of time as more and more data is processed \nand analysed. Knowledge is an important asset of an enterprise. \n\nKnowledge Management \n\nKnowledge management 9 (KM) is managing knowledge when the new knowledge is \nregularly acquired, processed and stored. Knowledge management also provisions for \nreplacing the earlier gathered knowledge and managing the life cycle of stored knowledge. \n\u2018Fill service is prompt\u2019 is temporal knowledge. It may change at a later date. \u2018Enterprise \nconsistent growth\u2019 is temporal knowledge. It may change in sixth year of operations. \n\nA management tool role is to create, control, use, monitor and delete. A KM tool has \nprocesses for discovering, using, sharing, replacing with new, creating and managing the \nknowledge database and information of the enterprise. \n\nWisdom \n\nSensible and reasonable decisions are made using advanced tools which enable wise \ndecision. Wisdom , according to an English dictionary is \u201cAbility to use the experience and \nknowledge in order to make sensible and reasonable judgment and decisions\u201d. Judgment \nfrom the experience and knowledge that \u201cACVMs chain needs adaptation of loyalty \npoint scheme\u201d is wisdom. Judgment from the knowledge of clients of a particular bank, \n\u201cOperating a free dispensary will improve heath of the clients\u201d, then they will earn more \nand consequently bank expects to attract bigger deposits is wisdom. \n\n5.6.1 \nKnowledge-Management Reference Architecture \n\nFigure 5.6 (a) shows a reference architecture for knowledge management. Figure 5.6(b) \nshows correspondences with the ITU-T reference model four layers and OSI model layers. \n\nThe lowest layer has sublayers for devices data, streaming data sources which provide \ninput for analytics and knowledge. Databases, Business Support Systems (BSSs), \nOperational Support Systems (OSSs) data can also be additional inputs. \n\nNext higher layer has data adaptation and enrichment sublayers. Adaptation and \nenrichment sublayers adapt the data from the lowest layer in appropriate forms, such as \ndatabase, structured data and unstructured data so that it can be used for analytics and \nprocessing. \n\nNext higher layer has processing and analytics sublayers. These sublayers are input to \ninformation access tools and knowledge discovery tools. \n\nThe highest layer has knowledge acquiring, managing, storing and knowledge life-cycle \nmanagement; sublayers for managing, storing and knowledge life-cycle management. \nKnowledge acquires from the use of information access tools and knowledge discovery \ntools. \n\n9 https://en.wikipedia.org/wiki/Knowledge_management \n\n194 \nInternet of Things: Architecture and Design Principles \n\nDevice and \nGateway \nCapabilities \nLayer \n\nIoT/M2M Devices Data, Streaming Data, Business \n\nSupport and Operational Support Systems, \n\nDatabases Sublayers \n\nServices and \nApplications \nCapabilities \nLayer \n\nGeneric and \nSpecific \nSupport \nCapabilities) \nData Adaptation and Enrichment Sublayers \n\nKnowledge Managing, Storing and Knowledge \n\nLife-Cycle Management and \nKnowledge Acquiring Sublayer \n\nInformation Access and \nKnowledge Discovery Tools Sublayer \n\nProcessing and Analytics, Services and \n\nApplication Support Sublayers \n\nApplication and \nApplication Support \nLayer \n\nPhysical/Data link \nLayer \n\nApplication Layer \n\nAdaptation \nLayer \n\nFigure 5.6 (a) A reference architecture for the knowledge management (left-hand side) and \n\n(b) Correspondence in terms of ITU-T reference model and OSI layers for IoT/M2M (middle \nand right-hand side) \n\nReconfirm Your Understanding \n\n\u25cf Data Information Knowledge Wisdom forms a pyramid. \n\n\u25cf Information is an enriched set of data values when considered in a given context that can be queried \nupon. Visualisation of data gives information. Spreadsheet gives the information. Analytics gives \ninformation. \n\n\u25cf Knowledge gathers from researching up on the information. Knowledge is sharable information and \nunderstanding about a subject or context. \n\n\u25cf Knowledge management is managing knowledge when new knowledge is acquired, processed and \nstored. \n\n\u25cf Knowledge management architecture highest layer is knowledge managing, storing, knowledge life- \ncycle management, knowledge acquiring, information access and knowledge discovery tools. \n\n\u25cf Wisdom is the ability to use the experience and knowledge in order to make sensible and reasonable \njudgments and decisions. \n\nData Acquiring, Organising, Processing and Analytics \n195 \n\nS elf-Assessment E xercise \n\n1. Explain Data Information Knowledge Wisdom pyramid. \n2. Show diagrammatically, software components at the layers in reference- \n\narchitecture for knowledge management of services at Internet of automotive \ncomponents. \n3. Why does knowledge management include functions for replacing the earlier \n\ngathered knowledge, usage of knowledge discovery tool periodically and \nmanaging the life cycle of stored knowledge? Take example of ACPAMS. \n4. Explain knowledge management by example of applications, services and \n\nprocesses for Internet of Automatic Chocolate Vending Machines, Internet of \nATMs and Internet of automobile components. \n\n\u2605 \n\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605\u2605\u2605 \n\nKey Concepts \n\n\u25cf Big data \n\n\u25cf Business intelligence \n\n\u25cf Business process \n\n\u25cf CEP \n\n\u25cf Data acquiring \n\n\u25cf Data generation \n\n\u25cf Data source types \n\n\u25cf Data storage \n\n\u25cf Data store \n\n\u25cf Data visualisation \n\n\u25cf Database \n\n\u25cf DBMS \n\n\u25cf Descriptive analytics \n\n\u25cf Dicing functionalities \n\n\u25cf Information \n\n\u25cf In-memory database \n\n\u25cf Knowledge \n\n\u25cf NOSQL \n\n\u25cf OLAP \n\n\u25cf OLTP \n\n\u25cf Predictive analytics \n\n\u25cf Query \n\n\u25cf Query processing \n\n\u25cf RDBMS \n\n\u25cf Relational database \n\n\u25cf Spreadsheet \n\n\u25cf SQL \n\n\u25cf Transaction \n\n\u25cf Time-series database \n\n\u25cf Wisdom \n\nLearning Outcomes \n\nLO 5.1 \n\n\u25cf Data, real-time data, events or event-driven data generate from the active or passive devices \nand other data sources. \n\n\u25cf A data acquisition application interacts and acquires data from the interactions. Large magnitude \nof data is acquired from a large number of connected devices, especially from machines in \nindustrial plants or embedded components data from large number of automobiles or health \ndevices in ICUs or wireless sensor networks. \n\n\u25cf Data storage systems store the data after validation. Data store can be database, relational \ndatabase at a server or cloud. Data store can be at data warehouse or Big data at a Cloud. \n\n\u25cf Data store may consist of multiple schemas or may consist of data in only one scheme, such as \na relational database. Data store at server for short reaction times, optimised performance and \nhigh security. \n\n196 \nInternet of Things: Architecture and Design Principles \n\n\u25cf Spatial storage is storage as spatial database which is optimised to store, enables querying the \ndata objects defined in a geometric space, and which is a database for 2D and 3D objects. \n\nLO 5.2 \n\n\u25cf A database is a collection of data. A relational database is a collection of data into multiple \ntables which relates to each other through special fields. \n\n\u25cf Database Management System is a software system, which contains a set of programs specially \ndesigned for creation and management of data stored in a database. \n\n\u25cf Database transaction is the execution of a specific set of operations on a database. Transactions \ncan be performed on a database. Relational database transaction is the execution of interrelated \ninstructions using relations. \n\n\u25cf Query processing means using a process, getting the results of the query made to a database. \n\n\u25cf Distributed database is a collection of logically interrelated, cooperating databases over a \ncomputer network. Distributed query processing means query processing operations in \ndistributed databases on the same system or networked systems. \n\n\u25cf SQL is language for data access control, schema creation and modifications. NOSQL stands for \nor Not Only SQL or No-SQL and no integration with applications that are based on SQL. It is \nused in cloud data store. \n\n\u25cf Time series data means an array of numbers indexed with time (date-time or a range of date- \ntime). \n\nLO 5.3 \n\n\u25cf A transaction is a collection of operations that form a single logical unit of database. OLTP \nprocess begins as soon as data or events generate in real time. Batch transactions processing, \nstream transactions processing, real-time transaction processing, and complex event processing \nare process methods for data and events of the data sources and data stores. \n\n\u25cf A business process consists of a series of interrelated structured activities or tasks or processes \nwhich follow a logical sequence. \n\n\u25cf A process matrix represents series of operations and activities on a given set of inputs that \nperform a specific task leading to a decision point in the process. \n\n\u25cf Business intelligence is a process that enables a business service to extract new facts and \nknowledge and then undertake better decisions. \n\n\u25cf Distribution of processes reduces the complexity and communication costs, and enables faster \nresponses and smaller processing load at the central system. \n\n\u25cf Complex application integration integrates heterogeneous application architectures and \nnumber of processes. \n\n\u25cf SOA is a software architecture model consisting of services, messages, operations and processes. \n\nLO 5.4 \n\n\u25cf Organised data is used for analytics, new facts and decision taking on those facts. Analytics has \nthree phases before deriving new facts and provide business intelligence : descriptive, predictive \nand prescriptive analytics. \n\n\u25cf Analytics uses statistical methods and finds new parameters which add value to the data. \n\n\u25cf Analytics architecture consists of the following layers: Data Sources, Data Storage and \nProcessing, Data Access and Query Processing and Data Services, Reporting and Advanced \nAnalytics Layers. \n\nData Acquiring, Organising, Processing and Analytics \n197 \n\n\u25cf Descriptive analytics, statistics, data mining and machine learning are analytics tools. Analytics \nenable actions, reporting and generating spreadsheet, data visualisations and KPIs. \n\n\u25cf OLAP runs faster on column format, i.e. more rows and few columns. \n\n\u25cf Predictive analytics answer the question \u201cWhat will happen?\u201d Predictive analytics is advanced \nanalytics. The user interprets the outputs from advanced analytics using descriptive analytics \nmethods, such as data visualisation. \n\n\u25cf Prescriptive analytics answers not only what is anticipated or what will happen or when it will \nhappen, but also why it will happen based on inputs from descriptive analytics and business \nrules. \n\n\u25cf Event analytics use event data for event tracking and event reporting. \n\n\u25cf Analytics architecture consists of the following layers\u2014Data Sources, Data Storage and \nProcessing, Data Access and Query Processing, Data Services, Reporting and Advanced \nAnalytics Layers. \n\nLO 5.5 \n\n\u25cf Data Information Knowledge Wisdom forms a pyramid. \n\n\u25cf Knowledge gathers from researching existing new information. Knowledge is sharable \ninformation and understanding about a subject or context. \n\n\u25cf Wisdom is the ability to use experience and knowledge in order to make sensible and reasonable \njudgment and decisions. \n\nExercises \n\nObjective Questions \n\nSelect one correct option out of the four in each question. \n\n1. An IoT application or service software components at the applications and services \n\nlayer are (i) Devices data or event or message generation, (ii) Data acquiring, \ncollection, assembling and storage, (iii) Transactions processing, (iv) IoT applications \nintegration with services (v) Business processes, (vi) Complex Event Processing, \n(vii) Business intelligence, (viii) Analytics, (xi) Data analytics stack, (ix) Intelligence, \n(x) Knowledge discovery and (xi) Knowledge management. Which is correct? \n(a) All except (i) to , (vi) to (xi) \n(b) (iv) to (viii) \n\n(c) All except (x) and (xi) \n(d) All except (i) \n2. A service means (i) a mechanism which enables the provisioning of access to one \n\nor more capabilities, (ii) has an interface for the service which provides access to \ncapabilities, (iii) initiates on message from another service, (iv) consists of a set of \nrelated software components and their functionalities, (v) accesses server database, \n(v) access to each capability is consistent with the constraints and policies, (vi) has a \nservice description, (vii) can advertise for its capabilities, and (vii) can be used with \nthe complex applications integration. Which is correct? \n\n\u2605 \n\n\u2605\u2605 \n\n198 \nInternet of Things: Architecture and Design Principles \n\n(a) All except (iii) to (v) and (vii) \n(b) All except (iii) to (v) and (vii) \n\n(c) All except (v) \n(d) All except (vii) \n3. (i) Objects in a data store model using classes which the database define, (ii) data \n\nstore includes data repositories such as database, relational database, flat file, (iii) \nData store includes data repositories such as spreadsheet, mail server, web server, \ndirectory services and VMware, (iv) Data store may be distributed over multiple \nnodes, and (v) A data store may consist of multiple schemas or may consist of data in \nonly one scheme. Which is correct? \n(a) (ii) to (v) \n(b) (ii) and (v) \n\n(c) (i), (ii) and (iv) \n(d) All \n4. Relation database examples are (i) MySQL, (iii) PostGreSQL, (iv) Oracle database \n\ncreated using PL/SQL, (v) Microsoft SQL server using T-SQL, (vi) HBase, \n(vii) MongoDB, (viii) CouchDB, (ix) a database in which data organised into multiple \ntables which relates to each other through special fields, and (x) a database in which \ndata organised into flat file table which enables systematic way for the access. Which \nis correct? \n(a) All except (x) \n(b) All except (vi), (vii), (viii) and (x) \n\n(c) All except (v) \n(d) (i) and (ix) \n5. Server management functions are (i) Monitoring of all critical services with SMS and \n\nemail notifications, (ii) the security of systems and the protection, (iii) maintaining \nconfidentiality and privacy of data, (iv) high degree of security and integrity and \neffective protection of data, files and databases at the organisation, (v) protection of \ncustomer data or enterprise internal documents by attackers which includes spam, \n(vi) mails, unauthorized uses of the access to the server, viruses, malwares and \nworms, and (vii) strict documentation and audit of all activities. Which is correct? \n(a) All except (i), (vi) and (vii) \n(b) All \n\n(c) (i) to (v) \n(d) (ii) to (vii) \n6. SQL is a language for (i) data querying, updating, inserting, appending and deleting \n\nthe databases, (ii) data access control, schema creation and modifications, (iii) access \nto server (iv) querying the file, and (v) service. Which is correct? \n(a) (i) and (ii) \n(b) All except (ii) \n\n(c) All except (iii) \n(d) (i), (ii) and (iv) \n7. Decision on real-time data is fast when query processing in data has low latency due \n\nto (i) massively parallel processing, (ii) relational databases, (iii) time series database, \n(iv) in-memory database, and (v) columnar database. Which is correct? \n(a) (iii), (iv) and (v) \n(b) All except (ii) \n\n\u2605\u2605 \n\n\u2605 \n\n\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\nData Acquiring, Organising, Processing and Analytics \n199 \n\n(c) (i) to (iv) \n(d) (i), (iv) and (v) \n8. NOSQL is (i) used in cloud data store, (ii) used in data mining, (iii) means no database \n\nschema, (iv) no integration with applications that are based on SQL, and (v) consists \nof classes of non-relational data storage systems, flexible data models and multiple \nschemas. Which is correct? \n(a) All except (ii) \n(b) All except (i) \n\n(c) (i), (iv) and (v) \n(d) All \n9. OLTP is used in (i) Internet of Streetlights, (ii) Internet of Automatic Chocolate \n\nVending Machines, (iii) Internet of ATMs, (iv) Internet of Automotive Components \nfor Service Centre Predictive Analytics, (v) Internet of RFIDs, (vi) Complex event \nprocessing, and (vii) in case of applications when requirements are availability, \nspeed, concurrency and recoverability in databases for real-time data or events. \n(a) All \n(b) (iii), (iv), (vi) and (vii) \n\n(c) (iii) and (vii) \n(d) (iii) to (vii) \n10. A layer in business intelligence and business processes architecture reference model \n\nfor internet of automotive components for service centre consists of the following: \n(a) Datagram transport layer security layer \n(b) Data access, SQL, query processing, R-descriptive statistics, predictive analytics \n\nlayer \n(c) Data integration layer \n(d) Transactions processing layer \n11. SOA (i) models the number of services and interrelationships, (ii) is a software \n\narchitecture model which consists of services, messages, operations and processes, \n(iii) components distribute over a network or the Internet in a high-level business \nentity, and (iv) new business applications and applications integration architecture \nin an enterprise can be developed using a SOA. Which is correct? \n(a) All except (iii) \n(b) All \n\n(c) All except (iv) \n(d) (ii) \n12. Descriptive analytics enable (i) actions, (ii) reporting or generating spreadsheets, \n\n(iii) statistical analysis, (iii) visualisations from different perspectives of the analysed \nresults, and (iv) creation of key performance indicators, (v) data visualisation of \nslices and dices from cross reference tables, (vi) creation of in-memory row-format \ndatabase, and (vii) later on predictions using predictive analytics. Which is correct? \n(a) (i) to (iv) \n(b) All except (ii) and (iii) \n\n(c) All \n(d) All except (vi) \n13. Big data means (i) cloud data, (ii) data received from number of sources of data, \n\n(iii) data sets with sizes beyond the ability of commonly used software tools to acquire, \nmanage and process data within a tolerable elapsed time, (iv) unstructured data in \n\n\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\n\u2605 \n\n\u2605\u2605 \n\n200 \nInternet of Things: Architecture and Design Principles \n\npredefined formats, and (v) data on which NOSQL (Structured Query Language) \napplicable. \n(a) All except (iv) \n(b) (iii) to (vii) \n\n(c) All except (i) and (vi) \n(d) (iii) to (vii) \n14. An Oracle Database has (i) in-memory row format option and (ii) in-memory column \n\nformat option. Which is correct? \n(a) Real-time analytics need both options \n(b) Real-time analytics need option (ii) \n\n(c) OLTP needs (ii) option \n(e) OLAP needs (i) option \n15. Analytics architecture and Berkeley Data Analytics Stack Architecture consist of \n\n(i) Data sources layer, (ii) Data storage and processing layer, (iii) Data access and \nquery processing layer, and (iv) Data services, reporting and advanced analytics \nlayer. Which is correct? \n(a) (i) to (iv) in analytics architecture only \n(b) All except (i) and (ii) \n\n(c) All except (i) \n(d) All \n16. Highest layer at knowledge management reference architecture consists of \n\n(i) knowledge managing, (ii) knowledge storing, (iii) knowledge life-cycle \nmanagement, (iv) KNOWLEDGE acquiring, (v) information access and knowledge \ndiscovery tools, (vi) analytics (vii) processing and (viii) services and databases. Which \nis correct? \n(a) All except (viii) \n(b) All except (iii) \n\n(c) (i) to (v) \n(d) All \n\nShort-Answer Questions \n\n1. What do the sensor data, real-time data, periodic intervals data, event data, and event \n\ninitiated data mean? Give an example of each in IoT/M2M applications. \n[LO 5.1] \n2. What are the checks, which validate the data? \n[LO 5.1] \n3. What are the methods for data storage, which can be used for analytics later? \n\n[LO 5.1] \n4. How do the database and relation database differ? \n[LO 5.2] \n5. What are the functions which spatial database can perform? \n[LO 5.2] \n6. How do you select a chocolate flavour FL1 sales on festive days from transactions \n\nwith the data store? \n[LO 5.2] \n7. Why do the database transactions follow rules of atomicity, consistency, isolation, \n\nand durability? \n[LO 5.2] \n8. List the performed actions during the event-stream processing and complex-event \n\nprocessing. \n[LO 5.2] \n9. How do mathematical operations (profiles, traces, and curves), queries or database \n\ntransactions on time series implement in a Time Series Database (TSDB)? \n[LO 5.2] \n\n\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\n\u2605 \n\n\u2605\u2605 \n\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605 \n\u2605\u2605 \n\n\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605\u2605\u2605 \n\nData Acquiring, Organising, Processing and Analytics \n201 \n\n10. What are the data types for which CAP theorem holds true? Answer why CAP \n\ntheorem states that out of three properties (consistency, availability and partitions), \ntwo are at least present for a service or process? \n[LO 5.2] \n11. What are the types of business processes? \n[LO 5.3] \n12. What are the software components for descriptive analytics? \n[LO 5.3] \n13. When are streaming transactions and batch transactions performed? \n[LO 5.3] \n14. What are the operations preceding business intelligence? \n[LO 5.3] \n15. List reasons for distributed databases reduced complexity, communication costs, \n\nfaster responses and smaller processing load at the central system. \n[LO 5.3] \n16. What are the different visualisations from the OLAP? \n[LO 5.4] \n17. Why does knowledge require replacement and needs use of knowledge discovery \n\ntools at specified periodic intervals? Take an enterprise which services automobiles \nusing descriptive and prescriptive analytics as an example. \n[LO 5.5] \n\nReview Questions \n\n1. Describe data generation from IoT/M2M devices. \n[ LO 5.1 ] \n2. List the features of relational time series service. \n[ LO 5.2 ] \n3. What is NOSQL and what are the NOSQL usages? \n[ LO 5.2 ] \n4. Describe different types of transaction processing on databases, streaming data and \n\nevents. \n[ LO 5.3 ] \n5. List the features of distributed business process and distributed business process \n\nsystem (DBPS). \n[ LO 5.3] \n6. List OLAP functionalities. \n[ LO 5.4 ] \n7. Describe in-memory row format and column format database features and usages. \n\n[ LO 5.4 ] \n8. Explain using an example of Data Information Knowledge Wisdom pyramid from \n\nthe sales data acquiring, organising and analytics. \n[ LO 5.5 ] \n\nPractice Exercises \n\n1. List data types which communicate from RFIDs in Internet of RFIDs. \n[LO 5.1] \n2. List ways in which sensor nodes configures in Internet of Streetlights. \n[LO 5.1] \n3. List the SQL functionalities. \n[LO 5.2] \n4. Which relational database tables in Example 5.2 for Internet of Automobile \n\nComponents are used in ACPAMS Centre? \n[LO 5.2] \n5. Consider Example 5.1 and list the process matrix and interleaved decision points. \n6. List the usages of Internet of Automatic Chocolate Vending Machines after analytics \n\nusing three relational database tables.(Example 5.3) \n[LO 5.3] \n7. List the business intelligence obtained in Internet of ATMs. \n[LO 5.3] \n8. Workout the n -dimensional structure of 2- n cross-referenced tables in Internet of \n\nAutomatic Chocolate Vending Machines. \n[LO 5.4] \n9. Assume n devices each in ICU from ten patients communicate data and events onto \n\nthe Internet. List the series of activities and software tools at each layer required for \nacquiring, storing and analytics. Draw the analytics reference architecture. [LO 5.5] \n10. List the processes for knowledge creation. \n[LO 5.5] \n\n\u2605\u2605 \n\n\u2605 \n\u2605\u2605 \n\u2605\u2605 \n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\u2605\u2605\u2605 \n\n\u2605 \n\u2605\u2605 \n\u2605\u2605 \n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\n\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605 \n\u2605\u2605 \n\u2605\u2605 \n\u2605\u2605\u2605 \n\n\u2605\u2605 \n\u2605\u2605 \n\n\u2605 \n\u2605\u2605\u2605 \n\n\u2605\u2605\u2605 \n\n\u2605 \n\n",
  "createdAt": "2026-02-17"
}