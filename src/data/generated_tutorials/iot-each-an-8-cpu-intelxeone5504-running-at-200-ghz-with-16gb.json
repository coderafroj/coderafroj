{
  "title": "each an 8-CPU Intel\u00aeXeon\u00aeE5504 running at 2.00 GHz, with 16\u223cGB",
  "slug": "iot-each-an-8-cpu-intelxeone5504-running-at-200-ghz-with-16gb",
  "description": "Module from iot.pdf: each an 8-CPU Intel\u00aeXeon\u00aeE5504 running at 2.00 GHz, with 16\u223cGB",
  "tags": [
    "iot",
    "Elite"
  ],
  "content": "# each an 8-CPU Intel\u00aeXeon\u00aeE5504 running at 2.00 GHz, with 16\u223cGB\n\nRAM and running the Ubuntu 12.04 operating system. The number of nodes in the P2P network was split evenly among all cluster hosts (up to 250 peers per cluster host), which were connected using a tradi- tional switched Ethernet LAN. The HTTP-to-CoAP proxy functional- ity relies on two di\ufb00erent implementations: \n\n\u2022 one based on the mjCoAP library [23], an open-source Java-based RFC-compliant implementation of the CoAP protocol; \u2022 the other based on the Californium platform [94]. \n\nBoth HTTP-to-CoAP proxies were written in Java and provide their own local service discovery mechanisms. The use of two di\ufb00erent types of HTTP-to-CoAP proxy shows clearly how the overlay can be easily developed and integrated with currently available technologies. The sensor nodes are either Arduino boards or Java-based emulated CoAP nodes (just for emulating large network scenarios). \n\n176 4 Discoverability \n\nEach performance result is obtained by averaging over 40 executions of PUT and GET procedures for each size of the overlay. As anticipated, the following performance metrics are of interest: \n\n\u2022 elapsed time for a JOIN operation (dimension: [ms]); \u2022 number of rounds for PUT operations (adimensional); \u2022 number of rounds for GET operations (adimensional). \n\nThe selection of the number of rounds for PUT and GET operations, rather than their times, is expedient to present performance results that are independent of the actual deployment environment. For the JOIN operation, the average total time required to completion is shown in order to provide a practical measurement of the complexity of this operation. However, the very nature of all operations relies on a common iterative procedure [78], thus making it possible to intuitively derive the behavior of all operations in terms of time and rounds. The performance results are shown in Figure 4.12. As expected, the complexity, in terms of JOIN time and numbers of rounds for PUT/GET operations, is a logarithmically increasing function of the number of peers. In Figure 4.12, the experimental data are directly compared with the following logarithmic \ufb01tting curves [95]: \n\nJoin time \u224316.5 + 61.29 \u22c5log n \n\n# of rounds PUT \u2243\u22125.75 + 3.44 \u22c5log n \n\n# of rounds GET \u2243\u22120.40 + 0.15 \u22c5log n. \n\nThis clearly proves the scalability brought by the use of a P2P approach, con\ufb01rming the formal analysis and results of Maymounkov and Mazi\u00e8res [78]. To summarize, we have presented a novel architecture for self- con\ufb01gurable, scalable, and reliable large-scale service discovery. The proposed approach provides e\ufb03cient mechanisms for both local and global service discovery. First, we have described the IoT gateway and the functionalities that this element must implement to perform resource and service discovery. Then, we have focused on large-scale distributed resource discovery, exploiting a proper P2P overlays, namely DLS and DGT, which implement, respectively, \u201cwhite-pages\u201d and \u201cyellow-pages\u201d services. Finally, we have shown a solution for automated local service discovery that allows for discovery of resources available in constrained WSNs and their publication into the P2P overlay with no need for any prior con\ufb01guration (Zeroconf). \n\n4.3 Scalable and Self-con\ufb01guring Architecture for Service Discovery in the IoT 177 \n\n0 200 400 600 800 1000 Nodes \n\ny = 16.5212 + 61.2973 \u00b7 log(n) \n\n0 200 400 600 800 1000 Nodes \n\ny = \u20135.7569 + 3.4415 \u00b7 log(n) \n\n0 200 400 600 800 1000 Nodes \n\ny = \u20130.40637 + 0.15098 \u00b7 log(n) \n\n0 \n\n100 \n\n200 \n\n300 \n\n400 \n\n500 \n\n600 (a) \n\nJOIN Time [ms] \n\n(b) \n\n0 \n\n5 \n\n10 \n\n15 \n\n20 \n\n25 \n\nPUT Rounds \n\n(c) \n\n0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1 \n\nGET Rounds \n\nFigure 4.12 Experimental results collected to evaluate the performance of the DLS overlay: (a) average elapsed time for JOIN operations, (b) the average number of rounds (adimensional) for PUT operations, and (c) the average number of rounds (adimensional) for GET operations on the DLS towards the number of active IoT gateways in the P2P network. Plotted data have also been used to construct \ufb01tted curves (in red); the formulae of which are reported in the top-right hand corners. \n\n178 4 Discoverability \n\nExtensive experimental performance evaluation of the proposed local and large-scale service discovery mechanisms was performed. For the local service discovery mechanism, experiments were con- ducted on Contiki-based nodes operating in constrained (IEEE 802.15.4) networks with RPL in the Cooja simulator. The large-scale service discovery mechanism was deployed and tested on P2P overlays of di\ufb00erent sizes, spanning from a few to 1000 peers, in order to eval- uate the performance in terms of scalability and self-con\ufb01guration. The results show that the time required for service resolution in the Zeroconf-based approach for local service discovery is linearly dependent on the number of hops in the path between the client and server node. For large-scale service discovery, the adoption of a P2P overlay provides scalability in terms of the time required to perform the basic publish/lookup operations. In conclusion, the easy and transparent integration of two di\ufb00erent types of overlays shows the feasibility and reliability of a large-scale architecture for e\ufb03cient and self-con\ufb01gurable service and resource discovery in IoT networks. \n\n4.4 Lightweight Service Discovery in Low-power IoT Networks \n\nZeroconf [60] is a protocol suite which reuses the semantics of DNS messages over IP multicast to provide name resolution and service discovery/advertisement over local networks. In order to support Zeroconf service discovery mechanisms, it is very important that the network supports IP multicasting and implements proper forwarding techniques to guarantee that packets are delivered to all group nodes and avoids the establishment of loops. Using e\ufb03cient packet forwarding mechanisms can bring bene\ufb01ts in multi-hop communications among smart objects, in terms of delay and energy consumption. Moreover, it is also important to note that the limited amount of memory available on smart objects requires the adoption of small-footprint mechanisms, in order to allow developers to integrate a complete software stack, without having to sacri\ufb01ce some modules in order to meet the memory constraints. Although the IETF ROLL working group is de\ufb01ning a Multicast Protocol for Low power and Lossy Networks (MPL) [96], based on the Trickle algorithm [97], some \n\n4.4 Lightweight Service Discovery in Low-power IoT Networks 179 \n\napplications might have di\ufb00erent requirements and could bene\ufb01t from the adoption of other multicast techniques. In the following sections we present a lightweight and low-power multicast forwarding protocol for service discovery in smart objects operating in IEEE 802.15.4 multi-hop networks. The proposed solu- tion features a smaller memory footprint than in other state-of-the-art solutions. The proposed mechanism has been implemented on Con- tiki OS-enabled smart objects. Extensive testing is carried out in the Cooja simulator to evaluate the feasibility and e\ufb03ciency, in terms of delay and energy consumption, of the proposed mechanism. Local service discovery mechanisms in LANs have been proposed in the literature. Protocols like UPnP [57] and SLP [58, 59] focus on automatic announcement and discovery of in-network existing services. However, their porting to IoT devices is not straightfor- ward because of the severe computation and energy constraints of the nodes. An alternative to these protocols relies on multicast forwarding. For instance, Jung and Kastner proposed an e\ufb03cient group communication strategy for the CoAP and the E\ufb03cient XML Interchange protocols [98]. To achieve group communication, they rely on the Open Building Information eXchange standard. However, this implementation runs on Raspberry PI nodes, so it is not suitable for constrained devices. Concerning 6LoWPAN and IPv6, the only active IETF draft on e\ufb03cient multicast forwarding is MPL [96], that relies on the Trickle algorithm to manage transmissions for both control and data plane. The di\ufb00erent multicast interfaces, identi\ufb01ed by an unicast address and associated with one or more multicast domains, are handled sep- arately, so as to maintain an independent seed set to decide whether to accept a packet or not. The MPL forwarder, which is in charge of sending data messages, has two di\ufb00erent possible strategies: proactive or reactive. In the former case, the MPL forwarder schedules the transmission of MPL data messages using the Trickle algorithm, without any prior indication that neighbor nodes are yet to receive the message. After transmitting a limited number of MPL data messages, the MPL forwarder may terminate proactive forwarding for the MPL data message. In the latter, the MPL forwarder sends link-local multicast MPL control messages using the Trickle algorithm. MPL forwarders use MPL control messages to discover new MPL data messages that have not yet been received. When an MPL forwarder discovers that a neighbor MPL forwarder has not yet received an \n\n180 4 Discoverability \n\nMPL data message, it schedules the transmission of those MPL data messages using the Trickle algorithm. The two approaches can coexist at the same time. Oikonomou and Phillips proposed Stateless Multicast RPL For- warding (SMRF [99]), which relies on the presence of the RPL routing protocol and requires group management information to be carried inside RPL destination advertisement object (DAO) messages. However, since, for our goal, a less complicated multicast strategy (no group management is required) is needed, we prefer to rely on a more lightweight \ufb02ooding technique, which adapts well to duty-cycled devices operating in RPL networks implementing the Zeroconf protocol suite. \n\n4.4.1 E\ufb03cient Forwarding Protocol for Service Discovery \n\nZeroconf is a protocol that allows for automatic creation of computer networks based on the TCP/IP Internet stack. It does not require any external con\ufb01guration [60]. Zeroconf provides three main functional- ities: \n\n\u2022 automatic network address assignment; \u2022 automatic distribution and resolution of host names; \u2022 automatic location of network services. \n\nAutomatic network assignment comes into the picture when a node \ufb01rst connects to the network. The host name distribution and reso- lution is implemented using multicast DNS (mDNS) [61], a service that has the same interfaces, packet formats, and semantics as stan- dard DNS, so as to resolve host names in networks that do not include a local name server. Zeroconf also allows to for publication of services (DNS-SD) in a local network. Both mDNS and DNS-SD do not require the presence of any server (and, therefore, its knowledge) to perform publish, lookup, and name resolution operations, but rely on the use of IP multicast communications in order to address all the nodes in the local network. Zeroconf speci\ufb01es that mDNS and DNS-SD mes- sages (for both requests and responses) must be sent to the mDNS IPv4/IPv6 link-local multicast address (i.e., 224.0.0.251 and \ufb0002::fb, respectively). However, Zeroconf does not require per-group multi- cast routing: according to the protocol speci\ufb01cations, messages should simply reach all nodes in the local network. \n\n4.4 Lightweight Service Discovery in Low-power IoT Networks 181 \n\n6LoWPAN de\ufb01nes methods \n\n\u2022 to transmit IPv6 packets and \u2022 to form IPv6 link-local addresses and statelessly autocon\ufb01gure addresses on IEEE 802.15.4 networks. \n\nThe RPL protocol de\ufb01nes a routing protocol for IP communications in LLNs. The IETF ROLL Working Group is working on the de\ufb01ni- tion of MPL, a multicast protocol providing IPv6 multicast forwarding in constrained networks. This could become a general multicast tech- nique able to manage multicast groups of any size. However, in some scenarios, such as Zeroconf service discovery, there is no need to actu- ally adopt such a full-feature multicast protocol. For the sake of Zero- conf service discovery, it is su\ufb03cient to provide a multicast forwarding mechanism that guarantees that messages can be delivered to all nodes in the local network. In this section, we detail a simple and e\ufb03cient for- warding algorithm that can be adopted by constrained devices oper- ating in RPL networks with ContikiMAC radio duty-cycling protocol, in order to enable IP multicast communications with a small footprint, targeting Zeroconf service discovery. \n\n4.4.1.1 Multicast through Local Filtered Flooding Flooding is the simplest routing protocol for broadcasting a packet to all nodes in the network. From a practical implementation point of view, each node forwards a received packet to all its neighbors. This technique is e\ufb00ective only for cycle-free topologies (i.e., trees). In the presence of graphs with cycles, it is necessary to implement duplicate detection techniques to avoid forward loops. An illustration is shown in Figure 4.13. In order to implement an e\ufb03cient mechanism to detect already- processed packets (and, thus, avoid redundant forwarding), we pro- pose the adoption of Bloom \ufb01lters [100]. Bloom \ufb01lters are probabilistic data structures that can be used to add elements to a set and to e\ufb03- ciently check whether an element belongs to the set or not. Bloom \ufb01lters provide two primitives: \n\n\u2022 add(x): add element x to the set; \u2022 query(x): test to check whether element x is in the set. \n\nThe \ufb01lter does not provide a remove(x) primitive, so it is not possible to undo an insertion. Bloom \ufb01lters are slower when performing check \n\n\n![Image](/src/assets/generated_images/iot_p194_i0.png)\n182 4 Discoverability \n\n\n1 \n\n1 \n\n1 \n\n3 \n\n3 3 1 \n\n2 \n\n2 \n\n3 \n\n4 \n\n5 5 5 5 \n\nServer Client \n\ntopology links packet forwarding possible loop \n\nDuplicate packet received Duplicate packet received \n\n4 \n\nFigure 4.13 Flooding of a DNS-SD query in generic topology with cycles. \n\noperations than equivalent probabilistic data structures (in terms of provided functionalities), such as quotient \ufb01lters [101], but occupy less memory. As available memory on smart objects is extremely limited, one of the design goals of the proposed forwarding algorithm is to keep the memory footprint (both in terms of RAM and ROM) as low as possible. Therefore, Bloom \ufb01lters have been selected as the most appropriate data structure to keep track of already-processed packets. A Bloom \ufb01lter is initially an array of m bits, all set to zero. The add(x) operation passes the input argument x through k di\ufb00erent hashing functions and obtains k indexes in the bit array of the Bloom \ufb01lter that will be set to one. The query(x) operation veri\ufb01es whether the indexes corresponding to x are all set to one. The Bloom \ufb01lter is probabilistic in the sense that a query(x) operation can return false positives: there can exist two values x1 and x2, such that query(x1) = query(x2) = true. False negatives, on the other hand, are not possible: this means that if a query(x) returns false, then x is not in \ufb01lter. The query(x) operation can thus return either \u201cprobably in the set\u201d or \u201cnot in the set\u201d. Bloom \ufb01lters can be instantiated to meet speci\ufb01c application requirements by selecting the parameters m (number of bits in the array) and k (number of hashing functions). For instance, the choice of m and k has an impact on the probability of getting false positives for query(x) operations and on memory occupation. In any case, the impossibility of removing an element from the \ufb01lter leads to an increase in the probability of false positives as more and more \n\n4.4 Lightweight Service Discovery in Low-power IoT Networks 183 \n\nelements are added to the \ufb01lter. Since the purpose of using a Bloom \ufb01lter in the forwarding algorithm is to detect duplicate elements, in order to cope with the problem of false positives, the Bloom \ufb01lter is periodically reset. Resetting the \ufb01lter might introduce some unnecessary retransmissions if the \ufb01lter is emptied before receiving a duplicate packet. However, retransmissions are preferable to packet drops in order to guarantee that a multicast packet reaches all hosts. Moreover, such unnecessary retransmissions might occur no more than once, as the packet would then be added to the \ufb01lter and not processed upon future receptions. To summarize, upon receiving a packet, a node will perform the following steps: \n\n1) Check if the incoming IP packet has already been processed, by per- forming a query operation in the Bloom \ufb01lter. 2) If the Bloom \ufb01lter contains the packet, discard it; otherwise, the packet is added to the Bloom \ufb01lter through an add operation. 3) If needed, forward the received IP packet to all neighbors by means of local IEEE 802.15.4 broadcast. \n\n4.4.2 E\ufb03cient Multiple Unicast Forwarding \n\nWhile the described algorithm implements an optimized \ufb02ooding mechanism by avoiding loops through the introduction of Bloom \ufb01lters, broadcasting with the ContikiMAC radio duty-cycling pro- tocol results in ine\ufb03cient transmissions, leading to higher energy consumption and end-to-end delays. In fact, in ContikiMAC, a broad- casting node must repeatedly transmit a packet for the full wake- up interval [49], in order to ensure that it can be received by all neighbor nodes, regardless of their wake-up time. This conservative approach has the following drawbacks: \n\n\u2022 the number of transmitted packets is larger than necessary, and therefore energy consumption is higher; \u2022 when a node is broadcasting a packet, other nodes are not allowed to transmit, and this delays the transmission until the channel is clear; \u2022 since ContikiMAC broadcasting does not make provision to acknowledge received packets, it might be that not all neighbors have successfully received the packet, thus leading to unreliable transmission. \n\nThese ine\ufb03ciencies are magni\ufb01ed when the channel check rate (CCR) decreases, since the full wake-up interval is longer and therefore \n\n\n![Image](/src/assets/generated_images/iot_p196_i0.png)\n184 4 Discoverability \n\nthe channel is busy for longer, thus leading to even more repeated transmissions and delays. This contrasts with the assumption that lower CCR leads to lower energy consumption. In order to tackle these issues, we replace local broadcast with multiple unicast transmission. The forwarding algorithm can therefore be optimized by selecting the receiving nodes from the list of next hops, which is retrieved from the RPL routing table. In fact, ContikiMAC provides per-node-pair synchronization, which ensures that packets are sent only when the receiver is supposed to be active. The receiver is required to send an acknowledgement for the received packet, thus transmitting packets only for as long as necessary, thus leading to more reliable transmissions. The enhanced version of the proposed multicast protocol can there- fore be detailed as follows: \n\n1) Check if the incoming IP packet has been processed already by per- forming a query operation in the Bloom \ufb01lter. 2) If the Bloom \ufb01lter contains the packet, discard it; otherwise, add the packet to the Bloom \ufb01lter through an add operation. 3) Retrieve the list of next hops from the routing table. 4) If needed, forward the received IP packet to each next hop using IEEE 802.15.4 unicast communication. \n\nAn excerpt of a sequence of transmitted frames, using broadcast for a DNS-SD query, is shown in Figure 4.14. The equivalent packet \ufb02ooding with multiple unicast transmissions is shown in Figure 4.15. Transmitted packets (TX), received packets \n\n\nFigure 4.14 DNS-SD query propagation DNS-SD query propagation with ContikiMAC broadcast. Time is on the x-axis while node identi\ufb01ers are on the y-axis. \n\n\n![Image](/src/assets/generated_images/iot_p197_i0.png)\n4.5 Implementation Results 185 \n\n\nFigure 4.15 DNS-SD query propagation with multi-unicast. Time is on the x-axis while node identi\ufb01ers are on the y-axis. \n\n(RX), and PHY interference (PHY INT) are highlighted. The root of the RPL tree (node 1) is always active, while all other nodes have CCR = 8 Hz. The timelines clearly show that multiple unicast transmissions optimize the number of transmitted packets and the packet propagation delay in the network, while guaranteeing more reliable transmissions. However, this comes at the cost of a slightly increased ROM/RAM footprint. \n\n4.5 Implementation Results \n\nIn order to evaluate the performance of the proposed multicast packet forwarding mechanism, a Contiki-based implementation has been developed. Besides the proposed multicast forwarding algorithm, the mDNS and DNS-SD protocols have been re-implemented, in order to have a smaller memory footprint than in other, already available implementations. The performance evaluation of the Zeroconf-based local service discovery strategy was conducted using WiSMote4 \n\nContiki nodes, simulated in the Cooja simulator. The Contiki soft- ware stack running on each node was con\ufb01gured in order to \ufb01t in the WiSMote\u2019s available memory, in terms of both RAM and ROM \u2013 WiSMote nodes feature a nominal 128 kB, 192 kB or 256 kB ROM and 16 kB RAM. The simulated smart objects run Contiki OS, uIPv6, RPL, and ContikiMAC. The local service discovery mechanism was tested on Contiki nodes arranged in linear and grid topologies, as shown in Figure 4.16, in \n\n4 http://wismote.org/. \n\n\n![Image](/src/assets/generated_images/iot_p198_i0.png)\n\n![Image](/src/assets/generated_images/iot_p198_i1.png)\n186 4 Discoverability \n\n\n2 \n\n4 \n\n8 \n\n11 \n\n15 16 17 3 \n\n12 13 14 \n\n9 1 10 \n\n5 6 7 \n\n\n2 4 5 6 7 8 9 10 11 12 1 13 14 15 16 17 18 19 20 3 \n\n(a) \n\n(b) \n\n18 \n\nFigure 4.16 Topologies considered for Zeroconf service discovery experimentation with the proposed multicast protocol: (a) linear and (b) grid. \n\nIEEE 802.15.4 networks, with RPL as routing protocol and Contiki- MAC as radio duty-cycling protocol. In particular: \n\n\u2022 node 1 is the 6LoWPAN border router (6LBR), which is the root of the RPL tree; \u2022 node 2 is the node acting as DNS-SD server; \u2022 node 3 is the node acting as DNS-SD client. \n\nThe \ufb01rst performance indicator is memory occupation in terms of ROM. The proposed multicast protocol \u2013 both with broadcast and multiple unicast transmission \u2013 is compared to the MPL (with Trickle algorithm) implementation available in the Contiki 3.x fork. The results are shown in Table 4.2. \n\nTable 4.2 ROM usage for the proposed multicast protocol and an MPL implementation: total ROM occupation and as a percentage of available memory on 128-kB WiSMote. \n\nLibrary ROM occupation [B] \n\nOccupation of overall available ROM \n\nThis work (broadcast) 842 0.64% \n\nThis work (multiple unicast) 1454 1.11% \n\nMPL with Trickle 3804 2.90% \n\n4.5 Implementation Results 187 \n\nAs expected, the footprint of the proposed solution is signi\ufb01cantly smaller than that of the MPL implementation: approximately 78% for broadcast and 62% for multiple unicast. The next phase of experimentation aims at evaluating the time and the overall network energy consumption needed to perform adver- tisement and resolution of services using Zeroconf in the topologies shown in Figure 4.16 and the proposed broadcast-based and multiple unicast-based approaches. All the results were obtained by performing 100 service discovery runs on each con\ufb01guration. The speci\ufb01c perfor- mance metrics are: \n\n\u2022 query client time (QC), which is the time needed by a node acting as client to send a DNS-SD query and receive a response (dimension: [ms]); \u2022 energy consumption (E), which is the overall network energy con- sumption for a DNS-SD query operation (dimension: [mJ]). \n\nThe impact of the CCR (varying from 8 Hz to 128 Hz) of the nodes par- ticipating in the constrained network is analyzed. The results for QC and E are shown in Figures 4.17 and 4.18, respectively. As expected, QC is inversely proportional to the CCR. The bene\ufb01t of using multiple \n\n0 \n\n2000 \n\n4000 \n\n6000 \n\n8000 \n\n10000 \n\n12000 \n\n0 16 32 48 64 80 96 112 128 \n\nTime [ms] \n\nCCR [Hz] \n\nBroadcast Grid Broadcast Linear Multiple Unicast Grid Multiple Unicast Linear \n\nFigure 4.17 Time required to perform a DNS-SD query by a client in linear and grid topologies with broadcast and multiple unicast. \n\n188 4 Discoverability \n\n0 \n\n500 \n\n1000 \n\n1500 \n\n2000 \n\n0 16 32 48 64 80 96 112 128 \n\nE [mJ] \n\nCCR [Hz] \n\nBroadcast Grid Broadcast Linear Multiple Unicast Grid Multiple Unicast Linear \n\nFigure 4.18 Overall network energy consumption when a client performs a DNS-SD query in linear and grid topologies with broadcast and multiple unicast. \n\nunicast transmissions, instead of broadcast, is higher when the CCR is low, while the two approaches tend to overlap for higher values of the CCR. At typical CCR values, multiple unicast performs better than broadcast because, with lower CCR, the wake-up interval is longer and ContikiMAC broadcast transmissions occupy the channel for the whole interval. Higher CCR values mean shorter wake-up intervals and therefore other nodes in the network are likely to be blocked. In the case of the grid topology, with a CCR of 128 Hz, broadcast is actually slightly faster than unicast. In fact, at this high rate, the smart objects are almost behaving as with null duty-cycling, which is the best-case scenario for broadcast transmission. As for energy consump- tion, the results clearly show that broadcast is much more ine\ufb03cient than multiple unicast transmissions. It is important to point out that a signi\ufb01cant contribution (more than 60% with multiple unicast and 30% with broadcast, at CCR = 8 Hz) to the energy consumption of the overall network comes from the border router, which does not per- form duty-cycling. Again, this is motivated by the ContikiMAC broad- cast strategy, which requires nodes to transmit for the whole wake-up interval. As for QC, the two approaches tend to overlap at high CCR. However, these results should not be interpreted as a suggestion to use \n\n4.5 Implementation Results 189 \n\nhigher CCR, as this would invalidate all the advantages of duty-cycling, which is particularly bene\ufb01cial in other scenarios. We introduced a novel multicast forwarding mechanism targeting service discovery in IoT scenarios. The proposed solution is suited to bringing e\ufb03cient IP-multicast support to low-power IoT networks with duty-cycled devices. The rationale behind the presented forward- ing mechanism is to have a lightweight and low-memory-footprint implementation for speci\ufb01c Zeroconf service discovery operations. In such scenarios, the adoption of a full-featured multicast implementa- tion, such as MPL, might be overkill, since there is no need to provide multicast group support. Instead, an e\ufb03cient \ufb02ooding mechanism is used in the local network. The proposed multicast protocol relies on \ufb01ltered local \ufb02ooding, which adapts well to duty-cycled devices operating in LLNs with RPL. In order to avoid forward loops, we introduce Bloom \ufb01lters, an e\ufb03cient probabilistic data structure, to detect duplicate packets and prevent forward loops. The experimental results demonstrate that the proposed multicast protocol features a much smaller footprint, in terms of ROM occupation, than the MPL implementation available in the o\ufb03cial Contiki fork. Finally, delay and network energy consumption have been evaluated. \n\n191 \n\n5 \n\nSecurity and Privacy in the IoT \n\nThe Internet of Things (IoT) refers to the Internet-like structure of billions of interconnected \u201cconstrained\u201d devices: with limited capabilities in terms of computational power and memory. These are often battery-powered, thus raising the need to adopt energy-e\ufb03cient technologies. Among the most notable challenges that building interconnected smart objects brings about are standardization and interoperability. Internet Protocol (IP) is foreseen as the standard for interoperability for smart objects. As billions of smart objects are expected to appear and IPv4 addresses have mostly been used, IPv6 has been identi\ufb01ed as a candidate for smart-object communication. The deployment of the IoT raises many security issues, arising from \n\n\u2022 the very nature of smart objects: the use of cryptographic algorithms that are lightweight, in terms of processing and memory require- ments; \u2022 the use of standard protocols and the need to minimize the amount of data exchanged between nodes. \n\nThis chapter provides a detailed overview of the security challenges related to the deployment of smart objects. Security protocols at net- work, transport, and application layers are discussed, together with the lightweight cryptographic algorithms that it is suggested should be used instead of conventional resource-hungry ones. Security aspects, such as key distribution and security bootstrapping, and application scenarios, such as secure data aggregation and service authorization, are also discussed. \n\nInternet of Things: Architectures, Protocols and Standards, First Edition. Simone Cirani, Gianluigi Ferrari, Marco Picone, and Luca Veltri. \u00a9 2019 John Wiley & Sons Ltd. Published 2019 by John Wiley & Sons Ltd. \n\n192 5 Security and Privacy in the IoT \n\n5.1 Security Issues in the IoT \n\nSecurity in IoT scenarios is a crucial consideration. It applies at dif- ferent levels, ranging from technological issues to more philosophical ones, such as privacy and trust, especially in scenarios like smart toys. The security challenges derive from the very nature of smart objects and the use of standard protocols. Heer et al. have considered the security challenges and requirements for an IP-based IoT by analyz- ing existing Internet protocols that might be applied to the IoT and their limitations and the problems that they might introduce [102]. Garcia-Morchon et al. summarize security threats in the IoT as follows [103]: \n\n1) cloning of smart objects by unauthorized manufacturers; 2) malicious substitution of smart things during installation; 3) \ufb01rmware replacement attacks; 4) extraction of security parameters (smart things may be physically unprotected); 5) eavesdropping attacks if communication channels are not ade- quately protected; 6) man-in-the-middle attacks during key exchange; 7) routing attacks; 8) denial-of-service attacks; 9) privacy threats. \n\nThreats 1\u20134 are related to the physical nature of smart objects, which are typically deployed in public areas and cannot be constantly supervised, thus leading to potential security problems. Threats 5\u20138 are examples of security issues arising from the need for objects to communicate with each other. Finally, Threat 5.1 is related to the fact that smart objects might deal with personal or sensitive data, which, if intercepted by unauthorized parties, might create ethical and privacy problems. While it is possible to cope with issues arising from the physical nature of objects only by adopting safe supply and installation mea- sures, such as avoiding untrusted manufacturers and installers, and by trying to protect smart objects in safe places, all other security threats can be tackled by adopting means such as secure communication pro- tocols and cryptographic algorithms. These measures enforce the fol- lowing basic security properties: \n\n5.1 Security Issues in the IoT 193 \n\n\u2022 Con\ufb01dentiality: transmitted data can be read only by the communi- cation endpoints; \u2022 Availability: the communication endpoints can always be reached and cannot be made inaccessible; \u2022 Integrity: received data are not tampered with during transmission; if this does not happen, then any change can be detected; \u2022 Authenticity: data senders can always be veri\ufb01ed and data receivers cannot be spoofed. \n\nThere is an additional property of security that should always be taken into account: authorization. Authorization means that data can be accessed only by those allowed to do so; it should be unavailable to others. This aspect, which requires identi\ufb01cation of the communica- tion endpoints, is particularly relevant in those scenarios where it is necessary to ensure that private data cannot be accessed by unknown or unauthorized parties. It is a common opinion that in the near future IP will be the base common network protocol for the IoT. This does not imply that all objects will be able to run IP; there will always be tiny devices, such as tiny sensors or RFID tags that will be organized in closed networks implementing very simple and application-speci\ufb01c communication protocols and that eventually will be connected to an external network through a suitable gateway. However, it is foreseen that all other small networked objects will exploit the bene\ufb01ts of IP and the corresponding protocol suite. Bormann has tried to de\ufb01ne the classes of constrained devices, in terms of memory capacity, in order to be used as a rough indication of device capabilities [104]: \n\n\u2022 Class 1: RAM size = \u223c10 kB, Flash size = \u223c100 kB; \u2022 Class 2: RAM size = \u223c50 kB, Flash size = \u223c250 kB; \n\nSome of these networked objects, with enough memory, compu- tational power, and power supply, will simply run existing IP-based protocol suite implementations. Others will still run standard Inter- net protocols, but may bene\ufb01t from speci\ufb01c implementations that try to achieve better performance in terms of memory size, computational power, and power consumption. In other constrained networked sce- narios, smart objects may require additional protocols and some pro- tocol adaptations in order to optimize Internet communications and lower memory, computational, and power requirements. \n\n194 5 Security and Privacy in the IoT \n\nThere is currently considerable e\ufb00ort within the IETF to extend existing protocols for use in resource-constrained networked envi- ronments. Some of the current IETF working groups targeted to these environments are: \n\n\u2022 Constrained RESTful Environments (CoRE) [21]; \u2022 IPv6 over Low Power WPAN (6LoWPAN) [19]; \u2022 Routing over Low Power and Lossy Networks (ROLL) [20]; \u2022 Lightweight Implementation Guidance (LWIG) [105]. \n\nIn Figure 5.1, a typical IP-based IoT protocol stack is depicted and compared with the classical Internet protocol stack used by standard non-constrained nodes for accessing the web. At the application layer, the HTTP [2] protocol is replaced by the Constrained Application Pro- tocol (CoAP) [7], which is an application layer protocol to be used by resource-constrained devices. It o\ufb00ers a representational state trans- fer (REST) service for machine-to-machine (M2M) communications, and can be easily translated to/from HTTP. Signi\ufb01cant reasons for proper protocol optimizations and adapta- tions for resource-constrained objects can be summarized as follows: \n\n\u2022 Smart objects typically use, at the physical and link layers, com- munication protocols (such as IEEE 802.15.4) that are character- ized by small maximum transmission units, thus leading to packet \n\nInternet Internet of Things \n\nPHY Physical \n\nLink \n\nNetwork \n\nTransport \n\nApplication \n\nLayers \n\nMAC \n\nIPv6/6LowPAN \n\nMAC \n\nIP \n\nTCP UDP \n\nCoAP HTTP \n\nPHY \n\nFigure 5.1 Comparison between the IoT and the Internet protocol stack for OSI layers. \n\n5.1 Security Issues in the IoT 195 \n\nfragmentation. In this case, the use of compressed protocols can sig- ni\ufb01cantly reduce the need for packet fragmentation and postponed transmissions. \u2022 Processing larger packets likely leads to higher energy consumption, which can be a critical issue in battery-powered devices. \u2022 Minimized versions of protocols (at all layers) can reduce the num- ber of exchanged messages. \n\nProtocol compression is especially relevant when dealing with secu- rity protocols, which typically introduce higher overhead and increase the size of transmitted data packets. Besides protocol compression, cross-layer interaction between protocols plays a crucial role. This is particularly important in order to avoid useless duplication of security features, which might have a detrimental impact on the computation and transmission performance. For instance, end-to-end security can be guaranteed by adopting IPSec at the network layer or TLS/DTLS at the transport layer. Combining these two security protocols results in very expensive processing, both at the secure channel setup phase and during packet transmission/reception. Another important issue in the introduction of security protocols is interoperability. Security protocols typically allow the negotiation of some parameters to be used during operations. Such negotiations might be related to cryptographic and digital signature algorithms. In order to guarantee full interoperability among smart objects, it is necessary to de\ufb01ne a set of mandatory options, which all objects must implement for minimal support. The algorithms supported by an object are declared in a negotiation phase and a suitable choice is then agreed upon by the two communicating parties. It is not necessary that the mandatory algorithms are standard algorithms used in the Internet, but can be ones targeted for use in constrained environments. A \ufb01nal remark should be made about the heterogeneous nature of smart objects, whose characteristics can vary signi\ufb01cantly with relevant di\ufb00erences with respect to those of conventional hosts. This means that the adoption of a suite of security protocols and cryptographic algorithms is a need and a challenge at the same time. Standardization can lead to full interoperability, yet it is extremely di\ufb03cult to agree on a set of protocols and algorithms that will be supported by all devices. \n\n196 5 Security and Privacy in the IoT \n\n5.2 Security Mechanisms Overview \n\nAs mentioned in Section 5.1, one of the most important requirements and crucial aspects for a correct deployment and di\ufb00usion of IoT is security. Several challenging security goals must be achieved, includ- ing data con\ufb01dentiality, data authentication, integrity, service avail- ability, peer entity authentication, authorization, anonymity, and/or pseudonymity. Since the protocol architecture of smart objects should adhere to standard IP architecture (for obvious integration reasons), many of the security mechanisms already de\ufb01ned and currently used for the Internet can be reused in IoT scenarios. Moreover, since many Internet security protocols allow for the possibility of selecting and suitably con\ufb01guring the algorithms and other cryptographic primi- tives used, they can be reused, although possibly with suitable algo- rithmic or con\ufb01guration modi\ufb01cations. In this section, the main protocols for securing IP-based end-to-end communications between smart objects are reviewed, and the main issues related to this type of communication are discussed. Algorithms and other mechanisms actually used by these protocols are discussed in Section 5.2.2. \n\n5.2.1 Traditional vs Lightweight security \n\nAccording to the protocol stacks depicted in Figure 5.1, a direct com- parison between possible layered architectures of security protocols in Internet and IoT scenarios is shown in Figure 5.2. \n\nInternet Internet of Things \n\nPHY Physical \n\nLayers \n\nLink \n\nNetwork \n\nTransport \n\nApplication \n\nMAC \n\nIP/IPSec/HIP \n\nMAC \n\nIP/IPSec/HIP \n\nTLS DTLS \n\nCoAPs HTTPs \n\nPHY \n\nFigure 5.2 Comparison of Internet and IoT security protocols. \n\n5.2 Security Mechanisms Overview 197 \n\nThe IoT protocol suite depicted in Figure 5.2 represents only the pos- sible choices for a smart object to enforce data protection (at di\ufb00erent layers), rather than the actual set of security mechanisms e\ufb00ectively implemented and simultaneously used at di\ufb00erent layers. However, in order to minimize the used resources, particular attention has to be devoted to avoid the repetition of the same functionalities at di\ufb00erent layers, if not strictly required. Referring to the IoT protocol stack of Figure 5.2, at the applica- tion layer is the CoAP application protocol, which can be used for request/response interactions between smart objects or between a smart object and a non-constrained (standard) Internet node (possibly by using some intermediate relay/proxy node). CoAP itself does not provide primitives for authentication and data protection, so these functions should be implemented directly at the applica- tion/service layer (by directly protecting the data encapsulated and exchanged by CoAP) or at one of the underlying layers. Although data authentication, integrity, and con\ufb01dentiality can be provided at lower layers, such as PHY or MAC (e.g., in IEEE 802.15.4 systems), no end-to-end security can be guaranteed without a high level of trust on intermediate nodes. However, due to the highly dynamic nature of the wireless multi-hop communications expected to be used to form the routing path between remote end nodes, this kind of security (hop-by-hop) is not, in general, su\ufb03cient. For this reason, security mechanisms at network, transport, or application levels should be considered instead of (or in addition to) PHY- and MAC-level mechanisms. \n\n5.2.1.1 Network Layer At the network layer, an IoT node can secure data exchange in a stan- dard way by using Internet Protocol Security (IPsec) [106]. IPSec was originally developed for IPv6, but found widespread deployment, \ufb01rst, as an extension of IPv4, into which it was back-engineered. IPSec was an integral part of the base IPv6 protocol suite, but has since then been made optional. IPSec can be used in protecting data \ufb02ows between a pair of hosts (host-to-host communication), between a pair of security gateways (network-to-network communication), or between a secu- rity gateway and a host (network-to-host communication). For each IP packet, IPSec can provide con\ufb01dentiality, integrity, data-origin authentication and protection against replay attacks (it works at the network layer). Such security services are implemented \n\n198 5 Security and Privacy in the IoT \n\nby two IPSec security protocols: Authentication Header (AH) and Encapsulated Security Payload (ESP). While AH provides integrity, data-origin authentication, and optionally anti-replay capabilities, ESP can provide con\ufb01dentiality, data-origin authentication, integrity, and anti-replay capabilities. IPSec AH and ESP de\ufb01ne only the way payload data (clear or enciphered) and IPSec control information are encapsulated, while the e\ufb00ective algorithms for data origin authentication/integrity/con- \ufb01dentiality are speci\ufb01ed separately and selected from amongst a set of available cipher suites. This modularity makes IPSec usable in the presence of very resource-constrained devices, if a suitable algorithm that guarantees both usability and adequate security is selected. This means that, from an algorithmic point of view, the problem moves from the IPSec protocol itself to the actual cryptographic algorithms. Section 5.2.2 is dedicated to algorithm-related issues. The keying material and the selected cryptographic algorithms used by IPSec for securing a communication are called an IPSec Security Association (SA). To establish an SA, IPSec can be pre-con\ufb01gured (specifying a pre-shared key, hash function and encryption algorithm) or can be dynamically negotiated by the IPSec Internet Key Exchange (IKE) protocol. Unfortunately, as the IKE protocol was designed for standard Internet nodes, it uses asymmetric cryptography, which is computationally heavy for very small devices. For this reason, suitable IKE extensions using lighter algorithms should be considered. These issues are considered in Section 5.2.2. Other problems related to the implementation of IPSec in con- strained IoT nodes include data overhead (with respect to IP), con\ufb01guration, and practical implementation aspects. Data overhead is introduced by the extra header encapsulation of IPSec AH and/or ESP. However, this can be limited by implementing header com- pression techniques, similar to what is done in 6LoWPAN for the IP header. A possible compression mechanism for IPSec in 6LoWPAN has been proposed and numerically evaluated [107]. Regarding the practical aspects, it is worth noting that IPSec is often designed for VPNs, thus making it di\ufb03cult for them to be dynamically con\ufb01gurable by an application. Moreover, existing implementations are also barely compatible with each other and often require manual con\ufb01guration to interoperate. An alternative to using IKE+IPsec is the Host Identity Protocol (HIP) [108]. The main objective of HIP is to decouple the two \n\n5.2 Security Mechanisms Overview 199 \n\nfunctions of host locator (for routing purposes) and host identi\ufb01er (for actual host identi\ufb01cation) currently performed by IP addresses. For this purpose, HIP introduces a new namespace between IP and upper layers, speci\ufb01c to host identi\ufb01cation and based on public cryptography. In HIP, the host identity (HI) is directly associated with a pair of public/private keys, where the private key is owned by the host and the public key is used as the host identi\ufb01er. HIP de\ufb01nes also an host identity tag (HIT), a 128-bit representation of the HI based on the hash of the HI plus other information. This can be used, for example, as a unique host identi\ufb01er in the existing IPv6 API and by application protocols. HIP also de\ufb01nes an HIP exchange that can be used between IP hosts to establish a HIP security association, which in turn can be used to start secure host-to-host communications based on the IPSec ESP protocol [109]. In addition to security, HIP provides methods for IP multi-homing and host mobility, which are important features for an IP-based IoT network architecture. Some work is also being carried out to let the HIP exchange run on very constrained devices. The approach involves using suitable public-key cryptographic primitives, such as the ones described in Section 5.2.2. \n\n5.2.1.2 Transport Layer In the current IP architecture, data exchange between application nodes can be secured at the transport layer through standard Trans- port Layer Security (TLS) and Datagram Transport Layer Security (DTLS) protocols. TLS is the most common secure protocol, running on top of the TCP, and providing to the application layer the same connection and stream-oriented interface as TCP [110]. In addition, TLS provides complete secure communication through: \n\n\u2022 peer-entity authentication and key exchange (using asymmetric cryptography); \u2022 data authentication, integrity, and anti-replay (through message authentication code); \u2022 con\ufb01dentiality (using symmetric encryption). \n\nPeer-entity authentication and key exchange is provided by the TLS handshake phase, which is performed at the beginning of the communication. DTLS, on the other hand, was introduced more recently, in order to provide a security service similar to TLS on top of UDP [111]. \n\n200 5 Security and Privacy in the IoT \n\nAlthough it is still poorly supported in standard Internet nodes, it is currently the reference security protocol for IoT systems since it uses UDP as transport and does not su\ufb00er from the problems caused by the use of TCP in network-constrained scenarios (due to the extremely variable transmission delay and lossy links). Both IPSec and DTLS provide the same security features, but with their own mechanisms and at di\ufb00erent stack layers. Moreover, the IPSec IKE key agreement is almost the same as the DTLS handshake function. The main advantage of securing communications at the transport layer with DTLS consists in allowing more precise access control. In fact, operation at the transport layer allows applications to directly and easily select which, if any, security service has to be set up. Another practical advantage is that DTLS allows for the reuse of the wide experience gained during implementations of TLS. For these reasons DTLS has recently received signi\ufb01cant attention as a possible way of securing communication of constrained node/net- work applications and it has been standardized as the security protocol for CoAP as associated to coaps URIs [7]. Unfortunately, there are still some few issues that must be faced in order to make DTLS more friendly for constrained devices. The most important are related to the limited packet size imposed by the underlying protocols, such as IEEE 802.15.4. In fact, as for IPSec, DTLS introduces an overhead during both handshake and data transport phases. DTLS causes fragmentation in the handshake layer, and this can add a signi\ufb01cant overhead. Another solution might be to use the fragmentation o\ufb00ered at IPv6 or the 6LoWPAN layer. Moreover, in order to reduce DTLS overhead, a packet optimization and compression mechanism can be introduced. For example Raza et al. proposed using the 6LoWPAN compression mechanisms for the DTLS protocol [112]. From the security point of view, one problem of using DTLS or IPSec is that end-to-end communication is not guaranteed when intermediate nodes such as proxies or application-level gateways are introduced. In fact, both IPSec and DTLS provide secure communi- cations at IP and transport layers respectively, and, in the presence of multi-hop application-level communications, they can ensure security only within each hop. In addition, some complications in providing end-to-end security may also arise when connectivity is realized directly at IP and transport layers. There are scenarios in which a part of a network (internal) of constrained devices is interconnected at IP \n\n5.2 Security Mechanisms Overview 201 \n\nlevel to the rest of an (external) network, for example the Internet. Although data protection can be guaranteed through IPSec or DTLS protocols, other network attacks, like \ufb02ooding or replay, may occur due to the asymmetry of the resources available at the end systems; for example, a high-powered host attached to the Internet may attack a constrained device by trying to consume all of its limited power or processing resources. In order to guarantee a suitable level of protection against this kind of attack, an intermediate security gateway may be required at the border of the internal network. A security gateway may act as access controller, granting access to the internal network only to trusted nodes. Solutions to this problem have been proposed [113, 114]. In particular, in the case of end-to-end application-level communication based on CoAP, a solution may be to require the external node to encapsulate CoAP/DTLS/IP tra\ufb03c within a proper DTLS tunnel established between the external node and the security gateway. It is also important to note that, although DTLS provides a datagram-oriented communication service (like UDP), it estab- lishes a point-to-point secure association that is not compatible with multicast communications (in contrast to UDP, which does support multicast). In order to make DTLS applicable in multicast IP-communication scenarios, some protocol extensions for group-key management will be needed in the future. \n\n5.2.1.3 Application Layer Providing security at the IP layer (through IPSec) or the transport layer (through TLS or DTLS) has several advantages. The main ones are: \n\n\u2022 The same standard mechanism and the same implementation can be shared by all applications, resulting in code reuse and reduced code size. \u2022 Programmers do not have to deal with the implementation of any security mechanism; this signi\ufb01cantly simpli\ufb01es the development of applications when secure communications are required. \n\nUnfortunately, as already described, both IPSec and (D)TLS have their own drawbacks. Probably the main one, common to both IP and trans- port approaches, is the impossibility to ensure complete end-to-end security when application communications are relayed by intermedi- ate nodes that work at application level (e.g., proxies). In this case, end-to-end security can be still provided with transport- or IP-level \n\n202 5 Security and Privacy in the IoT \n\nmechanisms, but only in the presence of very trusted intermediate sys- tems. However, in this case, the overall security is complicated by the handling of such hop-by-hop trust management. A di\ufb00erent approach to providing complete end-to-end security is to enforce security directly at the application level. This of course simpli\ufb01es the requirements for underlying layers, and probably reduces the cost, in term of packet size and data processing, since only application data have to be secured, and only per-data and not per-packet overhead is introduced. Moreover, multicast com- munication and in-network data aggregation in encrypted domains (for example through homomorphic cryptography) are easier to implement at application level. The main disadvantages of providing security at application level are the complications introduced for application development and the overall code size caused by poor reuse of software code. This is mainly due to the lack of well-de\ufb01ned and adopted secure protocols at appli- cation level. Examples of standards that can be used for this purpose are S/MIME and SRTP. S/MIME (Secure/Multipurpose Internet Mail Extensions) [115] is a standard for providing authentication, message integrity, non-repudiation of origin, and con\ufb01dentiality for application data. Although S/MIME was originally developed for securing MIME data between mail user agents, it is not restricted to mail and can be used for securing any application data and can be encapsulated within any application and transport protocol. SRTP (Secure Real-time Transport Protocol) [116] is another secure communication protocol that provides con\ufb01dentiality, message authentication, and replay protection to application data. It is an extension of the Real-time Transport Protocol (RTP) speci\ufb01cally developed for handling real-time data communications (e.g., voice or video communication), but can also be re-used in other application scenarios. It works in a per-packet fashion and is usually encapsulated in UDP. More investigation is required to state which is the standard protocol most suitable for securing data at application layer in network- and node-constrained scenarios such as the IoT. \n\n5.2.2 Lightweight Cryptography \n\nThe development of the IoT will result in the deployment of billions of smart objects that will interact with the existing Internet. Smart \n\n5.2 Security Mechanisms Overview 203 \n\nobjects are tiny computing devices, with constrained resources: low computation capabilities, little memory, and limited battery lives. Communication with smart objects in resource-constrained envi- ronments must necessarily take into account these hard limitations, especially in scenarios where security is crucial and conventional cryptographic primitives, such as the Advanced Encryption Standard (AES) [117], are inadequate. Lightweight cryptography (LWC) is a very interesting research area, aiming at the design of new ciphers that might meet the requirements of smart objects [118]. The term \u201clightweight\u201d should not be mistaken as meaning \u201cweak\u201d (in terms of cryptographic protection), but should instead be interpreted as referring to a family of cryptographic algorithms with smaller footprint, lower energy consumption, and low computational power needs. These ciphers aim at providing su\ufb03cient security in the environment of restricted resources that is encountered in many ubiquitous devices [119]. LWC thus represents a cryptography tailored to constrained devices, which must cope with the trade-o\ufb00s between security level, cost, and performance. In this section, an overview of the most prominent cryptographic algorithms is presented, followed by a comparison of lightweight cryptographic primitives and conventional ones, such as AES, which are currently adopted in standard Internet security protocols, such as IPSec and TLS. Symmetric ciphers for lightweight cryptography are presented \ufb01rst, followed by asymmetric ciphers and then crypto- graphic hash functions. Finally, privacy homomorphism is discussed. We note that this overview is not meant to be detailed or extensive, but aims at pointing out which encryption algorithms are most suitable for practical implementation in IoT scenarios. \n\n5.2.2.1 Symmetric-key LWC Algorithms Symmetric-key cryptographic algorithms use the same key for encryption of a plaintext and decryption of a ciphertext. The encryp- tion key represents a shared secret between the parties that are involved in the secure communication. An illustrative representation of symmetric-key secure communication is shown in Figure 5.3. Symmetric-key encryption can use either block ciphers or stream ciphers: \n\n\u2022 Block ciphers operate on \ufb01xed-length groups of bits, called blocks, padding the plaintext to make its length equal to a multiple of the block size. An example is the AES algorithm. \n\n204 5 Security and Privacy in the IoT \n\nm \n\nm c \n\nc \n\nk \n\nDk{c} \n\nEk{m} \n\nFigure 5.3 Secure communication with symmetric-key cryptographic algorithms. \n\n\u2022 In stream ciphers the digits of a plaintext are encrypted one at a time with the corresponding digit of a pseudorandom cipher digit stream (keystream). \n\nTiny Encryption Algorithm The Tiny Encryption Algorithm (TEA) is a block cipher renowned for its simplicity of description and implementation; typically a few lines of code [120]. TEA operates on two 32-bit unsigned integers (which could be derived from a 64-bit data block) and uses a 128-bit key. TEA relies only on arithmetic operations on 32-bit words and uses only addition, XORing, and shifts. TEA uses a large number of iterations, rather than a complicated program, in order to avoid preset tables and long setup times. The main design goal of TEA is to de\ufb01ne a simple and short cipher that does not rely on preset tables or pre-computations, thus leading to a smaller footprint. TEA has been revised in order to \ufb01x some weaknesses found in the original algorithm, such as the problem of equivalent keys, which reduced the actual key size from 128 to 126 bits. The redesign of TEA, named XTEA (extended TEA) [121], \ufb01xes this problem by changing the key schedule. XTEA also requires two fewer additions, thus resulting in a slightly faster algorithm. Other modi\ufb01cations of the TEA algorithm have been presented, such as XXTEA, block TEA, speed TEA, and tiny XTEA. As the TEA family uses exclusively very simple operations and has a very small code size, it is an ideal candidate as a cryptographic algorithm for implementing security mechanisms in smart objects and wireless sensors. \n\n5.2 Security Mechanisms Overview 205 \n\nScalable Encryption Algorithm The Scalable Encryption Algorithm (SEA) is targeted at small embed- ded applications [122]. The design considers a context with very limited processing resources and throughput requirements. Another design principle of SEA is \ufb02exibility: the plaintext size n, key size n, and processor (or word) size b are design parameters, with the only constraint that n is a multiple of 6b; for this reason, the algorithm is denoted as SEAn,b. The motivation of this \ufb02exibility is the observation that many encryption algorithms perform di\ufb00erently depending on the platform, e.g., 8-bit or 32-bit processors. SEAn,b is designed to be generic and adaptable to di\ufb00erent security levels (by varying the key size) and target hardware. A great advantage of SEAn,b is the \u201con-the-\ufb02y\u201d key derivation. The main disadvantage is that SEAn,b trades space for time and this may not be negligible on devices with limited computational power. \n\nPRESENT Cipher PRESENT is an ultra-lightweight block cipher algorithm based on a substitution-permutation network [123]. PRESENT has been designed to be extremely compact and e\ufb03cient in hardware. It operates on 64-bit blocks and with keys of either 80 or 128 bits. It is intended to be used in situations where low-power consumption and high chip e\ufb03ciency are desired, thus making it of particular interest for constrained environments. The main design goal of PRESENT is, as for the other lightweight ciphers, simplicity. PRESENT is performed in 31 rounds, each comprising three stages: \n\n\u2022 key-mixing, through XOR operation and a 61-bit rotation key schedule; \u2022 substitution layer, through 16 4-bit (input) by 4-bit (output) S-boxes; \u2022 permutation layer. \n\nAt the end of the 31st round, an additional round is performed by XORing the last-round subkey. ISO/IEC 29192-2:2012 Lightweight Cryptography names PRESENT as a block cipher suitable for lightweight cryptography [124]. \n\nHIGHT The HIGh security and lightweigHT (HIGHT) encryption algorithm is a generalized Feistel network with a block size of 64 bits, 128-bit keys and 32 rounds [125]. HIGHT was designed with an eye on \n\n206 5 Security and Privacy in the IoT \n\nlow-resource hardware performance. HIGHT uses very simple operations, such as XORing, addition mod 28, and bitwise rotation. The key schedule in HIGHT is designed so that subkeys are generated on the \ufb02y both in the encryption and the decryption phases. \n\nComparison of Symmetric LWC Algorithms LWC algorithms are not intended to supersede existing ciphers, such as AES, for widespread use. Their application is limited to those scenarios where classical ciphers might be ine\ufb03cient, such as scenarios where: \n\n\u2022 a moderate security level is required, so that keys need not be too long; \u2022 encryption should not be applied to large amounts of data; \u2022 the hardware area needed for implementation and the power con- sumption are considered harder requirements than speed. \n\nFor constrained devices, the choice of the cryptographic algorithm is a primary element that can a\ufb00ect performance. When low cost and energy consumption are hard requirements, computational power must inherently be downsized accordingly. Using 8-bit microcon- trollers (such as Atmel AVR microcontrollers [126]), which have limited capabilities in terms of computing power, memory, and storage, requires that implemented ciphers have small footprints and are kept simple. This may result in faster execution and thus in lower energy consumption, which may be critical for battery-powered devices. Although most symmetric cryptographic algorithms have been developed with a focus on e\ufb03cient software implementations, the deployment of smart objects will lead to an increasing attention being given to those ciphers that will perform well in hardware in terms of speed and energy consumption. In Table 5.1, we report a direct com- parison of the LWC algorithms outlined in Subsection 5.2.2.1 [118], with particular reference to the following metrics: key size, block size, rounds, consumed area measured in gate equivalents (GEs), and code size (in bytes). Reported values for gate equivalents are related to hardware implementations, while code size refers to software implementations. \n\n5.2.2.2 Public-key (Asymmetric) LWC Algorithms Public-key (asymmetric) cryptography requires the use of a public key and a private key. Public keys can be associated with the identity of a \n\nTable 5.1 Comparison of di\ufb00erent symmetric-key cryptographic algorithms. \n\nCipher Key size Block size Rounds GE Code size \n\n(hardware impl.) (software impl.) \n\n(bits) (bits) (bytes) \n\nSoftware ciphers AES 128 128 10 3400 [127, 128] 2606 \n\nTEA 128 64 32 3490 [129] 1140 \n\n3758 a)[130] \n\nSEA96,8 96 8 \u22653n\u22154 3925 b)[130] 2132 \n\n2547 [131] \n\nHardware ciphers PRESENT 80 64 32 1570 [123] 936 \n\nHIGHT 128 64 32 3048 [125] 5672 \n\na) Round-based implementation with datapath of size n b) Serialized implementation with datapath of size b. \n\n208 5 Security and Privacy in the IoT \n\nnode by including them in a public certi\ufb01cate, signed by a certi\ufb01cation authority, which can be asked to verify the certi\ufb01cate. Public-key cryptography requires a signi\ufb01cant e\ufb00ort to deploy a public-key infrastructure. Moreover, asymmetric cryptography requires higher processing and long keys (at least 1024 bits for RSA [132]). Alter- native public-key cryptographic schemes, such as elliptic curve cryptography [133], might require shorter keys to be used in order to achieve the same security as RSA keys. However, because of this, symmetric cryptography is preferred in terms of processing speed, computational e\ufb00ort, and size of transmitted messages. Public-key ciphers are usually used to set up symmetric keys to be used in subsequent communications. \n\nRSA Algorithm The Rivest, Shamir, and Adleman (RSA) algorithm is the best known and widely used public-key scheme. It is based on exponentiation in a \ufb01nite \ufb01eld over integers modulo N. Consider a modulus N and a pair of public and private keys (e, d). The encryption of a message m is given by c = me mod N, while the decryption is m = cd mod N. The key generation phase of RSA, aiming to generate the public\u2013private key pair, consists of the following steps: \n\n1) Select two large prime numbers denoted as p and q such that p \u2260q. 2) Compute n = p \u22c5q. 3) Compute the Euler\u2019s totient function \u03a6(n) = (p \u22121) \u22c5(q \u22121). 4) Choose an integer e such that 1 < e < \u03a6(n) and that the GCD(e,\u03a6(n)) = 1. 5) Compute d = e\u22121mod \u03a6(n). \n\nThe pair (n, e) is the public key, while d is the private key. The security of the RSA algorithm depends on the hard problem of factorizing large integers. In order to achieve an acceptable level of security, n should be at least 1024 bits long, so that p and q, and con- sequently \u03a6(n), cannot be obtained, thus protecting the (e, d) pair. RSA is unsuitable for adoption in constrained devices due to the need to operate on large numbers and the fact that long keys are required to achieve su\ufb03cient security. Moreover, both key generation and encryption/decryption are demanding procedures that result in higher energy consumption. \n\n5.2 Security Mechanisms Overview 209 \n\nElliptic Curve Cryptography Elliptic curve cryptography (ECC) is an approach to public-key cryptography based on the algebraic structure of elliptic curves over \ufb01nite \ufb01elds. While RSA is based on exponentiation on \ufb01nite \ufb01elds, ECC depends on point multiplication on elliptic curves. An elliptic curve E over the \ufb01nite \ufb01eld K (whose characteristic is not equal to 2 and 3) is de\ufb01ned as: \n\nE(K) \u2236y2 = x3 + ax + b with a, b \u2208K \n\nPoints P = (x, y) \u2208E(K) form an Abelian group, so point addition and scalar point multiplication can be performed. ECC provides higher security and a better performance than the \ufb01rst-generation public-key techniques, RSA and Di\ufb03e\u2013Hellman. Moreover, ECC is the most interesting public-key cryptographic fam- ily for embedded environments because it can reach the same security level as RSA with much shorter keys, as shown in Table 5.2, and with computationally lighter operations, like addition and multiplication, rather than exponentiation. ECC has been accepted commercially and has also been adopted by standards institutions such as the American National Standards Institute (ANSI), the Institute of Electrical and Electronics Engineers (IEEE), the International Organization for Standardization (ISO), the Standards for E\ufb03cient Cryptography Group (SECG), and the National Institute of Standards and Technology (NIST) [134\u2013138]. The implementation of a lightweight hardware ECC processor for constrained devices is attracting growing interest. A possible hard- ware implementation of a low-area, standalone, public-key engine for ECC, with a 113-bit binary \ufb01eld for short-term security and a 193-bit \n\nTable 5.2 Comparison of security levels for symmetric ciphers, ECC, and RSA (recommended NIST key sizes). \n\nSymmetric key size (bits) 80 112 128 192 256 \n\nECC key size (bits) 160 224 256 384 512 \n\nRSA key size (bits) 1024 2048 3072 7680 15360 \n\nSource: http://www.nsa.gov/business/programs/elliptic_curve .shtml \n\n210 5 Security and Privacy in the IoT \n\nbinary \ufb01eld for medium-term security, has been demonstrated [118]. The choice of a binary \ufb01eld, rather than a prime \ufb01eld, is related to the corresponding carry-free arithmetic, which \ufb01ts well in hardware implementations. With respect to other ECC hardware implementa- tions, the one presented uses a smaller area (in terms of GEs) and exhibits faster execution. \n\nPerformance Comparison of Public-key Cryptographic Algorithms Here we review the performance results [139] for implementations of RSA and ECC public-key algorithms, such as TinyECC and Wiselib, against benchmarks obtained in constrained devices (namely an 8-bit Arduino Uno board). Table 5.4 shows the implementation results for RSA public-key encryption, when the private key is held in SRAM or in ROM. In Table 5.5, the performance of ECDSA signature algorithms in TinyECC and Wiselib implementations is compared. A comparison of the ROM footprints is shown in Table 5.3. \n\n5.2.2.3 Lightweight Cryptographic Hash Functions Cryptographic hash functions, such as MD5 [140] and SHA-1 [141], are an essential part of any protocol that uses cryptography. Hash func- tions are used for di\ufb00erent purposes, such as message integrity check, \n\nTable 5.3 Public-key encryption library ROM occupancy. \n\nLibrary AvrCryptolib Wiselib TinyECC Relic-toolkit \n\nROM footprint (kB) 3.6 16 18 29 \n\nTable 5.4 RSA private key operation performance. \n\nKey length (bits) Execution time (ms) Memory footprint (bytes) \n\nKey in SRAM Key in ROM Key in SRAM Key in ROM \n\n64 66 70 40 32 \n\n128 124 459 80 64 \n\n512 25089 27348 320 256 \n\n1024 109666 218367 640 512 \n\n2048 1587559 1740267 1280 104 \n\n5.2 Security Mechanisms Overview 211 \n\nTable 5.5 ECDSA signature performance: TinyECC versus Wiselib implementations. \n\nCurve parameters Execution time (ms) Memory footprint (bytes) Comparable RSA key length \n\nTinyECC Wiselib TinyECC Wiselib \n\n128r1 1858 10774 776 732 704 \n\n128r2 2002 10615 776 732 704 \n\n160k1 2228 20164 892 842 1024 \n\n160r1 2250 20231 892 842 1024 \n\n160r2 2467 20231 892 842 1024 \n\n192k1 3425 34486 1008 952 1536 \n\n192r1 3578 34558 1008 952 1536 \n\ndigital signatures, and \ufb01ngerprinting. Cryptographic hash functions should ideally be: \n\n\u2022 computationally inexpensive; \u2022 pre-image resistant: given a hash h, it should be di\ufb03cult to invert the hash function in order to obtain the message m such that h = hash(m); \u2022 second pre-image resistant: given a message m1, it should be di\ufb03cult to \ufb01nd another message m2 such that hash(m1) = hash(m2); \u2022 collision resistant: it should be di\ufb03cult to \ufb01nd two messages m1 and m2, with m1 \u2260m2, such that hash(m1) = hash(m2) (hash collision). \n\nIn general, for a hash function with n-bit output, pre-image and second pre-image resistance require 2n operations, while collision resistance requires 2n\u22152 operations [142]. While the design of standard cryptographic hash functions does not focus on hardware e\ufb03ciency, lightweight cryptographic hash functions are needed for use in resource-constrained devices in order to minimize the amount of hardware (in terms of GEs) and energy consumption. In this subsection, we will overview some proposals for lightweight cryptographic hash functions that go beyond the classical MD and SHA families. \n\nDM-PRESENT and H-PRESENT Bogdanov et al. have proposed DM-PRESENT and H-PRESENT, two lightweight hash functions based on the PRESENT block cipher [142]. \n\n212 5 Security and Privacy in the IoT \n\nDM-PRESENT is a 64-bit hash function and comes in two versions: DM-PRESENT-80 and DM-PRESENT-128, depending on which cipher (PRESENT-80 or PRESENT-128) is used. H-PRESENT (namely H-PRESENT-128) is a 128-bit hash function based on the PRESENT-128 block cipher. In their work, the authors also consid- ered the problem of constructing longer hash functions based on the PRESENT block cipher in order to improve the security level. \n\nPHOTON PHOTON [143] is a hardware-oriented family of cryptographic hash functions designed for constrained devices. PHOTON uses a sponge-like construction [144] as domain extension algorithm and an AES-like primitive as an internal unkeyed permutation. A PHOTON instance is de\ufb01ned by its output size (64 \u2264n \u2264256), its input rate r, and its ouptut rate r\u2032 (PHOTON-n\u2215r\u2215r\u2032). The use of a sponge function framework aims at keeping the internal memory usage low. The framework has been extended in order to increase speed when hashing small messages, which is typically ine\ufb03cient in a sponge function framework. \n\nSPONGENT SPONGENT [145] is a family of lightweight hash functions with out- puts of 88, 128, 160, 224, and 256 bits. SPONGENT is based on a sponge construction with a PRESENT-type permutation. An instance of SPONGENT is de\ufb01ned by the output size n, the rate r, and the capacity c (SPONGENT-n\u2215c\u2215r). The size of the internal state, denoted as width, is b = r + c \u2265n. Implementations in ASIC hardware require 738, 1060, 1329, 1728, and 1950 GEs, respectively, making it the hash function with the smallest footprint in hardware. The 88-bit hash size is used only to achieve pre-image resistance. \n\nQUARK The QUARK [146] hash family comes with three instances: U-QUARK, D-QUARK, and S-QUARK, with hash sizes of 136, 176, and 256 bits, respectively. QUARK, like PHOTON and SPONGENT, is based on a sponge construction. The QUARK hash family is optimized for hardware implementation and, as stated by the authors, software implementations should instead rely on other designs. QUARK has a bigger footprint than PHOTON and SPONGENT, but shows higher throughput than SPONGENT and better security than PHOTON. \n\n5.2 Security Mechanisms Overview 213 \n\nKeccak Keccak [147] is a family of sponge functions. Keccak uses a sponge construction in which message blocks are XORed into the initial bits of the state, which is then invertibly permuted. In the version used in Keccak, the state consists of a 5\u00d75 array of 64-bit words: 1600 bits in total. Keccak produces an arbitrary output length. Keccak was selected by the NIST as the winner of the SHA-3 com- petition [148] on October 2, 2012. Since that time it has been referred to as SHA-3. \n\nSQUASH SQUASH (SQUare-hASH) [149] is suited to challenge-response MAC applications in constrained devices, such as RFID tags. SQUASH is completely deterministic, so it requires no internal source of randomness. SQUASH o\ufb00ers 64-bit pre-image resistance. SQUASH is not collision resistant, but this is not an issue since it targets RFID authentication protocols, where collision resistance is not needed. If collision resistance is a requirement, for instance for digital signatures, SQUASH is unsuitable and other hash functions should be considered. \n\n5.2.2.4 Homomorphic Encryption Schemes Homomorphic encryption is a form of encryption that allows speci\ufb01c types of computation to be executed on ciphertexts to give an encrypted result that is the ciphertext of the result of operations performed on the plaintext. By denoting E{\u22c5} as the homomorphic encryption function and f (\u22c5) as the computation function, it holds that: \n\nE{f (a, b)} = f (E{a}, E{b}) \n\nAn example of homomorphic encryption is the RSA algorithm. Con- sider a modulus N and an exponent e. The encryption of a message m is given by E{m} = memod N. The homomorphic property holds, since: \n\nE{m1 \u22c5m2} = (m1 \u22c5m2)e \n\nmod N = (m1)e mod N \u22c5(m2)e mod N = E{m1} \u22c5E{m2} \n\nOther examples of homomorphic encryption schemes are the ECC encryption [133], the ElGamal cryptosystem [150] and the Pailler cryptosystem [151]. \n\n214 5 Security and Privacy in the IoT \n\nHomomorphic encryption is receiving a growing interest for appli- cation in IoT scenarios, since it could be used to preserve con\ufb01dential- ity among the endpoints of communication, while making it possible for intermediate nodes to process information without the need to decrypt the data prior to processing. Homomorphic cryptosystems usually require higher levels of computation and need longer keys to achieve a comparable security level than symmetric-key algorithms. Depending on the operation f (\u22c5) that can be performed on the encrypted data, the homomorphic encryption scheme can be de\ufb01ned as additive or multiplicative. Additive homomorphism makes it possible to compute sums, subtractions, and scalar mul- tiplication of its operands; multiplicative homomorphism allows computation of the product of its operands. The RSA algorithm is an example of multiplicative homomorphic encryption. An example of additive homomorphic encryption is the Pailler cryptosystem. Given a modulus n, a shared random integer g, and user-generated random integers r1 and r2, the homomorphic property is: \n\nE{m1} \u22c5E{m2} = (gm1rn 1 mod n2) \u22c5(gm2rn 2 mod n2) \n\n= (gm1+m2)(r1r2)n mod n2 = E{m1 + m2} \n\nHomomorphic encryption schemes that are either additive or mul- tiplicative are termed \u201cpartially homomorphic\u201d. If both addition and multiplication are supported, a cryptosystem is called \u201cfully homomorphic\u201d. Fully homomorphic cryptosystems preserve the ring structure of the plaintexts and, therefore, enable more complex proce- dures to be used. The investigation of fully homomorphic encryption schemes is still in its early stages and no practical scheme with acceptable performance has been found (e.g., in terms of decryption delay). Application of these schemes to IoT scenarios is a rich research topic. \n\n5.2.3 Key Agreement, Distribution, and Security Bootstrapping \n\nKey distribution and management is a crucial issue that needs to be addressed when security mechanisms have to be adopted. Key agreement protocols have been around for years: the Di\ufb03e\u2013Hellman key exchange protocol is an example of a key agreement protocol that two parties perform in order to setup a shared key to be used in a ses- sion [152]. Other mechanisms have been de\ufb01ned and implemented. \n\n5.2 Security Mechanisms Overview 215 \n\nThe Internet Key Exchange (IKE) [153] protocol is a the protocol de\ufb01ned to setup a secure association to be used in IPSec. \n\n5.2.3.1 Key Agreement Protocols Asymmetric (public-key) cryptographic algorithms are often the basis for key agreement protocols, although other techniques that do not involve the adoption of asymmetric cryptography have been proposed. A polynomial-based key pre-distribution protocol has been de\ufb01ned [154] and applied to wireless sensor networks (WSNs) [155]. A possible alternative key agreement protocol is SPINS [156], which is a security architecture speci\ufb01cally designed for sensor networks. In SPINS, each sensor node shares a secret key with a base station, which is used as a trusted third-party to set up a new key, thus avoiding use of public-key cryptography. Chan et al. have presented three e\ufb03cient random key pre-distribution schemes for solving the security bootstrapping problem in resource-constrained sensor networks, each of which represents a di\ufb00erent tradeo\ufb00in the design space of random key protocols [157]. \n\n5.2.3.2 Shared Group-key Distribution The mechanisms just described apply to scenarios in which com- munication occurs between two parties (unicast and point-to-point communications). In other communication scenarios, such as point- to-multipoint (multicast) or multipoint-to-point communications, other mechanisms must be used. In such scenarios, the adoption of a shared group key is appealing. Secure group communications ensure con\ufb01dentiality, authenticity, and integrity of messages exchanged within a group through the use of suitable cryptographic services and without interfering with the communication data path. In order to achieve secure group commu- nication, nodes must share some cryptographic material that must be handled in a way that allows any group membership changes, both predictable and unpredictable, to be managed. In fact, any member- ship change should trigger a rekeying operation, which updates and redistributes the cryptographic material to the group members. This ensures that: \n\n\u2022 a former member of the groups cannot access current communica- tions (\u201cforward secrecy\u201d) [158]; \u2022 a new member cannot access previous communication (\u201cbackward secrecy\u201d [159]). \n\n216 5 Security and Privacy in the IoT \n\nKeoh [160] de\ufb01ne an approach, based on DTLS records, to secure mul- ticast communication in lossy low-power networks. Assuming that the cryptographic primitives used cannot be broken by an attacker with limited computational power (i.e., for whom it is infeasible to carry out a brute force attack in order to solve the prob- lems behind cryptographic schemes, such as discrete logarithms, or inverting MD5/SHA-1), the main challenge is the distribution of the group keys and their updates: this problem is referred to as group-key distribution, and can be tackled according to two di\ufb00erent approaches: \n\n\u2022 current communications can be deciphered independently of pre- vious communications (stateless receivers): this approach is called \u201cbroadcast encryption\u201d [161, 162]; \u2022 users maintain state of the past cryptographic material (stateful receivers): this approach is termed \u201cmulticast key distribu- tion\u201d [163]. \n\nIn multicast key distribution, centralized [164] or distributed [165] approaches can be adopted. In the distributed approach, the group key is computed and maintained by the group members themselves. An example of a distributed approach is the Tree-based Group Di\ufb03e\u2013Hellman protocol [166]. In a centralized approach, the task of key distribution is assigned to a single entity, called the key distribution center (KDC). This approach gives a simple mechanism with a minimal number of exchanged messages. Logical key hierarchy (LKH) [158] and MARKS [167] are key distribution protocols that try to optimize the number of exchanged messages between a KDC and the group members. LKH is based on key graphs, where keys are arranged into a hierarchy and the KDC maintains all the keys. MARKS is a scalable approach and does not need any update message when members join or leave the group predictably. However, MARKS does not address the issue of member eviction and subsequent key revocation. \n\n5.2.3.3 Security Bootstrapping All key agreement protocols require that some credentials, either public/private key pairs, symmetric keys, certi\ufb01cates, or others, have been installed and con\ufb01gured on nodes beforehand, so that the key agreement procedure can occur securely. Bootstrapping refers to the processing operations required before the network can operate: this requires that proper setup, ranging from link layer to application layer \n\n5.2 Security Mechanisms Overview 217 \n\ninformation, must take place on the nodes. Bootstrapping is a very important phase in the lifecycle of smart objects and can a\ufb00ect the way they behave in operational conditions. Even though the boot- strapping phase is outside the scope of this chapter, it is important to consider security bootstrapping mechanisms and architectures [168], so that possible threats, such as cloning or malicious substitution of objects, can be tackled properly. Jennings provides a sketch of a possible protocol to allow constrained devices to securely bootstrap into a system that uses them [169]. \n\n5.2.4 Processing Data in the Encrypted Domain: Secure Data Aggregation \n\nIn-network data aggregation in WSNs involves executing certain operations (such as sums and averages) at intermediate nodes in order to minimize the number of transmitted messages and the processing load at intermediate nodes, so that only signi\ufb01cant information is passed along in the network. This leads to several bene\ufb01ts, such as energy savings, which are crucial for constrained environments, such as low-power and lossy networks. Data aggregation refers to a multipoint-to-point communication scenario that requires inter- mediate nodes to operate on received data and forward the output of a suitable function applied to such input data. In such scenarios, where privacy of transmitted data is an issue, it might be necessary to send encrypted data. Encryption can be adopted not only to achieve con\ufb01dentiality, but also to verify the authenticity and integrity of messages. While secure data aggregation is certainly also an application-related issue in WSNs, optimized communication can also have other positive impacts in some IoT scenarios. For example, in smart parking or crit- ical infrastructure scenarios, there could be bene\ufb01ts from minimizing transmitted data, possibly by adopting the privacy homomorphism algorithms discussed in Section 5.2.2. A simple aggregation strategy is to queue the payloads of the received packets and send out only one packet with all the infor- mation. This approach can bring only limited gains, since only the payloads are considered. Another, more e\ufb03cient, approach can be used if the aggregator is aware of the type of operation that the \ufb01nal recipient is willing to perform. Consider a scenario where a node is interested in counting all the nodes in the network. Nodes send a \n\n218 5 Security and Privacy in the IoT \n\nad3 = f(ad1,ad2) \n\nad2 = f(d4,d5) ad1 = f(d1,d2,d3) \n\nd1 \n\nd3 d4 \n\nd5 \n\nData aggregator1 \n\nData aggregator3 \n\nData aggregator2 \n\nNode3 \n\nNode2 \n\nNode1 \n\nNode4 \n\nNode5 \n\nd2 \n\nFigure 5.4 In-network data aggregation. \n\npacket with \u201c1\u201d as the content. Aggregators receive these packets and can just sum the 1s received and send out one packet of the same size, whose content is the number of 1s received. By doing this, the information sent across the network is minimal and the \ufb01nal recipient only performs simple processing. Typically, secure data aggregation mechanisms require nodes to per- form the following operations: \n\n1) At the transmitting node, prior to transmission, data are encrypted with some cryptographic function E. 2) At the receiving node, all received data packets are decrypted with the inverse cryptographic function D = E\u22121 to retrieve the original data. 3) Data are aggregated with an aggregation function. 4) Prior to retransmission, aggregated data are encrypted through E and relayed to the next hop. \n\nThis process is iterated at intermediate nodes until the data reach the destination node that is interested in receiving the result of aggrega- tion, as shown in Figure 5.4. Both symmetric and asymmetric crypto- graphic schemes can be applied. The aggregation procedure just outlined raises the following issues, especially if we consider a scenario where the aggregators are not spe- cial nodes, but have the same features as other nodes in the network: \n\n\u2022 Aggregators must decrypt each incoming piece of information before processing in order to perform the aggregation and, sub- sequently, encrypt the result before transmission to the next hop. This has clearly an impact on the computation and, therefore, on the energy consumption of the aggregator. \u2022 An aggregator must keep a secure association (i.e., share a symmet- ric key) with any node that either sends data to or receives data \n\n5.2 Security Mechanisms Overview 219 \n\nfrom it. This further introduces the need for increased complexity at the aggregator. \u2022 Intermediate aggregators access the data that they receive, even though they are not intended to do so, since the actual recipient of the data is another node. This might introduce privacy concerns, especially in scenarios where intermediate nodes might not have a trust relationship with the sender. \n\nIn order to cope with the problems sketched above, various actions can be considered. All these issues can be addressed by using homomorphic encryption schemes, as introduced in Section 5.2.2.4. Homomorphic encryption can be used to avoid the need to decrypt the information that must be aggregated and then encrypt the result; it is possible to operate on the encrypted data directly. This can dra- matically increase the performance, in terms of execution time and energy savings, since the encryption/decryption operations are typi- cally computationally demanding. Besides computational and energy e\ufb03ciencies, a positive side e\ufb00ect of the adoption of homomorphic encryption is the fact that only the sources and the \ufb01nal destination of the data are capable of accessing the real data, thus preserving \u201cend-to-end\u201d con\ufb01dentiality for the aggregation application scenario. Additional security can be introduced by using probabilistic cryp- tosystems, such as the Pailler cryptosystem. In this case, given two encrypted values, it is not possible to decide whether they conceal the same value or not. This is especially useful to prevent eavesdroppers determining the content of a secure communication just by observing the encrypted packets. \n\n5.2.5 Authorization Mechanisms for Secure IoT Services \n\nAuthorization mechanisms should be considered when deploying IoT services, in order to tackle the concerns that deployment of smart objects and services relying on them might raise in the minds of the public. In particular, authorization mechanisms must address the following questions: \n\n\u2022 Which users can access some given data? \u2022 How should the information be presented to a given user? \u2022 Which operations is a user allowed to perform? \n\nRole-based access control (RBAC) and attribute-based access control (ABAC) are the most common approaches to restricting \n\n220 5 Security and Privacy in the IoT \n\nsystem access to authorized users. RBAC maps permissions to roles that a user has been assigned. On the other hand, ABAC maps permissions to attributes of the user. However, authorization mecha- nisms strongly depend on an authentication step that must have been previously taken, in order to identify users. As an example, a complex, context-aware access control system designed for a medical sensor networks scenario, which has critical privacy and con\ufb01dentiality issues, has been described by Garcia-Morchon and Wehrl [170]. Popular Internet-based services, such as social networks, have already faced the need to solve privacy-related problems when dealing with personal and protected data that might be accessed by third-parties; IoT applications are going to be facing the same issues. Since IoT services are expected to be o\ufb00ered in a RESTful paradigm, like those cited above, it may be helpful to borrow ideas from the experience that has been already created with Internet REST services. The OAuth (Open Authorization) protocol was de\ufb01ned to solve the problem of allowing authorized third parties to access personal user data [171]. The OAuth protocol de\ufb01nes the following three roles. \n\n\u2022 Resource owner: an entity capable of granting access to a protected resource, such as an end-user. \u2022 Resource server (a service provider, SP): a server hosting user-related information. \u2022 Client (a service sonsumer, SC): a third-party wanting to access per- sonal user data to reach its goals. \n\nAn additional role is an authorization server (AS), which issues access tokens to the client after obtaining authorization from the resource owner. In a general scenario, a SC that has been previously authorized by a user, can access the data that the user has made visible to the SC. This can be achieved by letting the SC retrieve the data from the SP on the user\u2019s behalf. In order to do so, one possible approach could be to force the user to give out personal authentication credentials to the SC. This approach has many drawbacks: \n\n\u2022 the SC is going to appear to the SP just like the actual user, thus having unlimited access to the user\u2019s personal data; \u2022 the user cannot de\ufb01ne di\ufb00erent restrictions for di\ufb00erent SCs; \u2022 the user cannot revoke the grant to a SC, unless it changes its cre- dentials. \n\n5.2 Security Mechanisms Overview 221 \n\nClient Authorization Server \n\nResource Owner \n\nResource Server 6 \n\n5 \n\n3 \n\n4 \n\n2 \n\n1 \n\nAuthorization Grant \n\nAuthorization Grant \n\nAuthorization Request \n\nAccess Token \n\nAccess Token \n\nProtected Resource \n\nFigure 5.5 Interaction between the four roles of the OAuth protocol \ufb02ow. \n\nIt is thus necessary to provide a mechanism that can separate the dif- ferent roles. This can be done by granting speci\ufb01c credentials to the SC, which they can exhibit to the SP. These contain information about the SC\u2019s identity and the user\u2019s identity, so that the SP can serve its requests according to the access policies that the user has de\ufb01ned for the SC. The OAuth protocol de\ufb01nes the mechanisms that are needed to grant, use, and verify these credentials, which are called \u201caccess tokens\u201d. The OAuth protocol de\ufb01nes the following \ufb02ow of interaction between the four roles introduced above, as illustrated in Figure 5.5. \n\n1) The client requests authorization from the resource owner: the authorization request can be made directly to the resource owner or, preferably, indirectly via the AS as an intermediary. 2) The client receives an authorization grant, which is a credential rep- resenting the resource owner\u2019s authorization. 3) The client requests an access token by authenticating with the AS and presenting the authorization grant. 4) The authorization server authenticates the client, validates the authorization grant, and, if the grant is valid, issues an access token. 5) The client requests the protected resource from the resource server and authenticates by presenting the access token. 6) The SP validates the access token and, if valid, serves the request. \n\nThe OAuth authorization framework (currently in version 2.0 [172]) enables a third-party application to obtain limited access to an HTTP service, either on behalf of a resource owner by orchestrating an \n\n222 5 Security and Privacy in the IoT \n\napproval interaction between the resource owner and the HTTP service, or by allowing the third-party application to obtain access on its own behalf. For IoT scenarios, when using CoAP as an application-layer protocol instead of HTTP, a modi\ufb01ed version of OAuth should be de\ufb01ned in order to ensure an authorization layer for restricting access to smart-object services. Since OAuth is an open protocol to allow secure authorization in a simple and standard method from web, mobile, and desktop applications, it has to be adapted in order to suit IoT application scenarios and to be compatible with constrained environments. For instance, header compression should be used to minimize the amount of information sent along. HTTP/CoAP proxies should be able to perform OAuth proxying as well, in order to allow interoperability between conventional and constrained OAuth clients and servers. This raises particular challenges since the OAuth speci\ufb01cation recommends the usage of HTTPS as a means to avoid man-in-the-middle attacks, thus preventing the access tokens from being stolen and used by malicious nodes. This means that CoAPs should be used in order to comply with the speci\ufb01cation. The HTTP/CoAP proxy should then be able to perform a TLS-to-DTLS mapping in order to ensure end-to-end security. However, the use of HTTPS (and CoAPs inherently) can be avoided: it is possible to use OAuth over an insecure communication channel by adopting HMAC-SHA1 and RSA-SHA1 digital signature schemes. \n\n5.3 Privacy Issues in the IoT \n\n5.3.1 The Role of Authorization \n\nThe evolution of online services, such as those enabled by social net- works, has had an important impact on the amount of data and per- sonal information disseminated on the Internet. Furthermore, it has prompted the development of applications that use this information to o\ufb00er new services, such as data aggregators. The information owned by online services is made available to third-party applications in the form of public application programming interfaces (APIs), typically using HTTP [2] as communication protocol and relying on the REST architectural style. The possibility that someone else besides the entity \n\n5.3 Privacy Issues in the IoT 223 \n\nthat generates the information and the service that is hosting it can access this information has raised concerns about the privacy of per- sonal information, since the trust relationship is no longer pairwise, but possibly involves other parties, unknown at the time of service subscription. Open Authorization (OAuth) is an open protocol to allow secure authorization from third-party applications in a simple and stan- dardized way [173], as previously described. The OAuth protocol provides an authorization layer for HTTP-based service APIs, typi- cally on top of a secure transport layer, such as HTTP-over-TLS (i.e., HTTPS) [174]. OAuth de\ufb01nes three main roles in the above scenario: \n\n\u2022 the user (U) is the entity that generates information; \u2022 the service provider (SP) hosts the information generated by the users and makes it available through APIs; \u2022 the service consumer (SC), also referred to as the \u201cclient application\u201d, accesses the information stored by the SP for its own utilization. \n\nIn order to comply with the security and privacy requirements, U must issue an explicit agreement that some client application can access information on their behalf. This is achieved by granting the client an access token, containing U\u2019s and SC\u2019s identities, which must be exhibited in every request as an authorization proof. The OAuth 2.0 protocol is the evolution of the original OAuth protocol and aims at improving client development simplicity by de\ufb01ning scenarios for authorizing web, mobile, and desktop applications [175]. While connecting to existing online services is a simple task for client application developers, implementing an OAuth-based authorization mechanism on the SP side is a more complicated, time-consuming, and, potentially, computationally intensive task. Moreover, it involves the registration of users and client applications, and the permis- sions that users grant to SC applications, and their integration with authentication services. International organizations, such as the IETF and the IPSO Alliance [176], and several research projects, such as the FP7 EU project CALIPSO (Connect All IP-based Smart Objects!) [177], promote the use of IP as the standard for interoperability between smart objects. The protocol stack run by smart objects tries to match classical Inter- net hosts in order to make it feasible to create the so-called \u201cextended Internet\u201d; in other words, the aggregation of the Internet with the IoT. \n\n224 5 Security and Privacy in the IoT \n\nThe IETF CoRE Working Group has de\ufb01ned the Constrained Applica- tion Protocol (CoAP; see Section 2.2.5.1) [7], a generic web protocol for RESTful constrained environments, targeted to M2M applications, which maps to HTTP for integration with the existing web. Security in IoT scenarios is crucial. It applies at di\ufb00erent levels, rang- ing from technological to privacy and trust issues, especially in scenar- ios involving smart toys (used by children) or crowd/social behavior monitoring. This is related to the fact that smart objects might have to deal with personal or sensitive data, which, if intercepted by unautho- rized parties, might create ethical and privacy problems. While the use of the OAuth protocol has little impact, in terms of processing and scalability, on conventional Internet-based services, its adoption in the IoT has to deal with the limitations and challenges of constrained devices. The limited computational power of smart objects may not be su\ufb03cient to perform the cryptographic primitives required for message authentication, integrity checks, and digital signatures, use of which would have a negative impact on energy consumption. Moreover, if the access permissions for the services provided by the smart object reside on the smart object itself, it could be extremely hard, if not impossible, to dynamically update them once they have been deployed. An example is found in smart parking systems, such as Fastprk1 by Worldsensing [178], where smart objects may be embedded directly in the asphalt. In rapidly evolving IoT scenarios, security is an extremely important issue. The heterogeneous and dynamic nature of the IoT raises several questions related to security and privacy, which must be addressed properly by taking into account the speci\ufb01c characteristics of smart objects and the environments they operate in. Classical security algorithms and protocols, used by traditional Internet hosts, cannot simply be adopted by smart objects, due to their processing and communication constraints. An extensive overview of state-of-the-art security mechanisms in the IoT (including symmetric/asymmetric cryptographic algorithms, hashing functions, security protocols at network/transport/application layers), aiming at providing features such as con\ufb01dentiality, integrity, and authentication, can be found in the literature [179]. An architecture for solving the problem of securing IoT cyberenti- ties (including smart objects, traditional hosts, and mobile devices), \n\n1 http://www.fastprk.com/. \n\n5.3 Privacy Issues in the IoT 225 \n\ncalled U2IoT, has been proposed [180], with the goal of addressing the issues of expanding domains, dynamic activity cycles, and het- erogeneous interactions. U2IoT takes into account security in interac- tions that occur in three di\ufb00erent phases: preactive, active, and postac- tive. In particular, the active phase provides authentication and access control functionalities. Authorization is therefore being considered a major issue, since it is becoming increasingly evident that access to resources in a global-scale network, such as the IoT, must be controlled and restricted in order to avoid severe security breaches in deployed applications. Several other studies have addressed very speci\ufb01c issues for the IoT. A lightweight multicast authentication scheme for small-scale IoT applications has been proposed [181]. Lai et al. take into account user mobility (i.e., roaming) and propose CPAL, an authentication mechanism designed to provide a \u201clinking function\u201d that can be used to enable authorized parties to link user access information, while preserving user anonymity and privacy [182]. The secure integration of WSNs into the IoT is discusses by Li and Xiong [183], who propose a security scheme that allows secure communication with Internet hosts by providing end-to-end con\ufb01dentiality, integrity, and authen- tication, based on a public-key infrastructure. The proposed scheme also introduces a two-step (o\ufb04ine/online) signcryption mechanism, in order to minimize processing time. Several authentication mechanisms have been de\ufb01ned for other issues, such as network access, that are also relevant for IoT scenar- ios. The Protocol for Carrying Authentication for Network Access (PANA) [184] is an IETF standard de\ufb01ning a network-layer transport for network access authentication. This is typically provided by the Extensible Authentication Protocol (EAP) [185]. PANA carries EAP, which can carry various authentication methods. OpenPANA [186] is an open-source implementation of PANA. The problem of service authorization has been extensively treated in the literature. Several studies have focused on how to implement di\ufb00erent access control strategies. \n\n\u2022 Discretionary access control (DAC) restricts access to objects based on the identity of subjects and/or the groups to which they belong. The controls are discretionary in the sense that a subject with cer- tain access permissions can transfer that permission on to any other subject [187]. \n\n226 5 Security and Privacy in the IoT \n\n\u2022 Role-based access control (RBAC) relies on a policy that restricts access to resources to those entities that have been assigned a spe- ci\ufb01c role [188\u2013190]: RBAC requires that the roles are de\ufb01ned and assigned to users, and that access permissions are set for resources. \u2022 Attribute-based access control (ABAC) restricts resource access to those entities that have one or more speci\ufb01c attributes (e.g., age, geographic location, etc.) [191]. \n\nRBAC and ABAC are the most common approaches to restricting system access to authorized users. RBAC maps permissions to roles that a user has been assigned. On the other hand, ABAC maps per- missions to attributes of the user. Typically, authorization mechanisms strongly depend on an authentication step that must have been pre- viously taken in order to identify users so that either their roles or their attributes can be veri\ufb01ed and matched against the policies set for resource access. Schi\ufb00man et al. have presented a mechanism for \ufb01ne-grained sub-delegation of access permissions for consumers of web appli- cations, called DAuth. [192], Applying access control mechanisms in constrained scenarios, such as wireless sensor networks, is a challenging task. IETF Authentication and Authorization for Constrained Envi- ronments (ACE) Working Group has also proposed the Delegated CoAP Authentication and Authorization Framework (DCAF) [193]. The DCAF architecture introduces authorization servers, which are used to perform authentication and authorization. Smart objects are prevented from having to store a large amounts of information by delegating the task to an external entity. While this solution is very similar to the one that we are about to describe, it focuses mainly on constrained environments, while the proposed one is intended to be generic and transparently integrated into both IoT and Internet scenarios. In this section, we present a novel architecture, targeted at IoT scenarios, for an external authorization service based on OAuth, and called IoT-OAS. The delegation of the authorization functionalities to an external service, which may be invoked by any subscribed host or thing, a\ufb00ects: \n\n\u2022 the time required to build new OAuth-protected online services, thus letting developers focus on service logic rather than on security and authorization issues; \n\n5.3 Privacy Issues in the IoT 227 \n\n\u2022 the simplicity of the smart object, which does not need to imple- ment any authorization logic but must only securely invoke the authorization service in order to decide whether to serve an incoming request or not; \u2022 the possibility to dynamically and remotely con\ufb01gure the access control policies that the SP is willing to enforce, especially in those scenarios where it is hard to intervene directly on the smart object. \n\nAlthough much work has been done to de\ufb01ne and integrate authorization mechanisms in several scenarios, the current proposal, unlike others, focuses on the de\ufb01nition of a generic authorization service that can be integrated into both Internet and IoT scenarios. In particular, the proposed mechanism explicitly takes into account the hybrid nature of the extended Internet that will be deployed in com- ing years. Moreover, the proposed architecture minimizes the e\ufb00ort required by service developers to secure their services by providing a standard, con\ufb01gurable, and highly interoperable authorization framework. \n\n5.3.2 IoT-OAS: Delegation-based Authorization for the Internet of Things \n\n5.3.2.1 Architecture IoT-OAS can be invoked by any subscribed host or smart object. It can be thought of as a remotely triggered switch that \ufb01lters incom- ing requests and decides whether to serve them or not. The design goal of the IoT-OAS architecture is to relieve smart objects of the bur- den of handling a large amount of authorization-related information and processing all incoming requests, even if unauthorized. By out- sourcing these functionalities, smart objects can keep their applica- tion logic as simple as possible, thus meeting the requirements for keeping the memory footprint as low as possible, which is extremely important for constrained devices. From a broader perspective, entire large-scale IoT deployments can greatly bene\ufb01t from the presence of IoT-OAS in terms of con\ufb01gurability: a single constrained node (or a group of constrained nodes as a whole) can have their access poli- cies updated remotely and dynamically, without requiring any direct intervention, which is especially convenient for smart objects placed in hard-to-reach and/or unattended locations. OAuth allows third-party \n\n\n![Image](/src/assets/generated_images/iot_p239_i0.png)\n228 5 Security and Privacy in the IoT \n\napplications to get access to user-related information hosted on an online service. All issued requests must certify that the SC application has been granted permission by the user to access its personal infor- mation on its behalf, namely by adding an access token, which relates the user\u2019s identity and the client application. For ease of presentation, the acronyms used in this section are summarized in Table 5.6. Besides the three roles introduced in Section 5.3.1 (U, SP, and SC), OAuth adds an additional role: the authentication service (AS), which is invoked by the SP to verify the identity of a user in order to grant access tokens. The standard OAuth operation \ufb02ow is shown in \n\nTable 5.6 Acronyms used. \n\nU User or resource owner \n\nSP Service provider, which hosts users\u2019 resources \n\nSC Service consumer, which accesses users\u2019 data stored by the SP \n\nAS Authentication service, which is used by the SP to verify the identity of a user \n\nRT Request token, a temporary ticket used by the SC to ask U to authorize access to its resources \n\nAT Access token, used by the SC to perform authenticated requests \n\nIoT-OAS Delegated external authorization service, which can be invoked by smart objects to perform authorization checks to access protected resources \n\n\nProtected Services API \n\nAuthorization Layer Service Provider User Data \n\nUser \n\nService Consumer (Web, Mobile, ...) \n\nAuthentication Service \n\n7 \n\n1 \n\n4 3 5 \n\n6 \n\n2 \n\n8 \n\nFigure 5.6 Standard OAuth roles and operation \ufb02ow. The numbers indicate the sequence. \n\n5.3 Privacy Issues in the IoT 229 \n\nFigure 5.6. The procedure through which a SC can get a valid access token is the following: \n\n1) U is willing to use the SC, either from a webpage, a mobile app, or a desktop application. 2) SC needs to access U\u2019s personal information hosted on the SP; SC asks the SP for an RT carrying SC\u2019s identity, which will be later exchanged for an AT. 3) SP veri\ufb01es SC\u2019s identity and returns a RT. 4) SC redirects U to the SP\u2019s authentication service with the RT 5) U contacts the SP\u2019s AS presenting the RT and is asked to authen- ticate in order to prove its consent to grant access permissions to the SC. 6) The RT is exchanged for an AT, which relates U and SC. 7) The SC receives the AT through a redirection to a callback URL (i.e., authentication callback). 8) The SC can issue requests to SP including the AT, for services that require U\u2019s permission (protected APIs). \n\nThe design goal of the IoT-OAS architecture is to enable SPs, either based on HTTP or CoAP, to easily integrate an authorization layer without requiring any implementation overhead, other than invoking an external service. Delegating the authorization logic to an external service requires a strong trust relationship between the SP and the IoT-OAS. Figure 5.7 shows the operation \ufb02ows for the AT grant procedure and the SC-to-SP interaction in the IoT-OAS architecture. A detailed description of these operation \ufb02ows is presented in the remainder of this section. \n\n5.3.2.2 Granting Access Tokens The operation \ufb02ow to grant an AT to a SC is shown in Figure 5.7a. The procedure resulting in the grant of an AT to a SC is similar to that of the standard OAuth operation \ufb02ow, yet it has the following important di\ufb00erences: \n\n1) As in the standard operation \ufb02ow, the procedure is initiated by U. 2) The SC regularly contacts an SP to receive an RT. 3) The SP, which does not implement any OAuth logic, contacts the IoT-OAS asking for an RT for the SC by performing a generate_request_token RPC request. 4) The IoT-OAS veri\ufb01es the identity of the SC and issues an RT, which is returned to the SP. \n\n\n![Image](/src/assets/generated_images/iot_p241_i0.png)\n\n![Image](/src/assets/generated_images/iot_p241_i1.png)\n230 5 Security and Privacy in the IoT \n\n\n\nService Provider \n\nService Provider \n\nService \n\n(a) \n\n(b) \n\nAuthentication Service \n\nService Consumer \n\nOAuth Service \n\nOAuth Service \n\nTrust relationship / Secure Channel \n\nAccess Token Response \n\nGenerate Access Token (AT) \n\nGenerate Request Token \n\nRequest Token Response \n\nRequest Token Response \n\nRequest Token (RT) Request \n\nRT | User \n\nHandle AT to Service Consumer Callback URL \n\n5 \n\n4 \n\n3 \n\n10 \n\n9 \n\n11 \n\n2 \n\n8 \n\n2 \n\n3 \n\n4 \n\n1 \n\n7 6 \n\n1 RT \n\nverification response \n\nRT \n\nUser \n\nrequest + access token \n\nresponse \n\nTrust relationship / Secure Channel \n\nverify(provider,request,access_token) \n\nPermission Store \n\nFigure 5.7 IoT-OAS main procedures: (a) AT grant procedure; (b) SP integration with IoT-OAS for request authorization. The numbers indicate the sequence. \n\n5) The SP hands the RT back to the SC. 6) The SC redirects U to the AS with the received RT. 7) U contacts the SP\u2019s AS presenting the RT and authenticates it in order to prove consent to grant access permissions to the SC. 8) The AS noti\ufb01es the SP that the authentication is successful and presents the RT with U\u2019s identity. 9) The SP asks the IoT-OAS to exchange the RT with an AT for U by issuing a generate_access_token RPC request. 10) The IoT-OAS generates the AT and returns it to the SP. 11) The SP hands the AT to the SC via an authentication callback. \n\n5.3 Privacy Issues in the IoT 231 \n\nThe use of an external IoT-OAS is totally transparent to the SC, which has no knowledge of how the SP is implementing the OAuth protocol. This leads to full backward compatibility with standard OAuth client applications. On the SP side, all the OAuth logic is delegated to the IoT-OAS, with the only exception being the AS. However, it is not mandatory that the AS resides within the SP\u2019s realm, as it might interface with third-party authentication services, such as OpenID [194]. The only information the SP must hold is the reference to users\u2019 identities in order to make it possible to set up access permission policies on a per-user basis. \n\n5.3.2.3 Authorizing Requests The interaction between SP and IoT-OAS when serving incoming requests is shown in Figure 5.7b. Since the presence of the IoT-OAS is totally transparent to the SC, the communication between the SC and the SP is a regular OAuth communication. The di\ufb00erence is, again, on the side of the SP, which needs to contact the IoT-OAS to verify that the incoming requests received from the SC are authorized in order to decide whether to serve them or not. The operation \ufb02ow is as follows: \n\n1) The SC requests U\u2019s information from the SP using the AT received after U\u2019s authentication (as in standard OAuth consumer-to-provider communication). 2) The SP, which does not implement any OAuth logic, refers to the IoT-OAS to verify if the incoming request is authorized (in order to do so, the SP issues a verify RPC request). 3) The IoT-OAS veri\ufb01es the SC\u2019s request and informs the SP about the SC\u2019s authorization for the request by performing a lookup in the permission store. 4) The SP serves the SC\u2019s request according to the IoT-OAS\u2019s response. \n\n5.3.2.4 SP-to-IoT-OAS Communication: Protocol Details The SP interacts with the IoT-OAS with a simple communication protocol. The protocol comprises three remote procedure calls (RPCs), which are detailed below. It is important to note that del- egating the authorization decision to an external service requires an extremely high trust level between the SP and the IoT-OAS. Moreover, all communications between them must be secured and \n\n232 5 Security and Privacy in the IoT \n\nmutually authenticated, so that the SP security level is at least as high as if the authorization service were implemented internally. To ensure that an appropriate security level is met, communica- tions between the SP and the IoT-OAS must occur with a secure transport such as HTTP-over-TLS (HTTPS), CoAP-over-DTLS (CoAPs) [195, 196], or HTTP/CoAP over a secure host-to-host chan- nel setup with IPSec [196]. Mutual authentication ensures that the IoT-OAS is veri\ufb01ed and the requests come from a veri\ufb01ed SP, whose identity is, therefore, implicit. The three RPCs of the SP-to-IoT-OAS communication protocol are as follows: \n\n1) generate_request_token(): this RPC is called by the SP to request the IoT-OAS to generate a request token for the given SC, to be later exchanged for an AT. 2) generate_access_token(request_token,user_id): this RPC is called by the RPC to request the IoT-OAS to exchange the given RT for a new AT related to the given user. 3) verify(request,access_token): this RPC is called by the SP to request the IoT-OAS to verify if the given SC request is authorized with the provided AT by performing a lookup into the permission store. \n\n5.3.2.5 Con\ufb01guration IoT-OAS provides high customization to SPs by o\ufb00ering per-user and per-service access control. The SPs can remotely con\ufb01gure and manage the permissions that SCs are granted, and these can be created, updated, revoked, and/or duplicated dynamically at any time. The IoT-OAS thus o\ufb00ers a dedicated SP access control con\ufb01guration, known as the permission store. The permission store is a collection of the relations between SCs, users, and SP services and can be seen as a lookup table. The con\ufb01guration of the permission store can be through web inter- faces or API calls provided by IoT-OAS. The possibility to dynamically manage the permissions, rather than having them co-located with the SP, is an extremely valuable feature, especially if SPs are smart objects with the need to be deployed in hard-to-access locations and that may be automatically and/or remotely recon\ufb01gured. \n\n5.3.3 IoT-OAS Application Scenarios \n\nIn this section, we present four signi\ufb01cant IoT application scenar- ios to illustrate the functionaly of the proposed IoT-OAS service \n\n5.3 Privacy Issues in the IoT 233 \n\narchitecture. We consider an external client (based on HTTP or CoAP according to the context) that wants to access a remote service provided by a network broker (NB), which is a border network element that exposes services on behalf of constrained nodes residing in the internal network. Alternatively, the service may be exposed directly by a generic smart object S directly available in the network behind a network gateway. To clarify the following description we assume that the OAuth credentials owned by the external client have been obtained through a prior con\ufb01guration phase based on the IoT-OAS service described in Section 5.3.2 and that service discovery is performed through an application-speci\ufb01c procedure, which is not directly related to the approach presented in this work. \n\n5.3.3.1 Network Broker Communication In the \ufb01rst scenario, illustrated in Figure 5.8a, the client C (acting as an SC) discovers ServiceA provided by the NB. In order to serve exter- nal requests, the NB can retrieve information from di\ufb00erent smart objects in its network. In this case, in order to simplify the context, we assume that the NB needs information only from the smart object S2. The client, through a secure channel based on HTTPS or CoAPs, sends a request R for ServiceA including its OAuth credentials, denoted as OAuth(C). The client\u2019s OAuth information is used by the service provider NB to validate the request, to verify the identity of C, and to con\ufb01rm that C has the right privileges to access the requested ser- vice. Since NB could be implemented using an embedded device or, more generally, using a device with limited computational and stor- age capabilities (which, with high probability, does/should not imple- ment a complex logic such as OAuth), it delegates the veri\ufb01cation of the incoming request to the IoT-OAS. Once the NB receives R from C, it sends a veri\ufb01cation request to the IoT-OAS (always through a secure channel based on HTTPS or CoAPs, according to its imple- mentation or capabilities) with the original incoming request and its credentials. The IoT-OAS, after verifying the validity of the submit- ted request (according to NB\u2019s con\ufb01guration) and C\u2019s identity, replies, communicating if R is authorized. If the feedback is positive and C is allowed to access the requested service, the NB internally contacts the smart object S2 to retrieve the required information and sends back the response to C. If the response received from the IoT-OAS is neg- ative, C is not granted access, and the NB responds immediately to C without any kind of interaction with the smart object. \n\n\n![Image](/src/assets/generated_images/iot_p245_i0.png)\n\n![Image](/src/assets/generated_images/iot_p245_i1.png)\n\n![Image](/src/assets/generated_images/iot_p245_i2.png)\n\n![Image](/src/assets/generated_images/iot_p245_i3.png)\n234 5 Security and Privacy in the IoT \n\n\nHTTPS/CoAPs \n\nR = Req[OAuth(C);ServiceA(P1)] \n\nResponse \n\nVerify (R) \n\nYes (OAuth(C)/No \n\nOAuth Service \n\n(a) \n\nClient (HTTP/CoAP) \n\nNetwork Broker \n\nS1 S4 \n\nS5 \n\nS3 \n\nS2 4 2 \n\n2 \n\n3 \n\n1 6 \n\n\n(d) \n\nCoAPs | CoAP/UDP/IPSec \n\nHTTPS \n\nResponse \n\nVerify \n\nOAuth Service \n\nYes (OAuth(C))/No \n\nR = Req[OAuth(C):ServiceB(S2)] \n\nClient (HTTP/CoAP) \n\nGateway \n\nS1 S4 \n\nS5 \n\nS3 \n\nS2 \n\n4 \n\n3 \n\n1 2 \n\n\n(c) \n\nCoAPs | CoAP/UDP/IPSec \n\nResponse \n\nVerify \n\nOAuth Service \n\nYes (OAuth(C))/No \n\nR = Req[OAuth(C);ServiceB(S2)] CoAP Client Gateway \n\nS1 S4 \n\nS5 \n\nS3 \n\nS2 \n\n1 2 \n\n4 \n\n3 \n\n\n(b) \n\nHTTPS/CoAPs \n\nR = Req[OAuth(C);ServiceB(S2)] \n\nResponse \n\nVerify (R) \n\nYes (OAuth(C)/No \n\nOAuth Service \n\nClient (HTTP/CoAP) Gateway \n\nS1 S4 \n\nS5 \n\nS3 \n\nS2 \n\n7 \n\n3 2 \n\n5 \n\n1 \n\n6 4 \n\n8 \n\nFigure 5.8 Application scenarios: (a) client-to-network broker communication; (b) gateway-enabled communication; (c) end-to-end CoAP communication between the external client and the smart object; (d) hybrid gateway-based communication. \n\n5.3 Privacy Issues in the IoT 235 \n\n5.3.3.2 Gateway-based Communication In the second scenario, illustrated in Figure 5.8b, an external client C, based on HTTPS or CoAPs communications, is interested in accessing a service directly provided by the smart object S2, which does not run HTTP or CoAP (due to computational or implementation constraints) and is behind a gateway G. Gateway G has the role of translating the incoming requests from external networks to available smart objects inside its own network. In this scenario, C sends a request R (includ- ing the client\u2019s OAuth credentials) to G for ServiceB provided by S2. R is translated by G and forwarded to S2, which, in order to validate the new request and the requestor\u2019s identity, sends through G a veri\ufb01ca- tion request to the IoT-OAS using a secure communication protocol such as HTTPS or CoAPs. The veri\ufb01cation message and the response (positive or negative) generated by S2 are managed and translated by G to allow communication between IoT-OAS, the smart object, and the client. \n\n5.3.3.3 End-to-End CoAP Communication Figure 5.8c shows a di\ufb00erent scenario, where a smart object S2 (i.e., reachable at an IPv6 address) in a sensor network directly provides a remote CoAP service ServiceB. Since all the involved entities can use the same protocol, in this case the network gateway acts only as a router without the need to translate incoming and outgoing mes- sages between the external world and the sensor network. The CoAP client CC sends securely and directly to the smart object a request R containing its OAuth credentials and the reference for ServiceB pro- vided by S2. Since the smart object is usually a sensor or an embedded device with limited computational and storage capabilities (and there- fore, as previously described, does not implement a complex logic like OAuth), it delegates the veri\ufb01cation of the incoming request to the OAuth service. S2 sends a veri\ufb01cation request to IoT-OAS over CoAPs to check R. The IoT-OAS validates the request based on CC\u2019s creden- tials and the type of requested service; it then informs the smart object S2 about whether R can be served or not. S2, according to the response of IoT-OAS, replies to the requesting client with the service outcome or, if the CC is not allowed to access ServiceB, with an error message. \n\n5.3.3.4 Hybrid Gateway-based Communication The last scenario, shown in Figure 5.8d, is characterized by a hybrid approach in which the external client uses an application protocol \n\n236 5 Security and Privacy in the IoT \n\n(such as HTTP) that is di\ufb00erent from that used by smart objects (CoAP). Similar to the case in Section 5.3.3.2, the gateway manages the communication between the external world and its network: in this case, it just translates incoming requests from HTTP to CoAP for S2. Once a new request (with OAuth credentials and service reference) arrives at the smart object, it uses IoT-OAS securely to verify the validity of R, through CoAPs. The response (positive or negative, according to the IoT-OAS feedback) is translated by the gateway from CoAP to HTTP and forwarded to the client through a secure channel. \n\n237 \n\n6 \n\nCloud and Fog Computing for the IoT \n\n6.1 Cloud Computing \n\nCloud Computing is an increasing trend, involving the move to external deployment of IT resources, which are then o\ufb00ered as services [197]. Cloud Computing enables convenient and on-demand network access to a shared pool of con\ufb01gurable computing resources (e.g., networks, servers, storage elements, applications, and services). These can be rapidly provisioned and released with minimal man- agement e\ufb00ort or service provider interaction [198]. At the hardware level, a number of physical devices, including processors, hard drives, and network devices, ful\ufb01ll processing and storage needs. Above this, a combination of a software layer, a virtualization layer, and a management layer, allows e\ufb00ective management of servers. The available service models are as follows: \n\n\u2022 Infrastructure as a Service (IaaS): provides processing, storage, net- works, and other computing resources, allowing the consumer to deploy and run arbitrary software, including OSs and applications. The consumer has control over the OSs, storage, deployed appli- cations and, possibly, limited control of select networking compo- nents. \u2022 Platform as a Service (PaaS): provides the capability to deploy infrastructure and consumer-created or acquired applications. The consumer has no control over the underlying infrastructure (e.g., network, servers, OSs, or storage) but only manages deployed applications. \n\nInternet of Things: Architectures, Protocols and Standards, First Edition. Simone Cirani, Gianluigi Ferrari, Marco Picone, and Luca Veltri. \u00a9 2019 John Wiley & Sons Ltd. Published 2019 by John Wiley & Sons Ltd. \n\n238 6 Cloud and Fog Computing for the IoT \n\n\u2022 Software as a Service (SaaS): provides the capability to use the provider\u2019s applications, running on the cloud infrastructure. These application are accessed from client devices through suitable client interfaces. The consumer does not manage or control the under- lying cloud infrastructure or individual application capabilities, with the possible exception of limited user-speci\ufb01c application con\ufb01guration settings. \n\nCloud computing is generally complementary to the IoT scenario, as it acts \n\n\u2022 as a collector of real-time sensed data \u2022 as provider of services built on the basis of collected information. \n\nThe main need is to be extremely scalable, thus allowing support for large-scale IoT applications. There are several open-source frame- works and technologies which can be used for cloud IoT systems, such as OpenStack (created by Rackspace and NASA in 2010) and OpenNebula [199]. The former is an open cloud OS that controls large pools of computing, storage, and networking resources and can be seen as a framework with a vendor-driven model; the second is an open-source project aimed at delivering a simple, feature-rich, and \ufb02exible solution to build and manage enterprise clouds and virtualized data centers. \n\n6.2 Big Data Processing Pattern \n\nFrom a business perspective, managing and gaining insights from data is a challenge and a key in gaining competitive advantage. Analytical solutions that mine structured and unstructured data are important, as they can help companies to gain information, not only from their privately acquired data, but also from the large amounts of data pub- licly available on the web, social networks, and blogs. Big Data opens up a wide range of possibilities for organizations to understand the needs of their customers, predict their demands, and optimize valu- able resources. Big Data is di\ufb00erent to and more powerful than traditional analytics tools used by companies [200]: it can \ufb01nd patterns and glean intelli- gence from data, translating them into business advantage. However, \n\n6.3 Big Stream 239 \n\nBig Data is powered by what is often referred as a \u201cmulti-V\u201d model, in which V stands for: \n\n\u2022 variety: to represent the data types; \u2022 velocity: to represent the rate at which the data is produced and pro- cessed and stored according with further analysis; \u2022 volume: to de\ufb01ne the amount of data; \u2022 veracity: refers to how much the data can be trusted given the relia- bility of its sources. \n\nBig Data architectures generally use traditional processing patterns with a pipeline approach [201]. These architectures are typically based on a processing perspective: the data \ufb02ow goes downstream from input to output, to perform speci\ufb01c tasks or reach the target goal. Typically, data are sequentially handled with tightly coupled pre-de\ufb01ned processing sub-units (static data routing). The paradigm can be described as \u201cprocess-oriented\u201d: a central coordination point manages the execution of subunits in a certain order and each sub-unit provides a speci\ufb01c processing output, which is used only within the scope of its own process, without the possibility of being shared among di\ufb00erent processes. This approach represents a major deviation from traditional service-oriented architectures, where the sub-units are external web services invoked by a coordinator process rather than internal services [202]. Big Data applications generally interact with cloud computing architectures, which can handle resources and provide services to consumers. Assun\u00e7\u00e3o et al. have provided a survey of approaches, environments, and technologies in key areas for big data analytics, investigating how they can contribute to build analytics solutions for clouds [203]. Gaps in knowledge and recommendations for the research community on future directions for cloud-supported big data computing are also described. \n\n6.3 Big Stream \n\nBillions of smart objects are expected to be deployed in urban, home, industrial, and rural scenarios, in order to collect information, which might then be used to build new applications. Shared and interoper- able communication mechanisms and protocols are currently being de\ufb01ned and standardized, allowing heterogeneous nodes to e\ufb03ciently \n\n240 6 Cloud and Fog Computing for the IoT \n\ncommunicate with each other and with existing Internet actors. An IP-based IoT will be able to extend and interoperate seamlessly with the existing Internet. Standardization institutions, such as the IETF [204], and several research projects [177] are in the process of de\ufb01ning mechanisms to bring IP to smart objects, a result of the need to adapt higher-layer protocols to constrained environments. However, not all objects will support IP, as there will always be tiny devices that are organized in closed/proprietary networks and rely on very simple and application-speci\ufb01c communication protocols. These networks will eventually connect to the Internet through a gateway/border router. Sensed data are typically collected and sent by uplink, namely from IoT networks, where smart objects are deployed, to collection envi- ronments (server or cloud), possibly through an intermediate local network element, which may perform some processing tasks, such as data aggregation and protocol translation. Processing and storing data at the edge of networks (e.g., on set-top boxes or access points) is the basis for the evolution of fog computing [205] in IoT scenarios. Fog Computing is a novel paradigm that aims at extending cloud comput- ing and services to the edge of the network, leveraging its proximity to end users, its dense geographical distribution, and its support for mobility. The wide geographical distribution makes the fog computing paradigm particularly suited to real-time big data analytics. Densely distributed data collection points allow a fourth axis \u2013 low-latency \u2013 to be added to typical big data dimensions (volume, variety, and velocity). Figure 6.1 shows the hierarchy of layers involved in data collection, processing, and distribution in IoT scenarios. With billions of nodes capable of gathering data and generating information, the availability of e\ufb03cient and scalable mechanisms for collecting, processing, and storing data is crucial. Big Data techniques, which were developed over the last few years (and became popular due to the evolution of online and social/crowd services), address the need to process extremely large amounts of heterogeneous data for multiple purposes. These techniques have been designed mainly to deal with huge volumes (focusing on the amount of data itself), rather than providing real-time processing and dispatching. Cloud Computing has been direct application for big data analysis due to its scalability, robustness, and cost-e\ufb00ectiveness. The number of data sources, on one side, and the subsequent frequency of incoming data, on the other side, create a new need for cloud architectures to handle massive \ufb02ows of information, thus producing a shift from the big data \n\n\n![Image](/src/assets/generated_images/iot_p252_i0.png)\n6.3 Big Stream 241 \n\n\nCloud \n\nFog \n\nloT Networks \n\nGW GW GW \n\nServices Storage Processing \n\nFigure 6.1 The hierarchy of layers involved in IoT scenarios: the fog works as an extension of the cloud to the network edge, where it can support data collection, processing, and distribution. \n\nparadigm to the big stream paradigm. In addition, the processing and storage functions implemented by remote cloud-based collectors are the enablers for their core businesses: providing services based on the collected/processed data to external consumers. Several relevant IoT scenarios, (such as industrial automation, transportation, networks of sensors and actuators), require real-time/ predictable latency and could even change their requirements (e.g., in terms of data sources) dynamically and abruptly. Big-stream-oriented systems will be able to react e\ufb00ectively to changes and to provide smart behavior when allocating resources, thus implementing scal- able and cost-e\ufb00ective cloud services. Dynamism and real-time requirements are another reason why big data approaches, with their intrinsic inertia (big data typically uses batch processing), are not suitable for many IoT scenarios. The main di\ufb00erences between the Big Data and Big Stream paradigms are the nature of the data sources and the real-time/latency requirements of the consumers. The big stream paradigm allows real-time and ad-hoc processing to be performed, to link incoming streams of data to consumers. It o\ufb00ers a high degree of scalability, \ufb01ne-grained and dynamic con\ufb01guration, and management of hetero- geneous data formats. In brief, while both Big Data and Big Stream \n\n\n![Image](/src/assets/generated_images/iot_p253_i0.png)\n\n![Image](/src/assets/generated_images/iot_p253_i1.png)\n242 6 Cloud and Fog Computing for the IoT \n\n\nSensor Streams \n\nInternet Streams \n\nFeedbacks & Updates \n\nImprove Ef\ufb01ciency \n\nProvide New Services \n\nPower Application \n\nCrowdsourcing Streams \u201cBig Data\u201d Analytics \n\n(a) \n\n\nLoopback Listeners \n\nMultiple Listeners \n\nSensor Streams \n\nInternet Streams \n\nCrowdsourcing Streams \u201cBig Stream\u201d Management \n\n(b) \n\nFigure 6.2 (a) Data sources in big data systems. (b) The multiple data sources and listener management in big stream systems. \n\nsystems deal with massive amounts of data, the former focuses on the analysis of data, while the latter focuses on the management of \ufb02ows of data, as shown in Figure 6.2. The di\ufb00erence is in the meaning of the term \u201cbig\u201d, which refers to the volume of data for big data and to the global data generation rate of the data sources for big stream. This di\ufb00erence is also relevant for the data that are considered relevant to consumer applications. For instance, while for big data applications it is important to keep all sensed data in order to be able to perform any required computation, in big stream applications, data aggregation or pruning may be performed in order to minimize the latency in conveying the results of computations to consumers; there is no need for persistence. Note that, as a generalization, big data applications might be consumers of big stream data \ufb02ows. \n\n6.3 Big Stream 243 \n\nFor these reasons, we present an architecture targeting cloud-based applications with real-time constraints \u2013 big stream applications \u2013 for IoT scenarios. It relies on the concepts of the data listener and the data-oriented processing graph in order to implement a scalable, highly con\ufb01gurable, and dynamic chain of computations on incoming big streams and to dispatch data using a push-based approach, thus providing the shortest delay between the generation of information and its consumption. \n\n6.3.1 Big-stream-oriented Architecture \n\nAs stated in Section 6.3, a major di\ufb00erence between big data and big stream approaches is the real-time/low-latency requirements of big stream consumers. The vast number of data sources in IoT applica- tions has made cloud-service implementors mistakenly believe that re-using big data-driven architectures will be the right solution for all applications, and that there is no need to design new paradigms spe- ci\ufb01c for IoT scenarios. IoT application scenarios are characterized by a huge number of data sources sending small amounts of information to a collector service, typically at a limited rate. Many services can be built upon these data: environmental monitoring, building automa- tion, and smart cities applications are just a few examples. These appli- cations typically have real-time or low-latency requirements if they are to provide e\ufb03cient reactive/proactive behavior. This could be e\ufb00ec- tively implemented in an IP-based IoT, where smart objects can be directly addressed. Applying a traditional big data approach for IoT application sce- narios might bring higher or even unpredictable latency between data generation and its availability to a consumer, since this was not among the main objectives behind the design of big data systems. Figure 6.3 illustrates the time contributions introduced when data pushed by smart objects need to be processed, stored, and then polled by consumers. The total time required by any data to be delivered to a consumer can be expressed as T = t0 + t1 + t2, where: \n\n\u2022 t0 is the time elapsed from the moment a data source sends infor- mation, through an available API, to the cloud service (1) and the service dispatches the data to an appropriate queue, where it can wait for an unpredictable time (2), in order to decouple data acqui- sition from processing. \n\n\n![Image](/src/assets/generated_images/iot_p255_i0.png)\n244 6 Cloud and Fog Computing for the IoT \n\n\nt0 t1 t2 wait \n\nrequest \n\nrespond \n\nlookup dispatch \n\nCustomer/Consumer process & store wait \n\nm \n\nn \n\nDW API \n\nIoT Networks \n\nApplications \n\nt1 = f (m, sizeof(DB)) \n\nttot = t0 + t1 + t2 \n\n1 \n\n2 3 \n\n7 \n\n6 \n\n5 4 \n\nFigure 6.3 Traditional big data architecture for IoT and delay contributions from data generation to applications information delivery. Refer to text for details. \n\n\u2022 t1 is the time needed for data, extracted by the queue, to be pre- processed and stored in data warehouse (DW) (3); this time depends on the number of concurrent processes that need to be executed and get access the common DW and the current size of the DW. \u2022 t2 is the data consumption time, which depends on the remaining time that a polling consumer needs to wait before performing the next fetch (4), the time for a request to be sent to the cloud service (5), the time required for lookup in the DW and post-processing of the fetched data (6), and the time for the response to be delivered back to the consumer (7). \n\nIt can be seen that the architecture described is not optimized to minimize the latency \u2013 and, therefore, to feed (possibly a large number of) real-time applications \u2013 but, rather, to perform data collection and batch processing. Moreover, it is important to understand that data signi\ufb01cant for Big Stream applications might be short-lived, since they are to be consumed immediately, while big data applications tend to collect and store massive amounts of data for an unpredictable time. In this chapter, we outline a novel architecture explicitly designed for the management of big stream applications targeting IoT scenarios. The main design criteria are the minimization of the latency in data dispatching to consumers and the optimization of resource allocation. The main novelty in the proposed architecture is that the data \ufb02ow \n\n6.3 Big Stream 245 \n\nis \u201cconsumer-oriented\u201d, rather than being based on the knowledge of collection points (repositories) where data can be retrieved. The data being generated by a deployed smart object might be of interest for a consumer application, termed the \u201clistener\u201d. A listener registers its interest in receiving updates (either in the form of raw or processed data) coming from a streaming endpoint (i.e., a cloud ser- vice). On the basis of application-speci\ufb01c needs, each listener de\ufb01nes a set of rules to specify what type of data should be selected and the associated \ufb01ltering operations. For example, in a smart parking appli- cation, a mobile app might be interested in receiving content related only to speci\ufb01c events (e.g., parking sensors status updates, the posi- tions of other cars, weather conditions, and so on) that occur in a given geographical area, in order to accomplish relevant tasks, such as \ufb01nd- ing a free, covered parking spot. The pseudocode that can be used to express the set of rules for the smart parking application is shown in Listing 6.1: \n\nListing 6.1 Smart parking pseudocode. when $temperatureEvent = { @type:http://schema.org/Weather#temperature} $humidityEvent = { @type:http://schema.org/Weather#humidity} $carPositionEvent = { @type:http://schema.org/SmartCar#travelPosition} $parkingStatusEvent = { @type:http://schema.org/SmartParking#status } @filter: { location: { @type:\"http://schema.org/GeoShape#polygon\", coordinates: [ [ [41.3983, 2.1729], [41.3986, 2.1729], [41.3986, 2.1734], [41.3983, 2.1734], [41.3983, 2.1729] ] ] } then <application logic> \n\nThe rules specify: \n\n\u2022 what kinds of events are of interest for the application; \u2022 a geographical \ufb01lter to apply in order to receive only events related to a speci\ufb01c area. \n\n246 6 Cloud and Fog Computing for the IoT \n\nBesides the \ufb01nal listener (end-user), the cloud service might also act as a listener and process the same event data stream, but with di\ufb00er- ent rules, in order to provide a new stream that can be consumed by other listeners. An example would be a real-time tra\ufb03c information application, the pseudo-code for which is presented in the following listing: \n\nListing 6.2 Tra\ufb03c information application pseudocode. \n\nwhen $cityZone = {@type:http://schema.org/SmartCity#zone} $carPositionEvents = collect({ @type: http://schema.org/SmartCar#travelPosition, @filter: { location: cityZone.coordinates } }) over window:time(30s) then emit { @type: http://schema.org/SmartCity#trafficDensity, city_zone: $cityZone, density: $carPositionEvents.size, } \n\nThe proposed big stream architecture guarantees that, as soon as data are available, they will be dispatched to the listener, which is thus no longer responsible for polling data, thus minimizing latency and possibly avoiding network tra\ufb03c. The information \ufb02ow in a listener-based cloud architecture is shown in Figure 6.4. With the new paradigm, the total time required by any data to be delivered to a consumer can be expressed as: \n\nT = t0 + t1 (6.1) \n\nwhere: \n\n\u2022 t0 is the time elapsed from the moment a data source sends infor- mation, through an available API, to the cloud service (1) and the service dispatches the data to an appropriate queue, where it can wait for an unpredictable time (2), in order to decouple the data acquisition from processing. \u2022 t1 is the time needed to process data extracted from the queue and be processed (according to the needs of the listener, say to perform format translation) and then deliver it to registered listeners. \n\nIt is clear that the reversed perspective introduced by listener-oriented communication is optimal in terms of minimization of the time that \n\n\n![Image](/src/assets/generated_images/iot_p258_i0.png)\n6.3 Big Stream 247 \n\n\nt0 t1 \n\nl1 \n\nl2 \n\nl3 \n\nl4 \n\nm listener \n\nprocess & notify \n\nApplications \n\nIoT Networks \n\nDW \n\ndispatch \n\nAPI \n\nwait n Customer/Consumer \n\nttot = t0 + t1 \n\n1 \n\n2 3 \n\nFigure 6.4 The proposed listener-based architecture for the IoT: delay contributions from data generation to consumer information delivery are explicitly indicated. \n\na listener must wait before it receives data of interest. In order to highlight the bene\ufb01ts brought by the big stream approach over a big data approach, consider an alerting application, which should notify one or more consumers of an event in the fastest possible time. The traditional big data approach would require an unnecessary pre-processing/storage/post-processing cycle to be executed before the event could be made available to consumers, who would be responsible to retrieve the data by polling. The listener-oriented approach, on the other hand, guarantees that only necessary process- ing will be performed before data are delivered directly to the listener, thus providing an e\ufb00ective real-time solution. This general discussion shows that a consumer-oriented paradigm is better suited to real-time Big Stream applications than simply reusing existing big data architectures, which best suit applications that do not have critical real-time requirements. \n\n6.3.2 Graph-based Processing \n\nIn order to overcome the limitations of the \u201cprocess-oriented\u201d approach described in Section 6.2, and \ufb01t the proposed Big Stream \n\n\n![Image](/src/assets/generated_images/iot_p259_i0.png)\n248 6 Cloud and Fog Computing for the IoT \n\n\nCore Graph App. Graph \n\ng4 \n\ng3 \n\ng2 \n\ng1 f2 \n\nf1 \n\nf6 f3 \n\nf4 f5 \n\nApplications \n\nCustomer/Consumer \n\nIoT Networks \n\nAccess Control \n\nDW \n\nCoAP \n\nMQTT \n\nHTTP \n\nFigure 6.5 The proposed listener-based graph architecture: the nodes of the graph are listeners and the edges are the dynamic \ufb02ow of information data streams. \n\narchitecture, we have envisioned and designed a new cloud graph- based architecture built on top of basic building blocks that are self- consistent and perform \u201catomic\u201d processing on data, but that are not directly linked to a speci\ufb01c task. In such systems, the data \ufb02ows are based on dynamic graph-routing rules determined only by the nature of the data itself and not by a centralized coordination unit. This new approach allows the platform to be \u201cconsumer-oriented\u201d and to give optimal resource allocation. Without the need for a coordination process, the data streams can be dynamically routed in the network by following the edges of the graph. This allows the possibility of automatically switching o\ufb00nodes when processing units are not required, or transparently replicating nodes if some process- ing entity is overwhelmed by a signi\ufb01cant number of concurrent consumers. Figure 6.5 illustrates the proposed directed-graph processing archi- tecture and the concept of the listener. A listener is an entity (e.g., a processing unit in the graph or an external consumer) interested in the raw data stream or in the output provided by a di\ufb00erent node in the graph. Each listener represents a node in the topology and the pres- ence and combination of multiple listeners, across all processing units, de\ufb01nes the routing of data streams from producers to consumers. In this architectural approach: \n\n6.3 Big Stream 249 \n\n\u2022 nodes are processing units (processes), performing some kind of computation on incoming data; \u2022 edges represent \ufb02ows of information, linking together various pro- cessing units, which are thus together able to implement some com- plex behavior; \u2022 nodes of the graph are listeners for incoming data or outputs of other nodes of the graph. \n\nThe graph-based approach allows resource allocation to be opti- mized in terms of \n\n\u2022 e\ufb03ciency, by switching o\ufb00processing units that have no listeners registered to them (enabling cost-e\ufb00ectiveness) \u2022 scalability, by replicating those processing units which have a large number of registered listeners. \n\nThe combination of these two functionalities and the concept of the listener allow the platform and the overall system to adapt itself to dynamic and heterogeneous scenarios by properly routing data streams to the consumers, and to add new processing units and functionalities on demand. In order to provide a set of commonly available functionalities, while allowing for dynamic extension of the capabilities of the system, the graph comprises several concentric levels: \n\n\u2022 a core graph, with basic processing provided by the architecture (e.g., format translation, normalization, aggregation, data correla- tion, and other transformations); \u2022 one or more application graphs, with listeners that require data coming from an inner graph level in order to perform custom processing on already processed data. \n\nThe complexity of processing is directly proportional to the num- ber of levels crossed by the data. This means that data at an outer graph level must not be processed again at an inner level. From an architectural viewpoint, as shown in a scheme in Figure 6.6, nodes at inner graph levels cannot be listeners of nodes of outer graph levels. In other words, there can be no link from an outer graph node to an inner graph node, but only vice versa. Same-level graph nodes can be linked together if there is a need to do so. Figure 6.7 illustrates incoming and outgoing listener \ufb02ows between core- and application-graph units. In particular, a processing unit of the core graph can be a listener only \n\n\n![Image](/src/assets/generated_images/iot_p261_i0.png)\n\n![Image](/src/assets/generated_images/iot_p261_i1.png)\n\n![Image](/src/assets/generated_images/iot_p261_i2.png)\n250 6 Cloud and Fog Computing for the IoT \n\n\ng2 \n\ng3 \n\ng4 \n\ng5 \n\ng6 g7 \n\ng8 \n\ng1 f6 f2 \n\nf3 \n\nf4 f5 \n\nf1 \n\nIoT Networks \n\nCustomer/Consumer \n\nApplications \n\nDW \n\n(a) \n\n\ng1 f1 \n\nf2 \n\nf3 \n\ng2 \n\ng3 g6 \n\ng5 \n\ng4 g7 \n\ng8 \n\ng9 \n\nComplexity \n\n(b) \n\nFigure 6.6 (a) The concentric linked core and application graphs. (b) Basic processing nodes build the core graph: the outer nodes have increasing complexity. \n\n\nn m \n\nn m \n\nf \n\ng \n\nIncoming Data \n\nListeners from the Core Graph \n\nListeners from the Core Graph and/or Application Graph \n\nListeners to Core Graph or Application Graph \n\nListeners to heterogenous Consumers & Application \n\nOutgoing Data \n\nFigure 6.7 Allowed input and output \ufb02ows for core-graph and application-graph nodes. \n\n\n![Image](/src/assets/generated_images/iot_p262_i0.png)\n6.3 Big Stream 251 \n\nfor other nodes of the same level (n incoming streams) and a source both for other core or application graph nodes (m outgoing streams). A node of an application graph can be, at the same time: \n\n\u2022 a listener to n incoming \ufb02ows from core and/or application graphs; \u2022 a data source only for other (m) nodes of the application graph or heterogeneous external consumers. \n\n6.3.3 Implementation \n\nIn this section, the functionalities and the details of the implemen- tation of the proposed architecture using standard protocols and open-source components are presented. Three main modules form the system: \n\n\u2022 acquisition and normalization of the incoming raw data; \u2022 graph management; \u2022 application register entity. \n\nAll modules and their relationships are shown in Figure 6.8. A detailed explanation is given in the following sections. \n\n6.3.3.1 Acquisition Module The acquisition module represents the entry point, for external IoT networks of smart objects, to the cloud architecture. Its purpose is to receive incoming raw data from heterogeneous sources, making them available to all subsequent functional blocks. As mentioned \n\n\nApplication Register \n\nData Sources \n\nGraph Framework \n\nNormalization \n\nAcquisition \n\nFigure 6.8 Components of the proposed graph-based cloud architecture and relations between each element. \n\n252 6 Cloud and Fog Computing for the IoT \n\nbefore about IoT models, several application-layer protocols can be implemented by smart objects; adhering to this idea, the acquisition module has been modeled to include a set of di\ufb00erent connectors, in order to be able to handle each protocol-speci\ufb01c incoming data stream. Among the most common IoT application-layer protocols, the current implementation of the acquisition module supports HTTP, CoAP and MQTT. In order to increase scalability and e\ufb03- ciency, in the module implementation an instance of NGINX [206] has been adopted as an HTTP acquisition server node. The server is reachable via the default HTTP port, working with a dedicated PHP page as processing module. The latter has been con\ufb01gured to forward incoming data to the inner queue server. We have chosen NGINX, instead of the prevailing and well-known open-source Apache HTTPD Server [207], because it uses an event-driven asyn- chronous architecture to improve scalability and, speci\ufb01cally, aims to guarantee high performance even in the presence of a critical number of requests. The CoAP acquisition interface was implemented using a Java process, based on a mjCoAP server instance [24], waiting for incoming raw messages, and connected to the RabbitMQ queue server,1 passing it injected elements. Indeed, since the proposed architecture is big-stream-oriented, a suitable messaging paradigm is queue communication, so in the developed platform an instance of RabbitMQ queue broker was adopted. The MQTT acquisition node is built by implementing an Apache Software Foundation ActiveMQ server through a Java process that listens for incoming data over a speci\ufb01c input topic (mqtt.input). This solution was preferred to other solutions (e.g., the C-based server Mosquitto) because it provides a dedicated API that allows custom development of the component. The MQTT acquisition node is also connected to the architecture\u2019s queue server. In order to avoid potential bottlenecks and collision points, each acquisition protocol module has a dedicated exchange module and queue (managed by RabbitMQ), linked together with a protocol-related routing key, ensuring the e\ufb03cient management of incoming streams and their availability to the subsequent nodes. In the described implementation, an exchange is a RabbitMQ component that acts as a router in the system and dispatches incom- ing messages to one or more output queues, following dynamic routing rules. \n\n1 www.rabbitmq.com. \n\n\n![Image](/src/assets/generated_images/iot_p264_i0.png)\n6.3 Big Stream 253 \n\n6.3.3.2 Normalization Module Since incoming raw data are generally application- and theme- dependent, a normalization module has been incorporated in order to normalize all the collected information and generate a represen- tation suitable for processing. The normalization procedure involves fundamental and atomic operations on data, such as: \n\n\u2022 suppression of useless information (e.g., unnecessary headers or metadata); \u2022 annotation with additional information; \u2022 translation of payloads to a suitable format. \n\nIn order to handle the huge amount of incoming data e\ufb03ciently, the normalization step is organized with protocol-speci\ufb01c queues and exchanges. As shown in the normalization section of Figure 6.9, the information \ufb02ow originated by the acquisition module is handled as follows. All protocol-speci\ufb01c data streams are routed to a dedicated protocol-dependent exchange, which forwards them to a speci\ufb01c queue. A normalization process handles the input data currently available on that queue and performs all necessary normalization operations in order to obtain a stream of information units that can be processed by subsequent modules. The normalized stream is forwarded to an output exchange. The main advantage of using exchanges is that queues and normalization processes can be dynam- ically adapted to the current workload. For instance, normalization \n\n\nAcquisition Normalization \n\nCoAP Exchange \n\nCoAP \n\nMQTT \n\nHTTP \n\nCoAP Normalization \n\nMQTT Exchange MQTT Normalization \n\nCore Exchange Level 1 \n\ncoap.event.in \n\nmqtt.event.in \n\nHTTP Exchange HTTP Normalization http.event.in \n\nFigure 6.9 Detailed representation of acquisition and normalization blocks. \n\n254 6 Cloud and Fog Computing for the IoT \n\nqueues and processes can be easily replicated to avoid system con- gestion. Each normalization node has been implemented as a Java process, analyzing incoming raw data extracted from a queue identi- \ufb01ed through a protocol-like routing key (e.g., <protocol>.event.in), leaving unaltered the associated routing key, which identi\ufb01es the originator smart object\u2019s protocol. The received data are fragmented and encapsulated in a JSON-formatted document, which provides an easy-to-manage format. At the end of the normalization chain, each processor node forwards its new output chunk to the next exchange, which represents the entry-point of the graph module, promoting data \ufb02ows to the next layers of the proposed architecture. \n\n6.3.3.3 Graph Framework The graph framework comprises a number of di\ufb00erent computational processes representing a single node in the topology; layers are linked together with frontier exchanges, forwarding data streams to their internal nodes. Each graph node i of a speci\ufb01c layer n is a listener, waiting for an input data stream on a dedicated layer-n exchange-connected queue. If this node also acts as publisher, after performing its processing on the input data, it can deliver computation results to the its layer-n exchange. In order to forward streams, information generated by node i become available for layer n and layer n + 1 listeners that are inter- ested in this kind of data, thanks to the binding between layer-n and layer(n + 1) exchanges. Incoming messages are stored in active queues, connected to each graph layer\u2019s exchange. Queues can be placed into the core graph layers, for basic computation, or into application graph layers, for enhanced computation. Layers are connected through one-way links to their successor exchange, using the binding rules allowed by the queue manager, ensuring proper propagation of data \ufb02ows and avoid- ing loops. Each graph layer is composed by Java-based graph nodes dedicated to process data provided by the graph layer\u2019s exchange. Such nodes can either be core, if they are dedicated to simple and primitive data processing, or application, if they are oriented to a more complex and speci\ufb01c data management. Messages, identi\ufb01ed with a routing key, are \ufb01rst retrieved from the layer\u2019s exchange, are then processed, and \ufb01nally are sent to the target exchange, with a new work-related routing key, as shown in Figure 6.10. If the outgoing routing key belongs to the graph layer \n\n\n![Image](/src/assets/generated_images/iot_p266_i0.png)\n6.3 Big Stream 255 \n\n\nGraph Framework exchange binding @ application.rk.m.# \n\napplication.rk.m.alert \n\nInput Queue Reader \n\nData Filter Output Publisher Processing core.rk.n.zoneA \n\nCore Layer n \n\nApplication Layer m \n\ncore.exchange.n application.exchange.m \n\nFigure 6.10 Interaction between core and application layers with binding rule. \n\nas the incoming message, the data remain in the same exchange and become available for other local processes. If the outgoing routing key belongs to an outer graph layer, then data are forwarded to the corresponding exchange and \ufb01nally forwarded, adhering to binding rules. Each graph node, upon becoming part of the system, can specify if it acts as a data publisher, capable of handling and forwarding data to its layer\u2019s exchange, or if it acts only as data consumer. Data \ufb02ow continues until it reaches the last layer\u2019s exchange, which is responsi- ble for managing noti\ufb01cations to external entities that are interested in the \ufb01nal processed data, such as data warehouses, browsers, smart entities, and other cloud graph processes. \n\n6.3.3.4 Application Register Module The application register module has the fundamental responsibilities: \n\n\u2022 to manage the processing graph by maintaining all the information about the current statuses of all graph nodes in the system \u2022 to route data across the graph. \n\nIn more detail, the application register module performs the following operations: \n\n\u2022 attach new nodes or consumer applications interested in streams provided by the system; \u2022 detach nodes of the graph that are no longer interested in streaming \ufb02ows and eventually reattach them if required; \u2022 deal with nodes that are publishers of new streams; \u2022 maintain information regarding data topics, in order to correctly generate the routing keys and to compose data \ufb02ows between nodes in di\ufb00erent graph layers. \n\n\n![Image](/src/assets/generated_images/iot_p267_i0.png)\n256 6 Cloud and Fog Computing for the IoT \n\n\nGraph Framework \n\nProcess Process Process \n\nProcess \n\nProcess \n\n(D) Detach (B) Status \n\nPOST PUT \n\nNode Registration & Queue Manager \n\nGET \n\n(A3) \n\n(A2) \n\n(A5) \n\n(A4) \n\n(C) Change Publisher (A) Attach \n\nApplication Register \n\nQueue Server \n\nGraph State \n\n(E) Reattach \n\n(A1) \n\n(A6) \n\n(A7) \n\nFigure 6.11 Detailed representation of the application register module, with possible actions that may be performed by graph nodes, highlighting ATTACH request steps needed to include an external node in the graph. \n\nIn order to accomplish all these functionalities, the application register module is made up of two main components, as shown in Figure 6.11. The \ufb01rst module is the graph state database, which stores all the information about active graph nodes, such as their states, layers, and whether they are publishers. The second module is the node registra- tion and queue manager (NRQM), which handles requests from graph nodes or external processes, and handles queue management and rout- ing in the system. When a new process joins the graph as a listener, it sends an attach request to the application register module, specifying the kind of data that it is interested to. The NQRM module stores the information of the new process in the graph state database and creates a new dedicated input queue for the process, according to its prefer- ences. Finally, the NRQM sends a reference of the queue to the process, which becomes a new listener of the graph and can read the incoming stream from the input queue. After this registration phase, the node can perform new requests (e.g., publish, detach, and get status). The overall architecture is man- aged by a Java process (the application register), which coordinates the interactions between graph nodes and external services, such as the RabbitMQ queue server and the MySQL database. It maintains and updates all information and parameters related to processing unit queues. As a \ufb01rst step, the application register starts up all the external connections, and then it activates each layer\u2019s exchange, binding them \n\n6.3 Big Stream 257 \n\nwith their successors. Finally, it proceeds with the activation of a Jetty HTTP server, responsible for listening and handling all core and appli- cation node requests, as shown in Figure 6.11 using a RESTful HTTP paradigm. These requests are: \n\n\u2022 (A) attach \u2022 (B) status \u2022 (C) change publishing policy \u2022 (D) detach \u2022 (E) re-attach. \n\nFigure 6.12 shows all of the architecture modules described above, along with a detailed indication of the information \ufb02ows. \n\n6.3.4 Performance Evaluation \n\nThe implementation of the proposed graph framework for big stream management was carried out by deploying an Oracle VirtualBox VM, equipped with Linux Ubuntu 12.04 64-bit, 4 GB RAM, two CPUs and 10 GB HDD. The implemented architecture was evaluated through the de\ufb01nition of a real use case: a smart parking scenario. The data traces used for the evaluation of the proposed architecture were pro- vided by WorldSensing from one of the company\u2019s deployments in a real-life scenario, used to control parking spots on streets. The traces are a subset of an entire deployment (more than 10,000 sensors) with information from 400 sensors over a three-month period, forming a dataset with more than 604,000 parking events. Each dataset item is represented by: \n\n\u2022 sensor ID \u2022 event sequence number relative to the speci\ufb01c sensor \u2022 event timestamp \u2022 parking spot status (free/busy). \n\nNo additional information about the parking zone was provided. Therefore, in order to create a realistic scenario, parking spot sensors were divided into seven groups, representing di\ufb00erent parking zones of a city. This parking-spot\u2013city-zone association was stored in an external database. The parking dataset was used in the cloud infrastructure using a Java-based data generator, which simulates the IoT sensor network. The generator randomly selects an available protocol (HTTP, CoAP, \n\n\n![Image](/src/assets/generated_images/iot_p269_i0.png)\n\nNew Node \n\nLayer 4 Layer 3 \n\npublish \n\nLayer 2 \n\nLayer 1 \n\nNormalization queues \n\nGraph Framework Normalization \n\nProtocol - specific connectors \n\nAcquisition \n\nP \n\nP P P \n\nP P \n\nApplication Register \n\nGraph State \n\nNode Registration & Queue Manager \n\nsubscribe \n\nFigure 6.12 The complete graph cloud architecture, with reference to the data stream \ufb02ows between all building blocks, from IoT data sources to \ufb01nal consumers. \n\n6.3 Big Stream 259 \n\nor MQTT) and periodically sends streams to the corresponding acquisition node interface. Once the data has been received by the acquisition layer, they are forwarded to the dedicated normalization exchange, where corresponding nodes enrich incoming data with platform-speci\ufb01c details. With reference to the selected scenario, the normalization stage adds parking zone details to the input data, retrieving the association from an external database. Once the normalization module has completed its processing, it sends the structured data to the graph framework, allowing further processing of the enriched data stream. The graph framework considered in our experimental set-up com- prises eight core layers and seven application layers, within which dif- ferent node topologies are built and evaluated. Processed data follow a path based on routing keys, until the \ufb01nal external listener is reached. Each application node is interested in detecting changes of parking-spot data related to speci\ufb01c parking zones. Upon a change of the status, the graph node generates a new aggregated descriptor, which is forwarded to the responsible layer\u2019s exchange, which has to notify the change event to external entities interested in the update (free \u2192busy, busy \u2192free). The rate of these events, coming from a real deployment in a European city, respects some rules imposed by the company, and for our purposes might seem low. Thus, in order to cause su\ufb03cient stress to the proposed big stream cloud system, the performance was evaluated by varying the data generation rate in a suitable range. In other words, we force a speci\ufb01c rate of incoming events, without taking into account the real parking spots timestamps gathered from the dataset. The proposed architecture was evaluated using the testbed described in Section 6.3.3, by varying the incoming raw data from 1 msg/s to 100 msg/s. The evaluation involved assessing the performance of the acquisition stage and the computation stage. First, performance was evaluated by measuring the time di\ufb00erence between the instant at which data were sent from a data generator to the corresponding acquisition interface and the instant at which the data were enriched by normalization nodes, thus becoming available for processing by the \ufb01rst core node. The results are shown in Figure 6.13. The acquisition time slightly increased but it was around 15 ms at all rates considered. The second performance evaluation measured the time between the instant at which enriched data became ready for processing activities \n\n260 6 Cloud and Fog Computing for the IoT \n\n0 14 \n\n14.5 \n\n15 \n\n15.5 \n\n16 \n\n16.5 \n\n17 \n\n20 40 60 80 100 Data generation frequency [msg/s] \n\nTime [ms] \n\nFigure 6.13 Average time related to the acquisition block. \n\nand the instant at which the message reached the end of its graph framework routes, becoming available for external consumers/cus- tomers. In order to consider only the e\ufb00ective overhead introduced by the architecture, and without considering implementation-speci\ufb01c contributions, performance results were obtained by subtracting the processing time of all core and application nodes. Finally, these times were normalized over the number of computational nodes, in order to obtain the per-node overhead introduced by the architecture, inde- pendent of the speci\ufb01c routing and topology that were implemented. The results, shown in Figures 6.14 and 6.15, were calculated using the following expression: \n\nTprocessingfreq = Tout \u2212Tin \u2212 \n\nN\u2211 \n\nk=1 GPk \n\nN (6.2) \n\nwhere: Tout is the instant at which parking data reach the last applica- tion layer; Tin is the instant at which normalized data comes to the \ufb01rst core layer; and GPk is the processing time for a graph process k \u22081, \u2026 , N. Figure 6.14 shows how Tprocessing values grow with increasing the data generation frequency (from 10 to 100 msg/s). Each curve is related to a di\ufb00erent graph topology. Figure 6.15 shows how Tprocessing values grow \n\n6.3 Big Stream 261 \n\n20 0 \n\n50 \n\n100 \n\n150 \n\n200 \n\n250 \n\n300 \n\n350 \n\n400 \n\n450 \n\n25 30 35 40 45 50 Nodes [num] \n\nTime [ms] \n\n10 msg/sec 20 msg/sec 50 msg/sec 100 msg/sec \n\nFigure 6.14 Average times related to graph framework processing block, showing per-node time, varying data generation rate, for each subset of nodes deployed into the graph topology. \n\n10 0 \n\n50 \n\n100 \n\n150 \n\n200 \n\n250 \n\n300 \n\n350 \n\n400 \n\n450 \n\n20 30 40 50 60 70 80 90 100 \n\nData generation frequency [msg/s] \n\nTime [ms] \n\n20 nodes 25 nodes 30 nodes 35 nodes 40 nodes 45 nodes 50 nodes \n\nFigure 6.15 Average times related to graph framework processing block, showing per-node time, varying the subset of nodes deployed into the graph topology, for each evaluated data generation frequency. \n\n262 6 Cloud and Fog Computing for the IoT \n\nwith increasing number of nodes in the graph topology (from 20 to 50 nodes). Each curve in Figure 6.15 is related to a di\ufb00erent value of the frequency. \n\n6.3.5 Solutions and Security Considerations \n\nThe presented architecture is designed with reference to a speci\ufb01c IoT scenario with strict latency and real-time requirements, namely a smart parking scenario. There are several possible use cases and applications \ufb01tting this scenario, alerting or real-time monitoring applications. Smart cities are encountering many di\ufb03culties in real-life deploy- ments, even though obvious factors justify the necessity and the usefulness of making cities smarter. Vilajosana et al. have analyzed in detail the causes and factors that act as barriers in the process of institutionalization of smart cities, and have proposed an approach to make smart cities become a reality [208]. They advocate three di\ufb00erent stages in order to deploy smart cities technologies and services. \n\n\u2022 The bootstrap phase: This phase is dedicated to o\ufb00ering services and technologies that are not only of great use and genuinely improve urban living, but also o\ufb00er a return on investment. The important objective of this \ufb01rst step is, thus, to set technological basis for the infrastructure and guarantee the system has a long life by generating cash \ufb02ows for future investments. \u2022 The growth phase: In this phase, the \ufb01nances generated in the previ- ous phase are used to ramp up technologies and services that require large investments; these do not necessarily produce \ufb01nancial gains but are only of great use for consumers. \u2022 The wide adoption phase: In this third phase, collected data are made available through standardized APIs and o\ufb00ered by all di\ufb00erent stakeholders to third-party developers in order to create new services. At the end of this step, the system becomes self- sustainable and might produce a new tertiary sector speci\ufb01cally related to services and applications generated using the underlying infrastructure. \n\nWith reference to the third phase, they propose three di\ufb00erent busi- ness models to handle the delivery of information to third parties. \n\n\u2022 The app-store-like model: developers can build their apps using a set of veri\ufb01ed APIs after a subscription procedure that might involve a \n\n6.4 Big Stream and Security 263 \n\nsubscription fee. IoT operators can retain a small percentage of the pro\ufb01ts of apps published in the Apple Store and/or Android mar- ketplace. \u2022 The Google-Maps-like model: the percentage fee on the sales price of an app is scaled according to the number and granularity of the queries to deployed APIs. \u2022 The open-data model: this model grants access to APIs in a classical open data vision, without charging any fee to developers. \n\nThe architecture described in this paper is compatible with these steps, and, more speci\ufb01cally, it can adopt the Google-maps-like model, where infrastructure APIs make available di\ufb00erent informa- tion streams with di\ufb00erent complexity layers. The graph architecture, moreover, gives another opportunity to extend the business model, as developers can use available streams to generate a new node of the graph, and so publish a new stream for the system. Another aspect, with a relevant impact on the business model, is security. This entails both a processing module and interaction with external entities. It is possible to adopt di\ufb00erent policies related to authentication and/or authorization on data sources, for example based on well-known and standard solutions such as OAuth [175], preventing malicious alterations of data streams and the resulting negative consequences, which could a\ufb00ect both processing results and platform reliability. At a \ufb01nal stage, security could be applied for consumer accounting and authentication, ensuring appropri- ate platform access only to authenticated/authorized entities, and providing secure transactions with authorized entities via secured communications. Security features, including authorization, authentication and con\ufb01- dentiality, should be integrated into the architecture, in order to make the implementation complete and usable. Details about integration of security features in the proposed big stream platform and its further impact on the system performance are not included here. \n\n6.4 Big Stream and Security \n\nSeveral methods and strategies to enable con\ufb01dentiality in publish/- subscribe IoT infrastructures have been proposed. IoT systems have to avoid security threats, providing strong security foundations built on a holistic view of security for all IoT elements at all stages: from \n\n264 6 Cloud and Fog Computing for the IoT \n\nobject identi\ufb01cation to service provision; from data acquisition to stream processing. All security mechanisms must ensure resilience to attacks, data authentication, access control, and client privacy. Collina et al. imagine IoT systems bridging the physical and the \u201cvirtual\u201d worlds, using a novel broker that supports protocols such as HTTP and MQTT, adhering to the REST paradigm and allowing developers to easily and responsively expose fundamental entities as REST resources [209]. The broker does not address any security issues, the authors claiming that possible solutions could include: plain authentication; virtual private networks, access control lists, as well as OAuth, a new type of authorization used to grant third parties access to personal data (Hardt, 2012). Lagutin et al. have examined the roles of di\ufb00erent actors making up an inter-domain publish/subscribe network [210]. They consider the security requirements and minimal required trust associations between entities, introducing and analyzing an architecture that secures both data and control planes. They identify the main security goals for a publish/subscribe architecture as: \n\n\u2022 integrity \u2022 scalability \u2022 availability \u2022 prevention of unauthorized tra\ufb03c. \n\nThey identify di\ufb00erent actors and security mechanisms. The main mechanism is packet level authentication, which, combined with cryp- tographic signatures and data identi\ufb01ers tied to secured identi\ufb01ers, creates a strong binding between data and tra\ufb03c, thus preventing denial of service attacks. Wang et al. deal with security issues by relying on the requirements of a particular application and on an external publish/subscribe infrastructure [211]. The general security needs of the applications include con\ufb01dentiality, integrity, and availability. In contrast, the security concerns of the infrastructure focus on system integrity and availability. Security issues in publish/subscribe platforms rely on authentication, information integrity, subscription integrity, service integrity, user anonymity, and information con\ufb01dentiality, in addition to subscription con\ufb01dentiality, publication con\ufb01dentiality, and accountability. Raiciu and Rosenblum have presented a study of con\ufb01dentiality in content-based publish/subscribe (CBPS) systems [212], de\ufb01ned \n\n6.4 Big Stream and Security 265 \n\nas an interaction model storing the interests of subscribers in a content-based infrastructure, to guide routing of noti\ufb01cations to subjects of interest. In agreement with the Wang et al. approach [211], con\ufb01dentiality aspects are decoupled into two facets, namely noti\ufb01cation and subscription, suggesting that a con\ufb01dential CBPS (C-CBPS) must satisfy correctness and noti\ufb01cation, whereas a subscription CBPS must satisfy unforgeability and security, and match isolation. A high-level approach to obtain C-CBPS by rely- ing on noti\ufb01cations using simple blocks that may be controlled and checked more easily than if they were completely encrypted, is proposed. Fremantle et al. have analyzed the use of federated identity and access management in the IoT [213]. They follow a consumer-oriented approach in which consumers own data collected by their devices, and have control over the entities that access these data. Traditional security models, based on the concept of roles in a hierarchical struc- ture, are not applicable for IoT scenarios (because of the billions of devices involved and thus the impossibility of adopting a centralized model of authentication, and the necessity to support mechanisms for delegation of authority). The authors therefore proposed OAuth2 [175] as a possible solution that could achieve access management for IoT devices that support the MQTT protocol. The overall system consists of: \n\n\u2022 a MQTT broker \u2022 an authorization server supporting OAuth2 \u2022 a web authorization tool \u2022 a device. \n\nBacon et al. tackle the problem of application security in the cloud, aiming at incorporating end-to-end security so that cloud providers can not only isolate their clients from each other, but can also iso- late the data generated by multiple users who access a particular ser- vice provided by the cloud [214]. They propose an approach called \u201capplication-level virtualization,\u201d which consists of: \n\n\u2022 removing from applications all details regarding security and \ufb02ow control; \u2022 placing the security management logic in the cloud; \u2022 allowing providers to permit only those interactions that the clients specify, \n\n266 6 Cloud and Fog Computing for the IoT \n\n6.4.1 Graph-based Cloud System Security \n\nAddressing the security problem in a graph-based cloud system requires a broad approach, owing to di\ufb00erent needs of the compo- nents involved. In Figure 6.16, the main building blocks listed above are shown. The main components, and their respective security mechanisms, are indicated. The enhanced graph architecture provides security by means of two modules: \n\n\u2022 The outdoor front-end security module (OFS) carries out security operations that can be applied a priori, before receiving data from a generic external source, as well as before a \ufb01nal consumer can start interacting with the graph-based cloud platform. \u2022 The in-graph security module (IGS) adopts security \ufb01lters that can be applied inside the heart of the graph-based cloud platform, so that processing nodes are able to control access to the streams generated by internal computational modules. \n\nThe OFS module is crucial for infrastructure safety: its role includes monitoring access to the platform and authorizing information \ufb02ows coming from, or directed to, external entities. On one side, OFS must verify and authorize only desired external input data sources, allowing them to publish raw streams in the IoT system. On the other hand, OFS is required to secure outgoing streams, generated by di\ufb00erent layers of the graph platform itself, authorizing external consumers to use, them. \n\n\nCore Graph App. Graph \n\ng1 f1 f2 \n\nf6 f3 \n\nf5 f4 \n\ng2 g3 \n\ng4 \n\nApplications OFS OFS \n\nMQTT \n\nCoAP \n\nHTTP \n\n... \n\n... \n\nCustomer/Consumer \n\nIoT Networks \n\nDW \n\n= IGS \n\nFigure 6.16 Main building blocks of the proposed listener-based graph architecture. Nodes in the graph are listeners, edges between nodes represent dynamic \ufb02ows followed by information streams. Edges can be \u201copen\u201d or \u201csecured\u201d. \n\n6.4 Big Stream and Security 267 \n\nConsider, as example, the case of company C, which owns a set of particular sensors, and wishes to become an IoT stream source for the graph-based cloud platform. C wants: \n\n\u2022 to sell sensed data only to a speci\ufb01c subset of customers, in order to protect its commercial interests \u2022 to make a pro\ufb01t from these sales. \n\nTherefore, the OFS module is strictly related to sensors and devices at the input side, and to customers\u2019 smart objects at the output stage, so that it becomes protocol-dependent and can be adapted to the speci\ufb01c technologies supported by the target devices. The IGS module is not related to the OFS module, as it acts exclusively at the heart of the IoT graph architecture, coordinating and managing inner inter-node interactions. The IGS module must be implemented inside single processing nodes, enabling them to de\ufb01ne a set of rules that describe what entities may become listeners of a generated stream. Referring to the graph architecture, shown in Figure 6.16, edges in the graph can be classi\ufb01ed as follows: \n\n\u2022 \u201cOpen\u201d edges are data streams generated by core or application nodes in the graph platform, which can be forwarded to all interested listeners without need for isolation or access control. \u2022 \u201cSecured\u201d edges are data streams that should comply with speci\ufb01ed rules or restrictions that determined the possible consumers of the generated data. \n\nAs an example, consider again company C, which provides its sensors as data sources and has noti\ufb01ed the architecture that the streams pro- duced by its sensors should be secured. The integration of security modules in the IoT architecture entails modi\ufb01cations in the structure and the modules of the (unsecured) architecture previously described. In the rest of this section, an analysis of each module in the graph architecture is presented, in order to explain how security mechanisms can be embedded and managed. In particular, we introduce the OFS module, which supports the acquisition and normalization modules on authorization of external entities. In addition, an enhanced ver- sion of the application register is described in order to underline the management of secure interactions with processing nodes. Finally, an overview inside the graph nodes, analyzing how security is applied in the processing stages, is presented. \n\n268 6 Cloud and Fog Computing for the IoT \n\n6.4.2 Normalization after a Secure Stream Acquisition with OFS Module \n\nThe acquisition and normalization modules, shown in Figure 6.17, represent the entry point for external sources (e.g., smart objects deployed in di\ufb00erent IoT networks) to the proposed architecture. The purpose of the acquisition block is to receive incoming raw data from heterogeneous sources, making them available to all sub- sequent functional blocks. Since raw data are generally application- and subject-dependent, the normalization block has to \u201cnormalize\u201d incoming data, generating a common representation, suitable for further processing. This might involve suppression of unnecessary data, data enrichment, and format translation. After the normalization process, data are sent to the \ufb01rst core layer. Within each graph layer, streams are routed by dedicated components, called brokers. These are layer-speci\ufb01c and, in the current imple- mentation of the architecture, are RabbitMQ exchanges. As stated before, smart objects can communicate using di\ufb00erent protocols. For this reason, the acquisition block has to include a set of connectors, one for each supported protocol, in order to properly handle each protocol-speci\ufb01c incoming data stream. As shown in Figure 6.17, these modules must cooperate with the OFS module, which has to be activated before an external source is able to operate with the graph platform. At the acquisition stage, in order \n\n\nAcquisition Normalization \n\nCoAP \n\nOFS \n\nraw data via CoAP \n\nraw data via MQTT \n\nBroker \n\nHTTP Normalization \n\nMQTT Normalization \n\nCoAP Normalization \n\nraw data via HTTP \n\nMQTT \n\nHTTP \n\nFigure 6.17 The OFS module manages security in the acquisition and normalization blocks, interacting with an authentication storage entity containing data source identities. \n\n6.4 Big Stream and Security 269 \n\nfor the proposed IoT platform to support both \u201copen\u201d and \u201csecured\u201d communications, protocol-speci\ufb01c communication security mecha- nisms have to be implemented at the relevant layers: at the network layer through IPSec, at the transport layer through TLS/DTLS, at the application layer through S/MIME or OAuth. As stated before, the current implementation supports di\ufb00erent application protocols at the acquisition stage, namely MQTT, HTTP, and CoAP. In order to secure all communications with these protocols, we need to introduce di\ufb00erent protocol-speci\ufb01c policies. Fremantle et al. proposed an OAuth-based secure version of the MQTT protocol [213], showing that MQTT also complies with an n-legged OAuth protocol. The proposed IoT platform provides a good way to authenticate external data providers, adopting open-source and well-understood solutions. The OFS module can be secured by OAuth, used in ways dependent on the speci\ufb01c communication protocols supported by the heterogeneous IoT smart objects. A suitable solution to provide authorization in IoT scenarios is IoT-OAS, as presented in Section 5.3.2, which represents an autho- rization framework to secure HTTP/CoAP services. The IoT-OAS approach invokes an external OAuth-based authorization service (OAS). This approach is meant to be \ufb02exible, highly con\ufb01gurable, and easy to integrate with existing services, guaranteeing: \n\n\u2022 lower processing loads than solutions with access control imple- mented in the smart object; \u2022 \ufb01ne-grained (remote) customization of access policies; \u2022 scalability, without the need to operate directly on the device. \n\nReturning to the previous example, company C, to became a secured IoT data source, selects one of the supported protocols (HTTP, CoAP or MQTT) to send raw data streams in the secured version. \n\n6.4.3 Enhancing the Application Register with the IGS Module \n\nOne of the main motivations for securing a system internally is the need to secure some of its operations, as well as to isolate some pro- cessing steps of the entire stream management. The security features should be coordinated by the application register module, which main- tains and manages interactions between inner graph nodes of the IoT \n\n270 6 Cloud and Fog Computing for the IoT \n\n\nSecurity Rules \u03a8 \n\nGraph State \n\nSecurity Manager \n\nPOST PUT \n\nGraph Layer n+1 \n\nID (S) Interests (P) Rules \n\nAuth pm on interestk \n\nOK \n\nGET \n\nQueue Server \n\nPMSV \n\nGraph Framework \n\nGRAN \n\nApplication Register \n\nNode Registration & Queue Manager \n\ngn \n\npm \n\nFigure 6.18 The application register module structure with security elements. PMSV and GRAN modules interact with a storage entity to manage authorization in the graph. \n\nplatform using di\ufb00erent communication protocols, as requested by the architecture itself. In order to accomplish the operational functionalities listed previ- ously, the application register module has two main components, as shown in Figure 6.18. \n\n\u2022 The graph state database is responsible to maintain all information about the current graph status. Since this component is not critical from a performance viewpoint, it has been implemented through a simple relational SQL database. \u2022 The node registration and queue manager (NRQM) module is responsible for managing communications with existing graph nodes, as well as with external entities that ask to join the big stream architecture. \n\nTo add security features to these modules, the application register de\ufb01nes entities and modules speci\ufb01cally related to security manage- ment and coordination. As shown in Figure 6.18, the application reg- ister comprises the following additional modules: \n\n\u2022 The policy manager and storage validator (PMSV) is responsible for managing and verifying authorization rules, interacting with the persistent storage element, which maintains authorization policies. \u2022 The graph rule authorization noti\ufb01er (GRAN) interacts with pub- lisher graph nodes and veri\ufb01es if listener nodes are authorized to receive streams associated with speci\ufb01c topics. \n\n6.4 Big Stream and Security 271 \n\n\u2022 A persistent storage entity (e.g., a non-relational database) maintains authorization rules speci\ufb01ed by publisher graph nodes. \n\nIf a processing node pm asks to register with the IoT platform, requiring it to join the graph, after authentication (e.g., using a username/password pair, cryptographic certi\ufb01cates, ACLs, OAuth) there are two cases that require the use of security mechanisms and involve the de\ufb01ned modules: \n\n\u2022 a registration request coming from a node that is willing to become a publisher node for a secured stream (e.g, an application node cre- ated by developers of company C); \u2022 a registration request sent by a node, asking to be attached as a lis- tener for some streams. \n\nIn the \ufb01rst case, when an external process pm requests to register to the graph architecture, in order to secure one or more of its own streams, it updates the PMSV module. After indicating its published topics, it speci\ufb01es some policies and rules, to be stored, together with the assigned operative graph layer, in the persistent security storage by PMSV itself. These rules will be checked in case of future subscription requests for the node. In the second case, an external process pm, upon issuing a request to attach to the graph platform and to become a node, provides information related to its identity and also speci\ufb01es the interests to which it wants to subscribe. The application register, having identi\ufb01ed the graph layer into which the new node could be placed, takes charge of these interest speci\ufb01cations, passing then to the PMSV, which acts as follows. For each provided interestk, the PMSV module interacts with the persistent storage entity, performing a lookup for a match between the interest and stored publishing policies, and re\ufb01ning this lookup with layer matching: \n\nmatch = {layer = x OR layer = (x + 1)} AND \n\n{interestk \u2208\u03a8} (6.3) \n\nwhere x stands for the identi\ufb01ed listener graph layer; indicates each single speci\ufb01ed interest, extracted from the attaching request; repre- sents the persistent storage element; and contains a list of publisher nodes that have to authorize subscriptions. If match contains some positive results (e.g., gm node \u2013 a node in the graph), these are forwarded to the GRAN module, which \n\n272 6 Cloud and Fog Computing for the IoT \n\ninteracts with discovered publisher nodes, sending them the identity of the requesting listener node and asking them to allow or deny subscription to the requested topics. This response is sent back to the GRAN module, which analyzes it and, in compliance with the application register, authorizes or rejects the listener graph node subscription. In order to better explain the behavior of the application register module in relation to the join operation of an external entity that asks to become a graph listener, in Listing 6.3 we detail the interactions involved through a pseudocode representation. \n\nListing 6.3 Pseudocode representation of the operations of the application reg- ister when an external process asks to become a graph listener in the big stream architecture. \n\nNodeIdentityCertificate = { NodeInfo = {....}; INTERESTS = {interest_1, interest_2, ..., interest_N}; } MAIN() { Pm = receive_join_request(NodeIdentityCertificate); authenticated = authenticate_node(Pm); if (authenticated is TRUE) { x = identify_graph_layer_for_node(Pm); foreach (interest interest_k in INTERESTS) { Match = send_request_to_PMSV(layer = (x OR x+1), interest = interest_k); if (Match is EMPTY) { REPLY_DENY(topic = interest_k, destination_node = Pm); } else { foreach (GraphNode Gm in Match) { allow = request_grant_to_owner_via_GRAN(topic = interest_k, owner = Gm, listener = Pm); if (allow is FALSE) { REPLY_DENY(topic = interest_k, destination_node = Pm); } else { REPLY_SUCCESS (topic = interest_k, destination_node = Pm); } } } } } } \n\n6.4 Big Stream and Security 273 \n\nREPLY_DENY(topic, destination_node) { send_DENY_response_to_destination(required topic = topic); } REPLY_SUCCESS(topic, destination node) { send_SUCCESS_response_to_destination(required topic = topic, security_parameters = (....)); } \n\nThe processing nodes in the graph architecture can be both listeners and publishers at the same time, so that the previously detailed mecha- nisms can be applied together, without any constraint on the execution order. The \ufb02ows shown in Figure 6.18 represent the interactions in this mixed case. The rule on node authority, restricted to the same layer and to the next one, decreases lookup times in rule matching execution. Moreover, external smart object producers could also request a totally \u201csecured\u201d path, from source to \ufb01nal consumer. These con- straints have a higher priority than policies de\ufb01ned by publisher graph nodes, being speci\ufb01ed by the stream generators. In this way, these external priority rules are stored in the persistent storage elements as well, and when a new graph node registers to the proposed IoT platform, its graph-related policies are left out, and it is forced to comply with the external rules. \n\n6.4.4 Securing Streams inside Graph Nodes \n\nThe graph framework comprises several processing entities, which perform various computations on incoming data, and each represent- ing a single node in the graph topology. The connection of multiple listeners across all processing units de\ufb01nes the routing path of data streams, from producers to consumers. All nodes in the graph can be input listeners for incoming data and output producers for successor graph nodes. Since each graph node is the owner of the stream generated by its processing activity, it is reasonable to assume that it could decide to maintain its generated stream \u201copen\u201d and accessible to all its interested listeners, or to applying security policies, isolating its own information and de\ufb01ning a set of rules that restrict the number of authorized listener nodes. In this latter case, a \u201csecure\u201d stream is created and encrypted using algorithms selected by the owner. Each listener is thus required to decrypt incoming data before performing any processing. These encryption/decryption operations can be \n\n274 6 Cloud and Fog Computing for the IoT \n\n\nGraph Framework \n\nCore Layer n \n\nApplication Layer m \n\nInput Queue \n\nDecipher Cipher \n\nBroker \n\nProcessing Input Queue Listener \n\nData Filter Output Producer \n\nFigure 6.19 Detail of the structure of a single graph node: the decryption module is activated when the node is a listener of a secured stream, while the encryption module is activated if the node generates a secured stream. \n\navoided if listeners adopt homomorphic encryption [], allowing them to carry out computations on ciphertext, instead of on plaintext. This generates an encrypted result that matches one performed on the plaintext, but without exposing the data in each of di\ufb00erent steps chained together in the work\ufb02ow. Homomorphic encryption allows computation to be executed in the encrypted domain, thus providing end-to-end security, and avoiding the need for hop-by-hop encryption/decryption. In Figure 6.19, the modules inside a graph node are shown: the bro- ker of the core layer forwards streams to interested graph nodes, plac- ing these data in the input queues of each. The output stream generated by the processing of these nodes, will be sent to the same broker in the core layer, which is linked to the broker of the next graph layer, and which \u201cspreads\u201d generated streams to all interested nodes. Some of these modules will be activated only in speci\ufb01c situations. In partic- ular, the node illustrated acts as a listener of a \u201csecured\u201d data stream, so it has to decrypt an incoming message, activating the decryption module. It also acts as a producer of a \u201csecure\u201d stream and so it has to encrypt its processed streams with the encryption module before for- warding it, thus hiding the stream from unauthorized listener graph nodes. This is the case in the earlier example in which a graph node that is already a listener of the secured stream owned by company C, wants to secure the stream generated by its processing. It is important to point out that each graph node controls its gen- erated \ufb02ow, with visibility of only one step. This means that a listener of a \u201csecured\u201d \ufb02ow can publish an \u201copen\u201d stream and vice versa, thus producing \u201chybrid\u201d path combinations. These, in the stream \ufb02ow from \n\n6.4 Big Stream and Security 275 \n\nTable 6.1 Comparison between graph framework actors and OAuth roles. \n\nGraph framework actor OAuth role \n\nPublisher graph node, owner of the outgoing data stream Resource owner \n\nListener graph node, willing to subscribe to interested topics Consumer \n\nInfrastructure routing element (broker in a pub/sub paradigm) Provider \n\nIoT source to \ufb01nal consumer, produce a combination of \u201csecured\u201d and \u201copen\u201d steps. Referring to the example in which company C generates a \u201csecured\u201d stream of data coming from its sensors, an IoT developer might decide to create a new graph node listening to both the secured stream of company C and the stream of another company, D. In the processing unit of the new graph node, the developer can aggregate and transform the input streams, generating new and di\ufb00erent output streams, which can be published in \u201copen\u201d mode, since the developer is the owner of this new produced stream. Depending on the inner organization of the IoT architecture, there could be a parallel between actors enrolled in the graph framework and OAuth roles, as illustrated in Table 6.1. More precisely, OAuth roles could be detailed as follows. \n\n\u2022 Resource owner: the entity that owns the required resource and has to authorize an application to access it, according to authorization granted (e.g., read/write permission). \u2022 Consumer:the entity that wants to access and use the required resource, operating in compliance with granted policies related to this resource. \u2022 Provider: the entity that hosts the protected resource and veri\ufb01es the identity of the consumer that issues an access request to this resource. \n\nAs previously stated, each graph node can apply cryptography to its streams, using encryption and decryption modules. The security mechanisms leave a few degrees of freedom to developers, who can adopt their own solutions (e.g., using OAuth tokens) to secure streams, or rely on standard secure protocols, thus adopting well- known and veri\ufb01ed solutions. An overall view of the envisioned IoT architecture is shown in Figure 6.20, showing all component modules and their interactions. \n\n\nAcquisition Normalization \n\nNormalization \n\nNormalization \n\nNormalization \n\nNormalization \n\nNormalization \n\nraw data \n\nraw data \n\nraw data \n\nraw data \n\nraw data \n\nGraph Framework \n\nCoAP \n\nMQTT \n\nHTTP OFS OFS \n\nDW \n\n= IGS \n\nIoT Networks \u2026 \n\n\u2026 \n\nf1 f2 \n\nf6 f3 g2 \n\ng1 \n\ng3 \n\ng4 f5 f4 \n\nCore Graph \n\nPMSV Security Rules \n\nGraph State \n\nQueue Server \n\nPOST PUT GET \n\nGRAN \n\nApplication Register \n\nSecurity Manager \n\nNode Registration & Queue Manager \n\nApp. Graph \n\nCustomer/Consumer \n\nApplications \n\nFigure 6.20 Complete IoT cloud architecture, including proposed security modules and showing di\ufb00erent interactions, from incoming stage to \ufb01nal consumer noti\ufb01cation. \n\n6.4 Big Stream and Security 277 \n\n6.4.5 Evaluation of a Secure Big Stream Architecture \n\nThe evaluation involves a Java-based data generator, which: \n\n\u2022 simulates events arrivals from IoT sensors networks; \u2022 randomly selects an available protocol (HTTP, CoAP, MQTT); \u2022 periodically sends streams to the corresponding interface in the acquisition module. \n\nOnce received, data are forwarded to the dedicated normalization module, which enriches them with parking membership information from an external SQL database. The module structures the stream in a JSON schema compatible with the architecture. Once it has completed its processing, it sends the structured data to the graph framework, which forwards the stream following paths based on routing keys, until the \ufb01nal external listener is reached. The graph considered in our experimental set-up comprises eight core layers and seven application layers, within which di\ufb00erent graph topologies (from 20 to 50 nodes) are built and evaluated. The proposed architecture was evaluated by varying the incoming data stream generation rate between 10 msg/s and 100 msg/s. The \ufb01rst evaluation, which represents a benchmark for our performance analysis, uses the platform without security mechanisms. Then, security mechanisms were introduced into the graph framework module, in order to assess the impact of a security stage on the overall architecture. The \ufb01rst performance evaluation was conducted by measuring the delay between the time when normalized data were injected into the graph framework and the time instant at which the message reached the end of its routing, becoming available for external consumers/customers. In order to consider only the e\ufb00ective over- head introduced by the architecture, and without taking into account implementation-speci\ufb01c contributions, performance results were obtained by subtracting the processing time of all core and application nodes. Finally, these times were normalized over the number of computational nodes, in order to obtain the per-node overhead introduced by the architecture, in a way that is independent of the implemented routing and topology con\ufb01guration. The second performance evaluation adopted the same structure as the unsecured implementation, but introduced security mechanisms inside graph nodes, through the adoption of symmetric encryption to \n\n278 6 Cloud and Fog Computing for the IoT \n\nencrypt/decrypt operations, as described in Section 6.4.4. In order to guarantee a tradeo\ufb00between security-level and reliability, we chose the Advanced Encryption Standard (AES), which is a symmetric cryptosystem, in its 256-bit key version [117]. AES is a block cipher based on a substitution and permutation (SP) combination, working on 128-bit blocks. The chosen key size determines the number of repetitions of transformation rounds that convert the input, applying several processing stages and depending on the encryption key. The strength of AES256 derives from its key space \u2013 a possible 256-bit key \u2013 which a\ufb00ects the time needed to made a successful brute-force attack on a system in which it is implemented. In the second evaluation, we also implemented a new version of the processing core and application nodes, applying security at both input and output stages of the single graph node, with the following behavior: \n\n\u2022 If the processing node has received an AES 256-bit decryption key from the application tegister, it then uses this key to decrypt incom- ing messages, returning plaintext useful for processing operations. \u2022 If an AES 256-bit encryption key was provided by the application register to a graph node, it then encrypts the processed stream using this key, before forwarding the stream to the relevant exchange. \n\nThis security model is also applicable also to the example in which company C would like to secure its paths into the graph framework. In the second evaluation, encryption and decryption keys were pro- vided to all graph nodes, in order to secure all the intermediate steps followed by streams owned by the company. Di\ufb00erent topologies were obtained by varying the subset of nodes deployed, from 20 to 50, and the data generation rate, from 10 msg/s to 100 msg/s. The results are shown in Figure 6.21. The stream delay can be given using the following expression: \n\nTprocessingfreq = Tout \u2212Tin \u2212 \n\nN\u2211 \n\nk=1 GPk \n\nN (6.4) \n\nwhere Tout is the instant at which parking data reach the last appli- cation processing node; Tin indicates the instant at which normalized data comes to the \ufb01rst core layer; and GPk is the processing time of a graph node k \u2208{1, \u2026 , N}. \n\n6.4 Big Stream and Security 279 \n\n\nNoEncryption - Rgen = 10 msg/s \n\nNoEncryption - Rgen = 20 msg/s NoEncryption - Rgen = 50 msg/s NoEncryption - Rgen = 100 msg/s \n\nAES256 - Rgen = 10 msg/s AES256 - Rgen = 20 msg/s AES256 - Rgen = 50 msg/s \n\nAES256 - Rgen = 100 msg/s \n\n350 \n\n300 \n\n250 \n\n200 \n\n150 \n\n100 \n\n50 \n\n0 20 25 30 35 40 45 50 Nodes [num] \n\nTime [ms] \n\nFigure 6.21 Average stream delay (ms) related to graph framework processing block, showing per-node time, in the case of unsecured communication as well as the case of adoption of symmetric encryption. \n\nIn order to investigate the bene\ufb01ts and drawbacks of security solutions other than symmetric encryption, we implemented an asymmetric-cryptography version of the graph processing nodes, adopting RSA [132] with a 512-bit key. This is a private-public key cryptosystem. In a third evaluation scenario, the symmetric cryp- tosystem was replaced with private/public RSA certi\ufb01cates provided to the graph nodes by the application register module. The results, in terms of stream delay, are shown in Table 6.2. They highlight that an asymmetric cryptosystem is a bad choice for graph inter-node security. Asymmetric solutions might be adopted outside of the graph nodes, when an external node is willing to become an operating entity of the graph framework, challenging an authentica- tion transaction with its signed certi\ufb01cate, which allows for veri\ufb01ca- tion of its identity by the application register. Therefore, in the joining phase, asymmetric solutions could be used if time is not the main constraint. \n\n280 6 Cloud and Fog Computing for the IoT \n\nTable 6.2 Average stream delay related to the adoption of asymmetric encryption solution (RSA) into the graph framework processing block. \n\nNumber of nodes Stream delay (ms) \n\nMessage rate (msg/s) 50 100 \n\n20 128 10890 \n\n25 156 12962 \n\n30 2783 13841 \n\n35 10104 14048 \n\n40 11283 14515 \n\nIn order to better highlight this \ufb01nal analysis of the evaluation results, in Figure 6.22 a logarithmic-scaled version of the results is shown, evaluating the logarithm of the stream delay as a function of the number of nodes in the graph for: \n\n\u2022 no encryption, \u2022 symmetric encryption (AES256) \u2022 asymmetric encryption (RSA512). \n\nWarning region \n\nForbidden region \n\nWorking region \n\n20 1 \n\n2 \n\n3 \n\n4 \n\n5 \n\n6 \n\n7 \n\n8 \n\n9 \n\n10 \n\n25 30 \n\nNodes [num] \n\nLn(Per-Node Time) \n\n35 40 \n\nNoEncryption - Rgen = 50 msg/s NoEncryption - Rgen = 100 msg/s AES256 - Rgen = 50 msg/s AES256 - Rgen = 100 msg/s RSA512 - Rgen = 50 msg/s RSA512 - Rgen = 100 msg/s \n\nFigure 6.22 Logarithmic representation of the stream delay as a function of the number of nodes of the graph, evaluated both with and without security mechanisms. \n\n6.5 Fog Computing and the IoT 281 \n\nTwo values of data generation rate were used: 50 and 100 msg/sec. The results suggest that there are three main performance regions in which the proposed big stream platform could be considered: \n\n\u2022 the working region, approximately around the \u201cNoEncryption\u201d curves, for which the system has the benchmark results, and where processing does not introduce heavy delays; \u2022 the \u201cWarning\u201d region, around the AES256 curves, in which delays introduced by security steps degrade performance a little, while maintaining good quality of service (QoS); \u2022 the \u201cForbidden\u201d region, around the RSA512 curves, in which the system incurs major delays, which may cause crashes and dropping of service, invalidating QoS and any service level agreements (SLAs) signed with data stream producers and consumers. \n\n6.5 Fog Computing and the IoT \n\nThe role of cloud computing in the IoT is gaining more and more attention. Most research has so far been focused on smart objects, and in particular on the de\ufb01nition of e\ufb03cient, lower-power, IP-based communication protocols and mechanisms. Many of these areas have now been signi\ufb01cantly addressed. IoT solutions have been deployed and brought to the market in several application scenarios, from home automation to smart cities. Most of these fragmented and vertical solutions rely on the cloud to provide centralized access to services exploiting data that are sent uplink from deployed sensors to cloud storage. Typically, mobile apps \u201cconsuming\u201d such services are made available to end-users. However, this approach, which is useful for the IoT, does not fully exploit the potential of the cloud. Fog computing, also referred to as \u201cEdge Computing\u201d, is a novel paradigm that was introduced to meet requirements such as mobility support, low latency, and location awareness [205]. Fog computing aims to moving some cloud-based computation and storage to the edge of the network. The fog is a cloud close to the ground and, as such, provides end users with computing functionality that is closer to them, thus improving performance. It brings low-latency to consumers and enables development of new applications that take into account location-related information. \n\n282 6 Cloud and Fog Computing for the IoT \n\nThe characteristic features of fog computing are the following: \n\n\u2022 wide geographical distribution, in contrast to the centralization envisioned with the cloud; \u2022 subscriber model used by the players in the fog; \u2022 support for mobility. \n\nFog computing brings a new approach to Internet access networks by making computation, storage, and networking resources available at the edge of access networks. This improves performance, minimiz- ing latency and maximizing availability, since resources are accessible even if Internet access is not available [215]. Fog-based solutions aim at introducing an intermediate architec- tural layer in which resources and applications are made available in the proximity of end devices, thus avoiding the need for continuous access to the cloud. While cloud-only architectures can provide a solu- tion to scalability and \ufb02exibility issues by distributing resources among multiple servers, this approach has some weaknesses, such as: \n\n\u2022 latency \u2022 availability/dependence on Internet connectivity for operations \u2022 lack of \ufb02exible networking \u2022 quality of service/experience \u2022 security and privacy. \n\nDue to its bene\ufb01ts over cloud-based architectures, especially if time is a critical issue or Internet connectivity is poor or absent, fog comput- ing is expected to play a key role in the deployment of IoT applications. The fog is not intended to replace the cloud, but rather to comple- ment it, in order to provide location-aware and real-time services, thus enabling new applications that could have not been deployed other- wise. Fog-based access networks are based on the presence of highly specialized nodes, called fog nodes, which are able to run distributed applications at the edge of the network. In particular, the deployment of computing resources on Internet access networks allows for dynamic activation of Virtual Machines (VMs) on fog nodes. For this reason, the cloning and synchronization techniques of VMs at the core of this work \ufb01t perfectly into Fog-based infrastructures, as will be discussed in more detail in the following sections. The proposed architecture can protect local resources by providing remote access to their replicas in a transparent way. Local resources \n\n6.6 The Role of the IoT Hub 283 \n\nare kept synchronized by multiple clones of the same machine, thus achieving a high level of reliability and load balancing. Smart manage- ment of the activation/deactivation of replicas and the choice of the most appropriate fog node to run the clone allows for optimization of the usage of CPU and memory on the infrastructure, according to the speci\ufb01c real-time resource requirements of the applications involved. A lightweight alternative to VMs are containers, which provide a more \ufb02exible environment for \u201cdisposable applications\u201d like the IoT Hub. Container platforms like Docker [216] are gaining increasing attention for fog computing applications. Moving from a centralized to a decentralized paradigm enables processing to be o\ufb04aded to the edge, reducing application response times and improving overall user experience. This process will play a fundamental role in IoT. Several authors have described how a container-based architec- ture could be e\ufb03ciently used for dynamic networking applications [217, 218]. Ramalho and Neto have compared existing lightweight and hypervisor-based approaches for edge computing and presented an e\ufb03cient networking approach [219]. Morabito has presented a novel approach to the application of a lightweight virtualization technology (such as Docker) to constrained devices with a negligible overhead [220]. In this work a containerized version of the IoT Hub, based on Docker, will be considered. \n\n6.6 The Role of the IoT Hub \n\nThe billions of IoT sensing/actuating devices in the IoT will gener- ate an unprecedented amount of data, which will need to be man- aged properly in order to provide highly available and robust services. Although an IP-based IoT would make it possible to address smart objects directly, the following potential drawbacks exist: \n\n\u2022 In order to extend their battery lifetimes, smart objects may be duty-cycled and thus not always accessible. \u2022 Smart objects might be unable to handle a large number of con- current requests, thus leading to service disruption and becoming possible targets for denial-of-service attacks. \u2022 In some circumstances (for instance, to minimize memory footprint when the available in-device memory is critically low), smart objects may play the role of clients rather than servers. \n\n284 6 Cloud and Fog Computing for the IoT \n\nIEEE 802.15.4 IEEE 802.11 Bluetooth \n\nHeterogeneous Networks \n\nConsumers \n\nIoT Hub \n\nFigure 6.23 The IoT nub can manage multiple networks of heterogeneous smart objects and enables access to resources by external consumers that should not be aware of the ow-level details of communications. \n\nIn all the above cases, the presence of an intermediate network element operating at the application layer \u2013 typically the border router \u2013 is desirable. Such a node could integrate several function- alities that would reduce the processing load on smart objects and help overcome some of the problems discussed above (e.g., caching). This resourceful node, called the IoT Hub is shown in Figure 6.23. It helps move some of the processing load towards the edge of the network, following the fog computing paradigm [205]. Even though this approach will surely bring several bene\ufb01ts, the role of the IoT Hub then becomes central in the IoT architecture foreseen, since it will be responsible for processing all requests. As billions of smart objects are expected to be deployed, e\ufb03cient data processing has led to reliance on the cloud. The expression \u201cCloud of Things\u201d is sometimes used to refer to the interaction between IoT and the cloud [221]. Aazam et al. have set out an architecture for inte- grating the cloud and the IoT is proposed, based on a network element called a smart gateway [222]. This is intended to act as intermediary between heterogeneous networks and the cloud. The role of the smart gateway is similar to that of the IoT Hub, in terms of supporting sev- eral heterogeneous networks. However, the role of the cloud is mainly envisioned as being for data aggregation and storage, and usable by end-users to access data. In this approach, data are sent uplink, mak- ing it impossible to directly address and act on response from smart objects, as is supposed to happen in the IoT. \n\n6.6 The Role of the IoT Hub 285 \n\nAt the opposite extreme, in the current paper we envision that the cloud, by hosting replicas of the IoT Hub, is used to give direct and e\ufb03cient access to resources, while providing desirable features such as seamless access by external clients, security, and high availability. \n\n6.6.1 Virtualization and Replication \n\nIn order to increase the robustness of an hub-oriented IoT architec- ture, we propose a cloud-supported replication mechanism for IoT Hubs in order to e\ufb03ciently manage CoAP resources in a scalable and secure way. The proposed mechanism uses cloud platforms to clone and virtualize IoT Hubs. The replicas are full copies of the IoT Hubs and so implement all their functionalities. Accessing the replicas is therefore like asking a delegate for the same information. This brings several bene\ufb01ts: \n\n\u2022 A unique cloud-based interface for accessing resources is exposed. \u2022 The actual implementation details of the IoT Hub are hidden from communications, thus protecting the IoT Hub and the smart objects behind. \u2022 The cloud platform may introduce balancing policies in order to scale up or down the number of replicas according to current needs and the number of incoming/estimated requests and resources to be managed. \n\nThis solution enables remote access to resources in networks in a fully transparent and standardized way. In order to achieve our goals, a new application layer for IoT networks is designed and developed. In par- ticular, we focus on the design of an architecture that allows access by external clients, by virtualizing the functionalities of an IoT network. The details of the IoT network, such as its location or its actual imple- mentation, are kept hidden from users and external clients seeking to access resources. In other words, resource access by remote clients will be mediated by the cloud platform, which provides a standard and secure front end. \n\n6.6.1.1 The IoT Hub The IoT Hub does not have the same strict requirements on energy consumption and processing capabilities as other smart objects and it is thus useful to provide relevant features to a constrained network. The IoT Hub is placed at the edge of the constrained network and plays \n\n\n![Image](/src/assets/generated_images/iot_p297_i0.png)\n286 6 Cloud and Fog Computing for the IoT \n\n\nApplication Layer \n\nTransport Layer \n\nNetwork Layer \n\nPhysical/Link Layer \n\nProtocol stack Functional plane \n\nBorder Router \n\nIP \n\nCoAP HTTP MQTT Resource Directory Cache C2C Proxy H2C Proxy Replica Manager \n\nUDP TCP \n\nIEEE 802.15.4 IEEE 802.11 ... \n\nFigure 6.24 Protocol stack and functional modules implemented by an IoT Hub. \n\na fundamental role by implementing the functions \u2013 summarized in the functional plane and mapped in the protocol stack \u2013 shown in Figure 6.24. \n\n\u2022 LoWPAN border router: at the network layer, the IoT Hub is the gate- way between one or more constrained networks (e.g., IEEE 802.15.4) to which it belongs (via its radio interfaces). \u2022 CoAP/CoAP (C2C) proxy: at the application layer, this provides proxying capabilities for CoAP requests coming from external clients that should reach internal constrained nodes. \u2022 HTTP/CoAP (H2C) proxy: at the application layer, this provides cross-proxying (protocol translation) between HTTP and CoAP in order to let external HTTP clients access CoAP resources hosted by smart objects. \u2022 Resource directory: the IoT Hub maintains a list of all CoAP resources available in the constrained network. These resources may have been gathered through several mechanisms, such as those described in Chapter 4. \u2022 Cache: in order to avoid unnecessary load on smart objects and to minimize latency, a cache is kept with a representation of the most recently accessed resources. \u2022 Replica manager: this is a software module responsible for the coor- dination of and synchronization between the IoT Hub and its repli- cas. \n\nDue to the constrained nature of smart objects, they cannot typi- cally implement strong security mechanisms and access policies, for instance those related to authorization, in which the IoT Hub may act \n\n6.6 The Role of the IoT Hub 287 \n\nas a \ufb01lter for incoming requests in order to limit access to speci\ufb01c resources. Because of all the functionalities outlined above, the IoT Hub may su\ufb00er from the following critical issues, which may under- mine the lifecycle of a constrained IoT network: \n\n\u2022 The IoT Hub is a bottleneck of the architecture, since all tra\ufb03c must pass through it even if it is not a communication endpoint. \u2022 Failure of the IoT Hub would make the resources hosted by smart objects temporarily or permanently unavailable. \n\nIt is necessary to relieve the IoT Hub from some of this load in order to guarantee that resources can be accessed with high availability in a secure and seamless way. In this section, we propose an approach that relies on on the cloud to provide virtual replicas of the IoT Hub. Replicas of the IoT Hub are fully functional clones, which may be used by any external client to access resources in the same way as they would do with the actual IoT Hub. Interacting with resources through the replicas gives an access point that is di\ufb00erent from the real (physical) IoT Hub, thus decoupling the constrained network management function and granting access to external clients. Replicas of the IoT Hub are synchronized through a dedicated MQTT-based protocol, which is used to transfer copies of the resources from the IoT Hub to the replicas in a pub/sub model. Replicas can be instantiated on the \ufb02y, according to particular needs, thus also acting as load balancers (according to policies which may depend on the number of connected clients and smart objects) and as recovery facilities in the event of temporary failure of the real IoT Hub. \n\n6.6.1.2 Operational Scenarios Resource access through the proposed cloud-based platform can occur according to the following three operational models imple- mented by a smart object: \n\n\u2022 CoAP server \u2022 observable CoAP server \u2022 CoAP client. \n\nPolling Resources If the smart object is a CoAP server, it can receive requests to access its hosted resources. In this case, as shown in Figure 6.25, the message \n\n\n![Image](/src/assets/generated_images/iot_p299_i0.png)\n288 6 Cloud and Fog Computing for the IoT \n\n\n4 \n\n5 6'' \n\n6' 6 7 \n\n8 \n\n1 \n\n2 \n\nHTTP/CoAP HTTP/CoAP \n\n3 \n\nCoAP \n\nS.O. (Server) \n\nIoT Hub \n\nVPN IoT Hub Replica \n\nIoT Hub Replica \n\nIoT Hub Replica \n\nCloud Access Control \n\nConsumer \n\nFigure 6.25 Message \ufb02ow for the polling scenario: a HTTP/CoAP client requests a resource to the cloud platform, which internally selects a suitable IoT Hub replica and forwards the request. The request reaches the smart object only if neither the replica nor the IoT Hub have stored a fresh cached representation of the resource. Other replicas (which are not in the path of the request) are kept in sync using the synchronization protocol. \n\n\ufb02ow is as follows: (1) the external client sends a HTTP or CoAP request to the cloud platform front-end, which (2) forwards the request to one selected replica of the IoT Hub. If the replica has a \u201cfresh\u201d match- ing cached resource, it can return this immediately; otherwise (3) the replica forwards the request to the actual IoT Hub (which is securely connected through a VPN tunnel). If the IoT Hub has a fresh matching cached resource, it can return it immediately; otherwise (4) it acts as a reverse proxy and forwards a (and, if needed, translated) CoAP request to the CoAP server, which (5) returns the resource. At this point, the returned resource is cached by the IoT Hub, and (6) returned to the replica, which, in turn, (7\u20138) sends it back to the client. The resource cached at the IoT Hub is then (6\u2032 and 6\u2032\u2032) synchronized with its repli- cas, in order to speed up and e\ufb03ciently manage subsequent requests targeting the same resource. \n\nObserving Resources The Observe option [9] is a CoAP option that allows resource observ- ing. According to this speci\ufb01cation, a CoAP client can send a single request, including an Observe option with a value of 0 (register), in order to register its interest in receiving updates related to the targeted resource. The CoAP server sends a response each time the resource value is updated. In this case, multiple responses are sent after a single request. The Observe option allows a noti\ufb01cation-based communi- cation model to be implemented, thus reducing network tra\ufb03c. The observing scenario is shown in Figure 6.26. If the targeted smart object is a CoAP server which implements the Observe option, it can receive \n\n\n![Image](/src/assets/generated_images/iot_p300_i0.png)\n6.6 The Role of the IoT Hub 289 \n\n\n4 \n\n5 6'' \n\n6' 6 7 \n\n8 \n\n1 2 \n\nCoAP CoAP \n\n3 \n\nCoAP \n\nS.O. (Server) \n\nIoT Hub \n\nVPN IoT Hub Replica \n\nIoT Hub Replica \n\nIoT Hub Replica \n\nCloud Access Control \n\nConsumer \n\nFigure 6.26 Message \ufb02ow for the observing scenario: a CoAP client requests a resource to the cloud platform using the CoAP Observe option. The cloud platform internally selects a suitable IoT Hub replica and forwards the request. The observe request is then forwarded to the IoT Hub and to the smart object thus creating an \u201cobserve chain\u201d. Resource updates are then sent from the smart object back to the IoT Hub, then to the replica, and \ufb01nally to the CoAP client. Other replicas (which are not in the path of the request) are kept in sync using the synchronization protocol. \n\nrequests to access its hosted resources, which may be either observ- able or not. In the latter case, requests are handled as in the polling case. In the former case, instead, the message \ufb02ow resembles that of the polling scenario, but: \n\n\u2022 the IoT Hub observes the resource \u2022 the external client observes the cached resource on the replica. \n\nWhen the resource is updated: \n\n\u2022 the smart object will send a noti\ufb01cation to the IoT Hub; \u2022 the IoT Hub will synchronize the resource with its replica; \u2022 the replica will send a noti\ufb01cation to the external observing client. \n\nPushing Resources Sometimes, the memory constraints of smart objects make it unfea- sible to let them act as CoAP servers. In this case, as shown in Figure 6.27, the smart object acts as a CoAP client and sends CoAP requests (POST and PUT) to the IoT Hub, which plays the role of an origin server, maintaining resources on behalf of the clients. If the smart object is a CoAP client, according to the semantics of CoAP methods, the following message \ufb02ow takes place: (1) the smart object sends CoAP POST requests to the IoT Hub in order to create resources and CoAP PUT requests in order to change their value. When the IoT Hub receives POST and PUT requests, after handling these requests as necessary, it stores them and (2, 2\u2032 and 2\u2032\u2032) synchronizes them \n\n\n![Image](/src/assets/generated_images/iot_p301_i0.png)\n290 6 Cloud and Fog Computing for the IoT \n\n\n1 \n\n2'' \n\n2' 5 \n\n6 \n\n3 \n\n4 \n\nHTTP/CoAP HTTP/CoAP \n\n2 \n\nCoAP \n\nS.O. (Client) \n\nIoT Hub \n\nVPN IoT Hub Replica \n\nIoT Hub Replica \n\nIoT Hub Replica \n\nCloud Access Control \n\nConsumer \n\nFigure 6.27 Message \ufb02ow for the pushing scenario: a smart object acting as a CoAP client posts and updates resources on the IoT Hub, which acts as origin server. All replicas are kept in sync using the synchronization protocol. External client can request resources, which will served by a replica. \n\non the replica. When (3) an external client sends an HTTP or a CoAP request to the cloud platform front end, (4) the latter forwards the request to one selected replica of the IoT Hub. Since the replica is synchronized with the IoT Hub, (5\u20136) the replica can respond immediately with the stored representation of the resource. \n\n6.6.1.3 Synchronization Protocol The synchronization protocol used in the architecture implements a pub/sub communication model. Communication follows a one-to- many pattern from the IoT Hub to all of its replicas. All messages are sent by the IoT Hub to an MQTT message broker (hosted on the cloud platform \u2013 see Figure 6.28a). Speci\ufb01c MQTT topics can be used to selectively target one, many, or all replicas in order to implement unicast, multicast, or broadcast communications respec- tively. The MQTT broker is managed by the cloud platform, using a VPN connection, for security and addressing reasons, as shown in Figure 6.28a. The IoT Hub and its replicas are all identi\ufb01ed by a system-wide identi\ufb01er, assigned by the designed cloud platform. Each IoT Hub includes a replica manager (RM), which is a dedicated software module responsible for the synchronization of the IoT Hub and its replicas. The RM comprises the following items, as shown in Figure 6.28b: \n\n\u2022 a replica registry (RR), which contains the list of the identi\ufb01ers of all the replicas of the IoT Hub; \u2022 an MQTT subscriber, which registers to the broker to receive mes- sages related to two topics (which may coincide in the case of the actual IoT Hub): \n\n\n![Image](/src/assets/generated_images/iot_p302_i0.png)\n6.6 The Role of the IoT Hub 291 \n\n\nMQTT \n\nIoT Hub Replica \n\nIoT Hub Replica \n\nIoT Hub Replica \n\nMQTT MQTT \n\nMQTT \n\nBroker VPN \n\nIoT Hub \n\n(a) \n\nMQTT Subscriber \n\nMQTT Publisher Replica Registry \n\nReplica id id1 id2 id3 id4 ... \n\nReplica Manager \n\n(b) \n\nFigure 6.28 (a) broker-based message \ufb02ow between the IoT Hub and its replicas. (b) internal structure of the replica registry module of the IoT Hub. \n\n\u2013 its own identi\ufb01er (idi) \u2013 the identi\ufb01er of the actual IoT Hub (idhub); \u2022 an MQTT publisher, which publishes messages to the broker, using the method pub(t, m), where t is the topic and m is the message to be published. \n\nThe IoT Hub is in charge of maintaining full synchronization of its resources with its replicas, in order to ensure that all requests are served in the same way, regardless of the speci\ufb01c replica that was targeted by the client. Synchronization comes into play every time a resource on the IoT Hub changes. This can be caused by di\ufb00erent events. At startup, a replica of the IoT Hub needs to synchronize with the actual IoT Hub. The procedure is shown in Figure 6.31. The RM of the replica publishes its idi to the topic idhub, in order to notify of its creation (pub(idhub, idi)). At this point, the IoT Hub updates its RR by adding idi and then starts publishing to the broker all the resources (R) \n\n292 6 Cloud and Fog Computing for the IoT \n\nusing the topic idi (pub(idi, R)), which guarantees that the new replica will receive the resources. When the synchronization procedure has ended, the replica will be automatically kept synchronized with the IoT Hub during the normal system lifecycle. When resources are polled for (as will be described in Section 6.6.1.2), the IoT Hub might \ufb01nd out that a resource targeted by some request has changed. A request targeting a resource that either has not been cached or is not considered fresh must be forwarded by the IoT Hub to the smart object. Upon receiving the response from the smart object, after updating its cache and forwarding the response to the requesting replica, the IoT Hub uses the synchronization protocol to publish the updated information to all of its replicas. When observing resources (as described in Section 6.6.1.2), the synchronization procedure resembles that for the polling case. When resources are pushed by smart objects to the IoT Hub (as described in Section 6.6.1.2), the IoT Hub uses the synchronization protocol to publish the updated information at all replicas. Note that this syn- chronization strategy is needed only for those replicas that are part of the request/response loop. In fact, as all resources are automatically synchronized with the request-issuing replica by design, the replica perfectly reproduces the behavior of the actual IoT Hub. In order to validate the feasibility of the proposed IoT architectural solution and to evaluate its performance, extensive experimentation was conducted. The evaluation focused on the resource management on both local and remote IoT Hubs and the synchronization mecha- nisms previously described The experimental setup was designed and deployed with the aim of creating a realistic scenario, with heterogeneous components and nodes in a local IoT network and the cloud. The main components are: \n\n\u2022 Smart objects: Real and virtual nodes with CoAP modules based on the Californium framework [94]. \u2022 IoT Hubs: Raspberry Pi model B [223] or independent VM instance running all the functional modules presented in Section 6.6.1.1 (resource discovery, proxy CoAP/CoAP and HTTP/CoAP, border router, cache and replica manager). \u2022 Virtualization platforms: Four di\ufb00erent virtualization con\ufb01gura- tions on both local and cloud platforms are considered: \u2013 Microsoft Azure [224] \u2013 Amazon EC2 [225] \n\n6.6 The Role of the IoT Hub 293 \n\n\u2013 Open Stack [226] on Microsoft Azure \u2013 Open Stack on a local physical machine. \u2022 Resource external consumer: Real and virtual external consumers implementing HTTP and CoAP modules to dynamically interact and consume resources managed by the platform and active IoT Hubs and smart objects. \n\nWe con\ufb01gured and tested multiple virtualization con\ufb01gurations in order to evaluate the performance of the designed IoT architecture both on local and remote VMs. In particular, the Open Stack layer was tested on a local installation at the Department of Information Engineering of the University of Parma and, at a later stage, on Microsoft Azure in order to obtain and measure more realistic results on a professional cloud infrastructure. The local Open Stack installation runs on a physical machine with two 1.6 GHz processors and 3 GB RAM, while the Azure con\ufb01guration was a VM with four 2.0 GHz cores and 8 GB RAM. These two platforms were used to dynamically manage replicas of active IoT Hubs and to handle resource synchronization and remote data access. A virtual instance of an IoT Hub replica is characterized by an hardware pro\ufb01le with a single-core 2 GHz processor; 1 GB RAM; and 8 GB disk space. The internal IoT Hub runs a Linux Ubuntu 14.04 LTS operating system with SSH remote access, Oracle Java VM [227], and all the required functional software modules already installed and con\ufb01gured. The following key metrics are de\ufb01ned to measure the performance at di\ufb00erent architectural layers: \n\n\u2022 IoT Hub replica creation time: the time required to create and run, on the target cloud infrastructure, a new instance of an IoT Hub replica. \u2022 Resource synchronization time: the elapsed time needed to synchro- nize a new resource between two IoT Hubs. \u2022 Resource access time: the time required to access and retrieve a response for a resource of interest. It can be associated with di\ufb00erent con\ufb01gurations: \u2013 direct and local access to the CoAP server smart object (e.g., if the consumer and the node are in the same network); \u2013 remote access through the cloud and communication with the physical hub; \u2013 remote access to the cached value stored on an IoT Hub replica. \n\n294 6 Cloud and Fog Computing for the IoT \n\n\u2022 CPU usage %: the percentage of CPU used by the IoT Hub core pro- cess. \u2022 Memory usage %: the memory percentage used by the core process of the IoT Hub. \n\nThe \ufb01rst phase of the experimental performance analysis focuses on the evaluation of the time required to create (from scratch) and run a new IoT Hub replica instance on di\ufb00erent virtualized cloud infrastruc- tures. The results are shown Figure 6.30. Each value has been obtained by averaging over 10 di\ufb00erent VM creation runs and has a con\ufb01dence interval of 99%. It can be observed that: \n\n\u2022 the average costs on remote and professional cloud infrastructures are comparable; \u2022 the cost is higher on local and non-optimized solutions (such as the Open Stack instance running in our department). \n\nWe note that the metric corresponds to the total amount of time required to create a new VM from scratch (starting from a pre- con\ufb01gured image and adding the time to start all the required services and architectural software processes). This cost should be considered only once for each IoT Hub replica and is signi\ufb01cantly written o\ufb00with the increase of the hub\u2019s lifetime. Native VMs on Microsoft Azure and Amazon EC2 have approximately the same creation time, while the Open Stack platform introduces a small delay associated with the additional overhead (of the platform itself) required to manage multiple servers. The second phase of the experimental analysis was focused on: \n\n\u2022 the evaluation of the time required for synchronization of resources between two IoT hbs (physical and virtual); \u2022 the time needed by an external consumer to access a target resource of interest in di\ufb00erent scenarios and con\ufb01gurations. \n\nFigure 6.29a shows, as functions of the number resources: \n\n\u2022 the total time required for the synchronization of a set of resources between an IoT Hub and its new replica; \u2022 the average time required to synchronize a single resource in the same set. \n\nThe results show that the average synchronization cost for a single resource is stable and, consequently, the total required time is pro- portional to the number of resources to be synchronized. The results \n\n6.6 The Role of the IoT Hub 295 \n\n0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 \n\n10 20 30 40 50 60 70 80 90 100 \n\nSync Time [ms] \n\nResource Number \n\nTotal Sync Time Resource AVG Sync Time \n\nResource AVG Sync Time \n\nTotal Sync Time \n\n(a) \n\n0 \n\n20 \n\n40 \n\n60 \n\n80 \n\n100 \n\nLocal Network Azure-VM RemoteCache Azure-VM Remote \n\nTime [ms] \n\nResource Access Type \n\nAVG Resource Access Time [ms] \n\n(b) \n\nFigure 6.29 (a) Average synchronization time with respect to the number of synchronized resources; (b) average remote resource access time in di\ufb00erent application scenarios. \n\n296 6 Cloud and Fog Computing for the IoT \n\n0 \n\n100 \n\n200 \n\n300 \n\n400 \n\n500 \n\n600 \n\nOpenstack Azure Azure AWS Openstack VM \n\nTime [ms] \n\nPlatform \n\nFigure 6.30 Average IoT Hub creation time on di\ufb00erent cloud platforms. \n\nReplica Manager (IoT Hub) \n\nidhub \n\nReplica Manager (replica) \n\nidi \n\nMQTT Broker \n\nStartup \n\npub(idhub, idi) \n\nidi Update Replica Registry pub(idi, R) \n\nR \n\nFigure 6.31 Synchronization procedure performed at startup of the replica of an IoT Hub. \n\nalso show that for a reduced number of resources, the impact of the cost of MQTT connection creation is only slightly relevant compared with the payload. Obviously, by increasing the number of resources synchronized using the same MQTT connection it is possible to reduce this e\ufb00ect and reach a stable value below 25 ms/resource. \n\n6.6 The Role of the IoT Hub 297 \n\nIn Figure 6.29b, the average time required by a consumer to access a resource of interest provided by a smart object is evaluated in di\ufb00erent scenarios. In particular, we have considered three di\ufb00erent con\ufb01gura- tions where: \n\n\u2022 the consumer is in the same local network as the target smart object; \u2022 the external actor accesses a cached value on the active IoT Hub replica on the Azure platform; \u2022 the consumer accesses a resource that is not cached on the IoT Hub replica and, consequently, there is a requirement for direct commu- nication between the virtual replica and the real IoT Hub. \n\nThe results show, as intuitively expected, that the quickest access is obtained if the consumer is in the same network as the hub and does not require additional communication with remote infrastructure. However, if the consumer is an external actor, the average cost \u2013 still considering a realistic deployment through Microsoft Azure \u2013 is below 80 ms/resource. This value decreases if we consider a resource that is cached on the replica hub and does not require any additional communication with the local hub and, eventually, the smart object. Our experimentation also investigated the cost, in terms of CPU usage of an IoT Hub process, both for local (Raspberry Pi node) and remote (Microsoft Azure VM) instances. Figure 6.32 show the per- centage of CPU usage during a 60-s run of core activities, highlighting: \n\n\u2022 initialization of the main process and the creation of a set of \ufb01ve new resources on the local hub; \u2022 activation of the remote replica and its initialization; \u2022 synchronization of the group of \ufb01ve initial resources between local and remote replica hub; \u2022 sporadic addiction of single resources until the end of the experi- ment. \n\nThe results show how the initialization of the hub is an intensive activity on both local and remote instances. The CPU usage incurs a signi\ufb01cant one-time cost due to: \n\n\u2022 setting up the hub con\ufb01gurations (such as node identi\ufb01cation and software module selection); \u2022 establishing the VPN connection activating the CoAP server and the MQTT module (listener and publisher on speci\ufb01c topics); \u2022 starting up the resource directory. \n\n298 6 Cloud and Fog Computing for the IoT \n\n0 \n\n10 \n\n20 \n\n30 \n\n40 \n\n50 \n\n60 \n\n70 \n\n80 \n\n90 \n\n100 \n\n10 20 30 40 50 60 \n\nCPU % \n\nExecution time [s] \n\nLocal Raspberry Pi CPU % (1 Core 800 Mhz) \n\nRemote Azure VM CPU % (1 Core 2 Ghz) \n\nRemote Initialization \n\nResource Group Sync \n\nLocal Initialization \n\nSingle Resource Sync \n\nFigure 6.32 IoT Hub process CPU percentage usage for local (Raspberry Pi node) and remote (Microsoft Azure VM) instances. \n\nAfter the initialization phase, the CPU usage signi\ufb01cantly reduces for both resource group synchronization and sporadic management of new single resources. These activities represent common and frequent tasks for an active IoT Hub, which typically handles small variations in the set of managed resources during its lifetime. The main software process consumes a reduced amount of CPU (under 10%) for a small amount of time on both local and remote instances. In order to complete the analysis, Table 6.3 shows the average values (obtained through multiple independent runs and with a con\ufb01dence \n\nTable 6.3 Average CPU and memory utilization related to speci\ufb01c IoT Hub procedures on both local and remote instances. \n\nHub Init % Resource add % \n\nSync resource group % \n\nSync single resource % \n\n[Local] Raspberry Pi CPU 96 17.45 15.15 6.93 \n\n[Local] Raspberry Pi Memory +2,7 +0.02 +0.01 +0.002 \n\n[Remote] Azure VM Remote CPU 97 NA 34.22 1.93 \n\n[Remote] Azure VM Memory +1.9 NA +0.01 +0.001 \n\n6.6 The Role of the IoT Hub 299 \n\ninterval of 99%) of CPU and memory usage related to each speci\ufb01c hub procedure. The data con\ufb01rm the cost distribution, with a percent- age peak due to the initialization phase and lower values for group and single-resource synchronization. Memory utilization has been measured as the o\ufb00set with respect to the previous value and depends on the Java VM memory management [228]. In particular, when an object is no longer used, the Java Garbage Collector reclaims the underlying memory and reuses it for future object allocation without explicit deletion (no memory is given back to the operating system). An important aspect of a truly scalable architecture is the ability to quickly react to dynamic load changes, characterized by the rate of incoming requests that need to be served. The replication strategy proposed in this paper aims at providing a \ufb02exible and e\ufb03cient man- agement of IoT Hub replicas in order to guarantee that the response time remains below a given threshold. The virtualization approach provides a \ufb02exible solution that guarantees signi\ufb01cant availability and e\ufb03cient load balancing in highly dynamic IoT environments. In order to validate the designed replica management scheme, an additional experimental phase was carried out. Leveraging the same Microsoft Azure infrastructure used for all the other experiments, we measure the response time for incoming requests for smart object resources managed by the IoT Hub. In Figure 6.33, the e\ufb00ect of replica management is shown in terms of response time as a function of the incoming request rate. In particular, the results are the smallest number of requests that prompts creation of a new replica of the IoT Hub, which happens whenever the response time exceeds a threshold of 800 ms. The graph clearly shows that the response time tends to increase linearly as a function of the rate of requests until the IoT Hub reaches a breaking point associated with the maximum number of requests it can handle. This is clearly visible in the areas of the graph characterized by steep slopes. When a slope is detected, we activate a new replica, which brings the response time back to a value that meets our operational requirements. As the request rate increases, new replicas are created. As shown in Figure 6.33, we stopped our experimentation after the activation of three replicas. It is worth noting that: \n\n\u2022 a new replica is activated almost periodically (every 800 ms, accord- ing to the set threshold) \u2022 the slope of the response time between two consecutive activations is inversely proportional to the number of active replicas. \n\n300 6 Cloud and Fog Computing for the IoT \n\n200 \n\n400 \n\n600 \n\n800 \n\n1000 \n\n1200 \n\n1400 \n\n1600 \n\n1800 \n\n2000 \n\n0 500 1000 1500 2000 2500 \n\nResponse time [ms] \n\nRequests per second [n/s] \n\nFigure 6.33 E\ufb00ect of replica management with respect to the increasing number of requests per second (Microsoft Azure infrastructure). \n\nThe widespread adoption of container-based technologies has signi\ufb01cantly changed the way cloud and fog applications can be deployed and delivered to \ufb01nal users. In order to provide a thorough performance evaluation of the proposed solution, we also created a container-based version of the IoT Hub using the Docker plat- form [216]. The container has the same networking con\ufb01guration, features, and services as running on the VM-based version but shares an operating system kernel and features with other container instances running on the same server. The local experimentation was conducted using a VM running Ubuntu 14.04, with one 2.0 GHz processor and 1 GB RAM. Docker 1.11 was executed on top of this with the aim of evaluating the startup time of the dockerized IoT Hub. Such a low-end hardware pro\ufb01le, compared to realistic data center facilities, was purposely chosen to show the small footprint of the IoT Hub. In Figure 6.34, the average total startup time required to activate a fully operative IoT Hub instance, as well as the breakdown of container and IoT Hub services startup time, are shown. The results have been averaged over 1000 runs on the con\ufb01gured setup. The container startup time simply considers the activation of a Docker \n\n6.6 The Role of the IoT Hub 301 \n\n0 \n\n200 \n\n400 \n\n600 \n\n800 \n\n1000 \n\n1200 \n\nContainer IoTHub Services Total \n\nAverage Startup Time [ms] \n\nFigure 6.34 Average IoT Hub startup time on a Docker container. \n\ncontainer instance. On top of this running instance, we measure the time required to activate all IoT Hub services and to respond to incoming HTTP and CoAP requests. The results show how a container-based approach can be e\ufb03ciently adopted both on cloud or fog infrastructures (according to the target application scenarios) to support e\ufb03cient and highly dynamic creation and management of IoT Hub replicas on top of existing host machines. Unlike a VM-based approach, container-based IoT Hub instances can be instantiated and removed dynamically, depending on the instantaneous load and without a\ufb00ecting the host machine or requiring infrastructure-related e\ufb00orts (such as \ufb01le/template management or con\ufb01guration and activation of new machines). \n\n303 \n\n7 \n\nThe IoT in Practice \n\n7.1 Hardware for the IoT \n\nThe IoT is expected be a worldwide network comprising, by 2020, bil- lions of devices. This gigantic number of devices, pervasively deployed, will be characterized by their heterogeneity in terms of software and, in particular, hardware. In order to provide a general de\ufb01nition for hardware platforms, Figure 7.1 shows an high-level view of the main hardware components in a smart object. The illustrated modules are: \n\n\u2022 Communication module: This gives the smart object its communi- cation capabilities. It is typically either a radio transceiver with an antenna or a wired connection. \u2022 Microcontroller: This gives the smart object its behavior. It is a small microprocessor that runs the software of the smart object. \u2022 Sensors or actuators: These give the smart object a way to sense and interact with the physical world. \u2022 Power source: This is needed because the smart object contains electrical circuits. The most common power source is a battery, but there are other examples as well, such as piezoelectric power sources, that provide power when a physical force is applied, or small solar cells that provide power when light shines on them. \n\nMicrocontrollers have two types of memory: Read-only memory (ROM) and random access memory (RAM). ROM is used to store the program code that encodes the behavior of the device and RAM is used for temporary data the software needs to do its task. For \n\nInternet of Things: Architectures, Protocols and Standards, First Edition. Simone Cirani, Gianluigi Ferrari, Marco Picone, and Luca Veltri. \u00a9 2019 John Wiley & Sons Ltd. Published 2019 by John Wiley & Sons Ltd. \n\n304 7 The IoT in Practice \n\n\n\nRadio Micro-controller \n\nMicro-controller \n\nSensors Actuator \n\nSensors Actuator \n\nPower (a) \n\n(b) Power \n\nWired Communication \n\nFigure 7.1 Smart object hardware, with (a) radio network interface and (b) wired communication interface. \n\nexample, temporary data includes storage for program variables and bu\ufb00er memory for handling radio tra\ufb03c. For constrained devices, the content of the ROM is typically burned into the device when it is manufactured and is not altered after deploy- ment. Modern microcontrollers provide a mechanism for rewriting the ROM, which is useful for in-\ufb01eld updates of software after the devices have been deployed. In addition to memory for storing program code and temporary variables, microcontrollers contain a set of timers and mechanisms for interacting with external devices, such as communication devices, sensors, and actuators. The timers can be freely used by the software running on the microcontroller. External devices are physically connected to its pins. The software communicates with the devices using mechanisms provided by the microcontroller, typically in the form of a serial port or a serial bus. Most microcontrollers provide a so-called universal synchronous/asynchronous receiver/transmitter (USART) for communication with serial ports. Some USARTs can be con\ufb01gured to work as a serial peripheral interface (SPI) bus for communicating with sensors and actuators. A smart object is driven by electronics, and electronics need power. Therefore, every smart object needs a power source (some power \n\n7.1 Hardware for the IoT 305 \n\nTable 7.1 Power sources for smart objects, maximum current draws, and charge they can store. \n\nPower source Typical maximum current (mA) Typical charge (mAh) \n\nCR2032 button cell 20 200 \n\nAA alkaline battery 20 3000 \n\nSolar cell 40 Limitless \n\nRF power 25 Limitless \n\nsource examples are reported in Table 7.1). Today, the most common power source is a battery, but there are several other possibilities for power, such as solar cells, piezoelectricity, radio-transmitted energy, and other forms of power scavenging. Lithium cell batteries are currently the most common. With low-power hardware and proper energy-management software, a smart object can have a lifetime of years on standard lithium cell batteries. Unlike cell phones and laptops, which are human-operated, most smart objects are designed to operate without human control or human supervision. Furthermore, many smart objects are located in di\ufb03cult-to-reach places, and many are embedded in other objects. Therefore, in most cases it is impractical to recharge their batteries. \n\n7.1.1 Classes of Constrained Devices \n\nDespite the overwhelming variety of Internet-connected devices envi- sioned, it is absolutely worthwhile to have a common terminology for di\ufb00erent classes of constrained devices. For this reason, the RFC7228 [229] provides a de\ufb01nition for the main classes and characteristics of IoT smart objects and constrained devices (Table 7.2). These characteristics correspond to distinguishable clusters of com- mercially available chips and design cores for constrained devices. It is expected that the boundaries of these classes will move over time; Moore\u2019s law tends to be less e\ufb00ective in the embedded space than in personal computing devices, so gains made available by increases in transistor count and density are more likely to be invested in reduc- tions in cost and power requirements than in continual increases in computing power. \n\n306 7 The IoT in Practice \n\nTable 7.2 RFC7228 classes of constrained devices. \n\nName Data size (e.g., RAM) Code size (e.g., Flash) \n\nClass 0 (C0) \u226a10 KiB \u226a100 KiB \n\nClass 1 (C1) \u223c10 KiB \u223c100 KiB \n\nClass 2 (C2) \u223c50 KiB \u223c250 KiB \n\nIn more detail, the classes are as follows: \n\nClass 0 devices are very constrained sensor-like motes. They are so severely constrained in memory and processing capabilities that most likely they will not have the resources required to communicate directly with the Internet in a secure manner. These devices will participate in Internet communications with the help of larger devices acting as proxies, gateways, or servers. Class 0 devices generally cannot be secured or managed comprehensively in the traditional sense. They will most likely be precon\ufb01gured (and will be recon\ufb01gured rarely, if at all) with a very small data set. For management purposes, they could answer keep-alive signals and send on/o\ufb00or basic health and status indications. \n\nClass 1 devices are quite constrained in code space and processing capabili- ties, such that they cannot easily talk to other Internet nodes employ- ing a full protocol stack such as HTTP, Transport Layer Security, and related security protocols and XML-based data representations. They are can use a protocol stack speci\ufb01cally designed for constrained nodes (such as CoAP over UDP) and participate in meaningful conversations without the help of a gateway node. They can provide support for the security functions required on a large network. Therefore, they can be integrated as fully developed peers into an IP network, but they need to be parsimonious with state memory, code space, and often power expenditure for protocol and application usage. \n\nClass 2 devices are less constrained and fundamentally capable of supporting most of the same protocol stacks as used on notebooks or servers. They can bene\ufb01t from lightweight and energy-e\ufb03cient protocols and \n\n7.1 Hardware for the IoT 307 \n\nfrom consuming less bandwidth. Using fewer resources for networking leaves more resources available for applications. Thus, using the pro- tocol stacks de\ufb01ned for more constrained devices on Class 2 devices might reduce development costs and increase interoperability. \n\n7.1.2 Hardware Platforms \n\nIn this section we introduce some of the main hardware platforms available on the market, trying to highlight their distinctive features and associated classes. \n\n7.1.2.1 TelosB TelosB1 is a mote from Memsic Technology. It has the same design as the Tmote Sky mote from Sentilla. It is comprises the MSP430 (the MSP430F1611) microcontroller and a CC2420 radio chip. The micro- controller of this mote operates at 415 MHz and has 10 kB internal RAM and a 48 kB programmable \ufb02ash memory. The TelosB was developed by the University of California, Berkeley. It was a new mote design based on experiences with previous mote generations. It was designed with three major goals that would enable experimentation: minimal power consumption, ease of use, and increased software and hardware robustness. The use of the MSP430 in Telos gave it a power pro\ufb01le almost one-tenth that of previous mote platforms. Figure 7.2 is a schematic overview of the mote and shows how the components interact. Table 7.3 gives the detailed hardware pro\ufb01le, with the modules and their associated descriptions. Telos B can be classi\ufb01ed as a Class 0 constrained device. \n\n7.1.2.2 Zolertia Z1 The Zolertia Z12 is a general purpose development board targeting wireless sensor networks and heterogeneous IoT applications. It is equipped with two on-board digital sensors (an accelerometer and a temperature sensor), and uses Phidget Sensors connectors to easily extend connected devices such as sensors and actuators. Figure 7.3 and Table 7.4 are a schematic overview of the Z1, and a summary of the components interactions and available sensors with \n\n1 http://www.memsic.com/userfiles/files/Datasheets/WSN/ telosb:datasheet.pdf. 2 http://zolertia.io/z1. \n\n\n![Image](/src/assets/generated_images/iot_p318_i0.png)\n\n![Image](/src/assets/generated_images/iot_p318_i1.png)\n308 7 The IoT in Practice \n\n\n\nUSB Connector \n\nLight Sensor \n\nTemp./ Humidity Sensor \n\nLogger Flash Serial ID \n\n802.15.4 Radio \n\n6 and 10-Pin Connector \n\nEmbedded Antenna \n\nMSP430 \u03bc controller Analog I/O Digital I/O \n\nFigure 7.2 The hardware schema and the board image of the TelosB mote platform. \n\nTable 7.3 Hardware speci\ufb01cation of the MemSic TelosB mote. \n\nName Description \n\nMCU TI MSP430F1611 \n\nRAM 10 kB \n\nROM 48 kB \n\nSerial communication UART \n\nMain module current draw 1.8 mA (active mode) \n\n5.1 \u03bcA (sleep mode) \n\nIEEE 802.15.4 compliant \n\nRF transceiver 2400\u20132483.5 MHz \n\nRF current draw 23 mA (receive mode) \n\n21 \u03bcA (idle mode) \n\n1 \u03bcA (sleep mode) \n\nBattery 2 \u00d7 AA batteries \n\nSensors Visible light sensor \n\nHumidity sensor \n\nTemperature sensor \n\n\n![Image](/src/assets/generated_images/iot_p319_i0.png)\n7.1 Hardware for the IoT 309 \n\n\nSPI I2C UART1 \n\nUART0 USB \n\nGPIOs \n\nPhidgets Connectors, ADCs, DACs Ceramic \n\n2 antenna options U.FL external \n\nCC2420 \n\n16Mb Flash \n\nMCU \n\n3-axis Accel. Temp. Sensor \n\nExp. Connector 52pin \n\nInterrupts \n\nBSL JTAG \n\nJTAG Header \n\nGND \n\nAnalog Input USBGND \n\nUSB + 5V \n\n3V Phidget \n\n5V Phidget \n\nAnalog Input \n\nGround (0V) Power (+5V) \n\nPower (+3V or +5V) Top View \n\nMicro-USB \n\nDigital Buses Connectivity 12C, SPI, UARTs, USB, Timer Capture/Compare Regs \n\nAnalog I/O 2 \u00d7 3V phidgets | 1 \u00d7 3V+1\u00d75V phidgets ADCs, DACs \n\nRF Connectivity IEEE 802.15.4, 6LowPan, Zigbee 1mW (0 dBm) \n\nDigital I/O GPIOs, Interrupts, Timers, Comparators I/O Figure 3 \u2014 Z1 Expansion Capabilities (54-pin XPCon) \n\nFigure 7.3 The Zolertia Z1 platform with board images and main component schema. \n\n310 7 The IoT in Practice \n\nTable 7.4 Hardware speci\ufb01cation of the Zolertia Z1 platform. \n\nName Description \n\nMCU TI MSP430F2617 \n\nRAM 8 kB \n\nROM 92 kB \n\nDigital communication I2C, SPI and UART \n\nMain module current draw 0.5 mA (active mode) \n\n0.5 \u03bcA (standby mode) \n\nIEEE 802.15.4 compliant \n\nRF transceiver CC2420 2.4 GHz \n\nRF current draw 18.8 mA (receive mode) \n\n426 \u03bcA (idle mode) \n\n20 \u03bcA (sleep mode) \n\nBattery 2 \u00d7 AA or AAA cells \n\n1 \u00d7 CR2032 coin cell \n\nSensors Low-power digital temperature sensor 3-axis, \u00b12/4/8/16g digital accelerometer, 3 V and 5 V Phidget Sensors connectors \n\ntheir connectors. Like Telos B, Zolertia Z1 can be classi\ufb01ed as a Class 0 constrained device. \n\n7.1.2.3 OpenMote OpenMote3 hardware is composed of three boards: OpenMote- CC2538, OpenBase and OpenBattery. OpenMote-CC2538 is the mote itself and includes the microcontroller and the radio transceiver, as well as other peripherals such as LEDs and buttons. The OpenBase is the board allowing programming and debugging through a UART or USB interface with a computer or via an Ethernet port with the Internet. The OpenBattery is the board that lets OpenMote-CC2538 run autonomously by providing energy to all its subsystems, as well allowing it to interface it with various sensors. \n\n3 http://www.openmote.com. \n\n7.1 Hardware for the IoT 311 \n\nThe OpenMote-CC2538 includes the following hardware: \n\n\u2022 CC2538: This is a system on a chip (SoC) from Texas Instruments, with a 32-bit Cortex-M3 microcontroller and a CC2520-like radio transceiver. The microcontroller runs up to 32 MHz and includes 32 kB of RAM and 512 kB of \ufb02ash memory, and the usual periph- erals (GPIOs, ADC, timers, etc.). The radio operates in the 2.4 GHz band and is fully compatible with the IEEE 802.15.4-2006 standard. \u2022 TPS62730: This is a step-down DC/DC converter from Texas Instruments with two operation modes: regulated and bypass. In bypass mode the TPS62730 directly connects the input voltage from the battery (typically 3 V) to the whole system. In regulated mode the TPS62730 regulates the input voltage down to 2.1 V. The bene\ufb01t of this architecture is in terms of system e\ufb03ciency, since it is an improvement under both low- and high-load conditions; that is, either when the system is sleeping or when the radio is transmitting or receiving. \u2022 ABM8G: This is a 32 MHz crystal from Abracon Corporation, used to clock the microcontroller and the radio transceiver. It is rated at 30 ppm (parts per million) from \u221220\u2218C to +70\u2218C. \u2022 ABS07: This is a 32.768 kHz crystal from Abracon Corporation used to clock the microcontroller\u2019s real time clock. It is rated at 10 ppm from \u221240\u2218C to +85\u2218C. \u2022 LEDs: There are four LEDs (red, green, yellow and orange) from Rohm Semiconductor, used for debugging purposes. \u2022 Buttons: There are two buttons, from Omron. One is used to reset the board and the other is connected to a GPIO line, thus enabling the microcontroller to be woken from sleep modes through an inter- rupt. \u2022 Antenna connector: The antenna connector enables an external antenna to be connected to the board. \u2022 XBee layout: The OpenMote is fully compliant with the XBee form factor, meaning that it can be easily interfaced with a computer using a XBee Explorer dongle. \n\nFigure 7.4 and Table 7.5 give a schematic overview of the Open Mote, the component interactions and the available sensors with connec- tors. The OpenMote runs multiple operating systems, such as Contiki, OpenWSN, FreeRTOS and RiOT. It can be classi\ufb01ed as a Class 0 con- strained devices. \n\n\n![Image](/src/assets/generated_images/iot_p322_i0.png)\n312 7 The IoT in Practice \n\n\nAD4/DIO4 \n\nDIN \n\nVCC \n\nDOUT \n\nAD3/DIO3 \n\nCC2538 OpenBase Module \n\nOpenBattery Module \n\nAD0/DIO0 \n\n23 24 25 26 27 28 \n\n22 21 20 19 18 17 16 15 \n\n1 \n\n56 \n\n57 \n\n1 \n\n1 \n\n1 \n\n2 \n\nVCC \n\n2 3 4 5 6 7 8 9 10 11 12 13 14 \n\n55 54 53 52 51 50 49 48 47 46 45 44 43 XOSC32K_Q1 XOSC32K_Q2 JTAG_TMS JTAG_TCK JTAG_TDO JTAG_TDI \n\nON/BYP DTR/DI8 PWM1 PWM0/RSSI D08 \n\nVDD \n\nAGND \n\nDCOUPL DVDD PB1 PB2 PB3 PB4 PB5 PB6/JTAG_TDI PB7/JTAG_TDO JTAG_TCK JTAG_TMS PD7/XOSC32K_Q2 PD6/XOSC32K_Q1 AVDD_GUARD \n\nR_BIAS DGND_USB USB_P USB_P USB_N DVDD_USB STAT GREEN_LED YELLOW_LED ORANGE_LED RED_LED VCC USER_BUTTON \n\nUSB_SEL \n\nUSB_N DVDD_USB PB0 PC7 PC6 PC5 PC4 \n\nPC3 PC2 PC1 PC0 \n\nVDD \n\nAVDD AVDD AVDD \n\nAVDD \n\nAVDD \n\nXOSC32M_Q2 XOSC32M_Q1 \n\nPD5 DCOUPL2 \n\nPD4 PD3 \n\nRF_N RF_P \n\nPA0/UART_RXD PA1/UART_TXD PA2/SSI_CLK PA3/SSI_SEL PA4/SSI_RXD PA5/SSI_TXD PA6 PA7 VDD PD0 PD1 PD2 RESET_N 2 \n\n2 1 1 \n\n2 \n\n29 30 31 32 33 34 XOSC32M_Q1 \n\nXOSC32M_Q2 35 36 37 38 39 40 41 42 \n\nVCC \n\nVCC \n\nANT2_SEL \n\nANT1_SEL \n\n1 \n\n1 2 \n\n1 \n\n1 \n\nAD2/DIO2 AD1/DIO1 \n\nRESET_N \n\nCTS/DIO7 AD5/DIO5 RTS/AD6/DIO6 ON/SLEEP \n\nR281 \n\n2.2kOhm \n\nGND \n\nGND \n\nGND \n\nGND \n\nGND \n\nGND R421 \n\n56kOhm \n\nCC2538 \n\nC561 \n\nC321 \n\n1uF \n\n1nF \n\n1uF \n\nC281 \n\nFigure 7.4 The OpenMote platform with main hardware schema and core board with battery and OpenBase additional modules. \n\n7.1 Hardware for the IoT 313 \n\nTable 7.5 Hardware speci\ufb01cation of the OpenMote platform. \n\nName Description \n\nMCU TI 32-bit Cortex-M3 \n\nRAM 32 kB \n\nROM 512 kB \n\nDigital communication I2C, and UART \n\nMain module current draw 0.5 mA (active mode) \n\n0.5 \u03bcA (standby mode) \n\nIEEE 802.15.4 compliant \n\nRF transceiver CC2520 2.4 GHz \n\nBattery 2 \u00d7 AAA cells \n\nSensors Temperature/humidity sensor (SHT21) \n\nAcceleration sensor (ADXL346) \n\nLight sensor (MAX44009) \n\n7.1.2.4 Arduino Arduino4 is a computer hardware and software company manufactur- ing microcontroller kits for building digital devices that can sense and interact with the physical world. The board designs adopt a variety of microprocessors and controllers and are equipped with sets of digi- tal and analog input/output pins, which may be interfaced expansion boards (called \u201cshields\u201d) and other external circuits and components. The typical programming language is a dialect of the traditional C and C++, with the possibility of including the many existing libraries from the developer community. The Arduino project started in Italy in 2005 as a program for students at the Ivrea Interaction Design Institute. The aim was to create a low-cost and easy-to-use board for novices and profes- sionals. Arduino boards have been designed to create devices and prototypes that interact with the environment using sensors and actuators and multiple communication paradigms (thanks to the shield expansion-board system). One of the \ufb01rst Arduino boards built for the IoT ecosystem was the Arduino Yun. This is a microcontroller board based on the \n\n4 https://www.arduino.cc. \n\n\n![Image](/src/assets/generated_images/iot_p324_i0.png)\n314 7 The IoT in Practice \n\nATmega32u4 and the Atheros AR9331. The Atheros processor runs a Linux distribution, based on OpenWrt,5 called Linino OS. The board has built-in Ethernet and Wi-Fi communication interfaces, a USB-A port, a micro-SD card slot, 20 digital input/output pins (seven of which can be used as PWM outputs and twelve as analog inputs), a 16 MHz crystal oscillator, a micro USB connection, an ICSP header, and three reset buttons. Figure 7.5 shows the Arduino Yun architecture and how the Linux module of the board can communicate with a traditional Arduino module. This communication capability distinguishes this board from the other boards, o\ufb00ering a powerful networked computer that can be used to create IoT prototypes in several application scenarios. \n\nATmega 32u4 \n\nLinino AR 9331 \n\nUSB Prog. \n\nWiFi Interface ETH Interface \n\nUSB HOST \n\nSD CARD \n\nBRIDGE \n\nARDUINO ENVIRONMENT LINUX ENVIRONMENT \n\nRx \n\nRx Tx \n\nTx \n\n\nFigure 7.5 Classical and Yun versions of the Arduino platform with a detailed representation of the Yun hardware architecture and main components. \n\n5 https://openwrt.org/. \n\n\n![Image](/src/assets/generated_images/iot_p325_i0.png)\n\n![Image](/src/assets/generated_images/iot_p325_i1.png)\n7.1 Hardware for the IoT 315 \n\n\nWiFi AR9331 Linux \n\nMicro SD \n\nATmega 32U4 \n\nUSB Host \n\nProg. Micro USB \n\nEthernet \n\n\nFigure 7.5 (Continued) \n\nTables 7.6 and 7.7 report the detailed hardware pro\ufb01le of Arduino Yun modules with their associated components and descriptions. The Yun board can be classi\ufb01ed as a Class 2 constrained device. \n\n7.1.2.5 Intel Galileo Intel Galileo6 was the \ufb01rst Arduino-certi\ufb01ed development board based on Intel\u2019s x86 architecture. It was designed for makers and education/ \n\n6 https://software.intel.com/en-us/iot/hardware/galileo. \n\n316 7 The IoT in Practice \n\nTable 7.6 Hardware speci\ufb01cation of the Arduino Yun AVR Arduino microcontroller. \n\nName Description \n\nMicrocontroller ATmega32U4 \n\nOperating Voltage 5 V \n\nInput Voltage 5 V \n\nDigital I/O pins 20 \n\nPWM Output 7 \n\nAnalog I/O pins 12 \n\nFlash memory 32 kB (4 kB used by the bootloader) \n\nSRAM 2.5 kB \n\nEEPROM 1 kB \n\nClock speed 16 MHz \n\nTable 7.7 Hardware speci\ufb01cation of the Arduino Yun Arduino microprocessor. \n\nName Description \n\nProcessor Atheros AR9331 \n\nArchitecture MIPS \n\nOperating voltage 3.3 V \n\nEthernet IEEE 802.3 (10/100Mbit/s) \n\nWi-Fi IEEE 802.11b/g/n (2.4 GHz) \n\nUSB type 2.0 Host \n\nFlash memory 16 MB \n\nRAM 64 MB DDR2 \n\nSRAM 2.5 kB \n\nEEPROM 1 kB \n\nClock speed 400 MHz \n\n\n![Image](/src/assets/generated_images/iot_p327_i0.png)\n\n![Image](/src/assets/generated_images/iot_p327_i1.png)\n7.1 Hardware for the IoT 317 \n\nacademic communities. The board combines Intel technology with support for Arduino expansion shields and the related software and libraries. The board runs an open-source Linux operating system with the Arduino software libraries, enabling re-use of existing software. Intel Galileo hosts a Linux operating system. Intel Galileo is equipped with the Intel Quark SoC X1000, the \ufb01rst product from the Intel Quark technology family of low-power, small-core products. The Galileo board comes with several comput- ing industry standard I/O interfaces, including ACPI, PCI Express, 10/100 Mbit Ethernet, Micro SD or SDHD, USB 2.0 and EHCI/OHCI USB host ports, high-speed UART, RS-232 serial port, programmable 8 MB NOR \ufb02ash, and a JTAG port for debugging. Figure 7.6 and Table 7.8 give a schematic overview of the Intel Galileo boards, component interactions and available communication modules, for both \ufb01rst- and second-generation devices. Galileo can be classi\ufb01ed as a Class 2 constrained devices. \n\nMUX \n\nMUX \n\nGPIO PWM \n\nGPIO PWM \n\nADC FLASH \n\nMUX \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICSP \n\nIOREF Jumper selects 3.3V or SVShield Operation \n\nAll GPIO PWM provided by a single I2 C+ 10 Expander \n\n1 \n\n2 3 \n\n4 \n\n5 6 \n\n7 \n\n8 \n\n6 \n\n5 \n\n4 \n\n3 \n\n2 \n\n1 \n\nVIN \n\nAO \n\nA1 \n\nA2 \n\nA3 \n\nA4 \n\nA5 \n\nGND \n\nGND \n\n5V \n\n3.3V 3.3V \n\n5V 5V Brick PowerSupply Three-Output Voltage Regulator VTT Regulator FETs for S0/S3 states \n\n~1011 GND RESET 1013 1012 1 3 5 6 4 2 \n\n5V \n\nJTAG \n\nSPI1 \n\nGPIO LED \n\n4 \n\n32.768 KHz GPIO (INT0/1) \n\n10 9 8 7 6 5 4 3 2 \n\n8 7 6 5 4 3 2 1 RX TX 102 ~103 \n\n~105 104 \n\n~106 107 \n\n1 108 ~109 ~1010 ~1011 1012 1013 GND AREF SDA SCL \n\n4 \n\n2 \n\n2 2 UART 0 \n\n2 \n\n25MHz \n\nClocks Out \n\nPCle* \n\n2 6 \n\n2 \n\n4 \n\n4 \n\nDEDIPROG \n\nSPI \n\nLSPI \n\n12C+ \n\nCOIN HDR \n\nDDR3 X8 DDR3 X8 256 MB \n\nVIN \n\nMUX \n\nMUX MUX \n\nDIGITAL (PWM~) \n\nMUX \n\nGPIO PWM \n\nGPIO PWM GPIO PWM \n\nADC FLASH \n\nMUX \n\nRESET \n\nIOREF \n\nIntel6 Galileo Board Fab D October 2013 \n\nPOWER ANALOG IN \n\nRMI [0] \n\nMini-PCle* \n\nMicro SD Connector \n\nHost USB 0 \n\nSDIO \n\nHost USB 1 \n\nClient USB \n\nPHY \n\n3 pin Jack (Not Audio) \n\n3.3V <-> 5V Level Translation provided on board between allSoCIOs and Shield Headers \n\nUART 1 \n\nHost USB Client USB \n\n10/100 Ethernet \n\nRS-232 XCVR \n\n\nProcessor \n\n\nFigure 7.6 First and second generations of the Intel Galileo platform with board schemas and hardware architecture of main components. \n\n\n![Image](/src/assets/generated_images/iot_p328_i0.png)\n318 7 The IoT in Practice \n\n\nGen 1 \n\nGen 2 \n\nFigure 7.6 (Continued) \n\n7.1.2.6 Raspberry Pi The Raspberry Pi7 is a series of single-board computers created in the United Kingdom by the Raspberry Pi Foundation. The original aim of \n\n7 https://www.raspberrypi.org/. \n\n7.1 Hardware for the IoT 319 \n\nTable 7.8 Hardware speci\ufb01cation of the Intel Galileo board. \n\nName Description \n\nMCU SoC X Intel Qua k X1000 \n\nRAM 256 MB \n\nMemory SDCard (MBytes) \n\nSerial communication I2C and UART \n\nMain module current draw 0.5 mA (active mode) \n\n0.5 \u03bcA (standby mode) \n\nNetwork adapter IEEE 802.3 10/100 (Ethernet) \n\nBattery \u2013 \n\nSensors \u2013 \n\nthe founders was to encourage the teaching of basic computer science in schools and developing countries. Step by step, their boards signif- icantly changed the way manufacturers and developers thought about and created new projects in many application scenarios. For example, the original model became very popular and started spreading outside of its initial target market for uses such as robotics. Figure 7.7 shows three Raspberry Pi boards with their available components and hardware pro\ufb01les. The Broadcom BCM2835 SoC was used on the \ufb01rst generation and was inspired by the chip used in \ufb01rst-generation smartphones (its CPU is an older ARMv6 architec- ture). It includes a 700 MHz ARM1176JZF-S processor, VideoCore IV GPU, and RAM. It has a level 1 (L1) cache of 16 kB and a level 2 (L2) cache of 128 kB. The level 2 cache is used primarily by the GPU. The SoC is stacked underneath the RAM chip, so only its edge is visible. The Raspberry Pi 2 uses a Broadcom BCM2836 SoC with a 900 MHz 32-bit quad-core ARM Cortex-A7 processor (as do many current smartphones), with 256 kB shared L2 cache. The Raspberry Pi 3 uses a Broadcom BCM2837 SoC with a 1.2 GHz 64-bit quad-core ARM Cortex-A53 processor, with 512 kB shared L2 cache. The Model A, A+ and Pi Zero are shipped without Ethernet modules and are commonly connected to a network using external adapters for Ethernet or Wi-Fi. Models B and B+ have the Ethernet port that is provided by a built-in USB Ethernet adapter using the \n\n\n![Image](/src/assets/generated_images/iot_p330_i0.png)\n\n![Image](/src/assets/generated_images/iot_p330_i1.png)\n\n![Image](/src/assets/generated_images/iot_p330_i2.png)\n320 7 The IoT in Practice \n\n\n\n\nFigure 7.7 Main Raspberry Pi boards and revisions. \n\n7.2 Software for the IoT 321 \n\nSMSC LAN9514 chip. The Raspberry Pi 3 and Pi Zero W (wireless) provide a 2.4 GHz Wi-Fi 802.11n (150 Mbit/s) and Bluetooth 4.1 (24 Mbit/s) connectivity module based on a Broadcom BCM43438 chip. The Raspberry Pi 3 is also equipped with a 10/100 Ethernet port. The Raspberry Pi can be also used with USB storage, USB-to-MIDI converters, and virtually any other device/component with USB capa- bilities. Other external devices, sensors/actuators and peripherals can be attached through a set of pins and connectors available on the board\u2019s surface. The Raspberry Pi board family can run multiple operating systems, such as Raspbian, Fedora, Ubuntu MATE, Kali Linux, Ubuntu Core, Windows 10 IoT Core, RISC OS, Slackware, Debian, Arch Linux ARM, and Android Things. This combination of high-pro\ufb01le hardware, soft- ware and operating systems makes these boards to represent powerful and complex nodes in heterogenous IoT applications. They can e\ufb03- ciently work as IoT Hubs, gateways and data collectors using heteroge- nous protocols and running multiple services at the same time. All the Raspberry Pi boards can be classi\ufb01ed as Class 2 constrained devices. \n\n7.2 Software for the IoT \n\nIn this section, an overview of the main operating systems for the IoT is presented. The Contiki operating system is particularly important, and a more detailed description is therefore provided in Section 7.2.6. \n\n7.2.1 OpenWSN \n\nThe OpenWSN8 project is an open-source implementation of a fully standards-based protocol stack for IoT networks. It was based on the new IEEE802.15.4e time-slotted channel-hopping standard. IEEE802.15.4e, coupled with IoT standards such as 6LoWPAN, RPL and CoAP, enables ultra-low-power and highly reliable mesh networks that are fully integrated into the Internet. OpenWSN has been ported to numerous commercial available plat- forms from older 16-bit micro-controllers to state-of-the-art 32-bit \n\n8 https://openwsn.atlassian.net/wiki/pages/viewpage.action? pageId=688187. \n\n\n![Image](/src/assets/generated_images/iot_p332_i0.png)\n322 7 The IoT in Practice \n\n\nGINA OpenMote-CC2538 UDP TCP \n\nRPL \n\n6LoWPAN \n\n6top (6TiSCH) \n\nIEEE802.15.4e TSCH \n\nPlatforms \n\nIEEE802.15.4 (PHY) \n\nHTTP \n\nApplications \n\nCoAP \n\nZ1 TelosB \n\nWSN430v13b \n\nWSN430v14 \n\nOpenMoteSTM SAM R21 loT-LAB_M3 AgileFox \n\n10% BSP 90% hardware independent \n\nFigure 7.8 OpenWSN protocol stack, highlighting hardware-independent modules and supported hardware platforms. \n\nCortex-M architectures. The OpenWSN project o\ufb00ers a free and open-source implementation of a protocol stack and the surrounding debugging and integration tools, thereby contributing to the overall goal of promoting the use of low-power wireless mesh networks. Figure 7.8 shows the OpenWSN protocol layers and software libraries, which are hardware independent, and a set of supported hardware platforms, on which it can be installed and used. \n\n7.2.2 TinyOS \n\nTinyOS9 is a free, open-source, BSD-licensed OS designed for low- power embedded distributed wireless devices used in sensor net- works. It has designed to support the intensive concurrent operations required by networked sensors, with minimal hardware require- ments. TinyOS was developed by University of California, Berkeley, Intel Research, and Crossbow Technology. It is written in the nesC (Network Embedded Systems C) programming language, which is a version of C optimized to support components and concurrency. It is also component-based, supporting event-driven programming of applications for TinyOS. \n\n9 www.tinyos.net/. \n\n7.2 Software for the IoT 323 \n\n7.2.3 FreeRTOS \n\nFreeRTOS10 is a real-time operating system kernel for embed- ded devices designed to be small and simple. It been ported to 35 micro-controllers and it is distributed under the GPL with an optional exception. The exception permits users\u2019 proprietary code to remain closed source while maintaining the kernel itself as open source, thereby facilitating the use of FreeRTOS in proprietary applications. In order to make the code readable, easy to port, and maintainable, it is written mostly in C, (but some assembly functions have been included to support architecture-speci\ufb01c scheduler routines). It pro- vides methods for multiple threads or tasks, mutexes, semaphores and software timers. \n\n7.2.4 TI-RTOS \n\nTI-RTOS11 is a real-time operating system that enables faster development by eliminating the need for developers to write and maintain system software such as schedulers, protocol stacks, power-management frameworks and drivers. It is provided with full C source code and requires no up-front or runtime license fees. TI-RTOS scales from a low-footprint, real-time preemptive multitasking kernel to a complete RTOS with additional middleware components includ- ing a power manager, TCP/IP and USB stacks, a FAT \ufb01le system, and device drivers, allowing developers to focus on di\ufb00erentiating their applications. Figure 7.9 shows the main software components of the TI-RTOS operating system. In particular, it is based on a core layer with a real-time kernel, connectivity support and power management. On top of that, a set of platform APIs allow the developer to build custom applications. The OS provides a large set of ready-to-use libraries based on TCP/UDP/IP networking, standard BSD socket interface and main application layer protocols such as HTTP, TFTP, Telnet, DNS, and DHCP. \n\n10 www.freertos.org/. 11 http://www.ti.com/tool/ti-rtos. \n\n\n![Image](/src/assets/generated_images/iot_p334_i0.png)\n\n![Image](/src/assets/generated_images/iot_p334_i1.png)\n324 7 The IoT in Practice \n\n\nReal-Time Kernel Power Manager \n\nDrivers \n\nUser Application Tasks \n\nOptional Other Middleware USB, File Systems \n\nConnectivity Wi-Fi\u00ae, Bluetooth\u00ae Smart, ZigBee\u00ae, Cellular (via PPP), TCP/IP \n\nIoT SoC Sensors \n\nAPIs IP \n\nARP NAT \n\nI/F Manager \n\nRoute Manager \n\nEthernet I/F \n\nHardware Adaptation Layer \n\nEthernet Packet Driver \n\nSerial Port Driver \n\nTimer Driver \n\nHardware \n\nUser LED Driver \n\nTCP UDP ICMP \n\nStandard BSD Sockets Interface \n\nIGMP \n\nS N T P \n\nH T T P \n\nT F T P \n\nT E L N E T \n\nD N S \n\nD H C P \n\nPlatform \n\nFigure 7.9 Schematic overview of the TI-RTOS operating system with main modules and software components. \n\n\nEmbedded IP Stack Applications System Libraries Network Stack \n\nCoAP UDP RPL* IPv6 6LoWPAN IEEE 802.15.4 MAC Radio Transmission \n\n* Partially Supported \n\nHTTP TCP UDP \n\nICMP \n\nIEEE 802.3 IEEE 802.11 IEEE 802.3 IEEE 802.11 \n\nIPv6 \n\nOSLR or OSPF* Kernel \n\nHardware Abstraction \n\nHardware Platform \n\nICMP \n\nTraditional IP Stack Content-Centric Stack \n\nApplications \n\nCCN Lite \n\nFigure 7.10 Overview of networking architecture for the RIOT operating system. \n\n7.2.5 RIOT \n\nRIOT12 is an open-source microkernel operating system for the IoT, licensed as LGPL. It allows C and C++ application programming, and provides both full multi-threading and real-time capabilities (in contrast to other operating systems with similar memory footprints, such as TinyOS or Contiki). RIOT runs on 8-bit (e.g., AVR Atmega), 16-bit (e.g., TI MSP430) and 32-bit hardware (e.g., ARM Cortex). A native port also enables RIOT to run as a Linux or MacOS process, enabling the use of standard development and debugging tools such as GNU Compiler Collection, GNU Debugger, Valgrind, Wireshark, an so on. RIOT is partly POSIX-compliant and provides multiple network stacks, including IPv6, 6LoWPAN and standard protocols such as RPL, UDP, TCP, and CoAP (see Figure 7.10). \n\n12 www.riot-os.org/. \n\n7.2 Software for the IoT 325 \n\n7.2.6 Contiki OS \n\nContiki is an operating system for networked, memory-constrained systems, targeting low-power wireless IoT devices. Its main charac- teristics are: \n\n\u2022 It is open source and in continuous development. Even if it is less well documented and less well maintained than commercial operating systems, it allows developers not only to work on custom applications but also to modify core OS functionalities such as the TCP/IP stack and the routing protocol. \u2022 It provides a full TCP/uIPv6 stack using 6LoWPAN [230] for header compression, and creates LR-WPAN routes with RPL [39], the IPv6 routing protocol for low-power and lossy networks \n\nContiki was created by Adam Dunkels in 2002 and has been further developed by a worldwide team of developers from Texas Instruments, Atmel, Cisco, ENEA, ETH Zurich, Redwire, RWTH Aachen Univer- sity, Oxford University, SAP, Sensinode, the Swedish Institute of Com- puter Science, ST Microelectronics, Zolertia, and many others. Contiki is designed to run on classes of hardware devices that are severely constrained in terms of memory, power, processing power, and communication bandwidth. For example, in terms of memory, despite providing multitasking and a built-in TCP/IP stack, Contiki only needs about 10 kB of RAM and 30 kB of ROM. A typical Contiki system has memory of the order of kilobytes, a power budget of the order of milliwatts, processing speed measured in megahertz, and communication bandwidth of the order of hundreds of kilobits/sec- ond. This class of systems includes various types of embedded systems as well as a number of old 8-bit computers. A brief description of the core features of Contiki will be provided, highlighting why they are of particular interest for building complex IoT applications. \n\n7.2.6.1 Networking Contiki provides three network mechanisms: \n\n\u2022 the uIP13 TCP/IP stack, which provides IPv4 networking; \u2022 the uIPv6 stack, which provides IPv6 networking; \u2022 the Rime stack, which is a set of custom lightweight networking pro- tocols designed speci\ufb01cally for low-power wireless networks. \n\n13 https://github.com/adamdunkels/uip. \n\n326 7 The IoT in Practice \n\nThe IPv6 stack was contributed by Cisco and was, at the time of release, the smallest IPv6 stack to receive IPv6-ready certi\ufb01cation. The IPv6 stack also contains the RPL routing protocol and the 6LoWPAN header compression and adaptation layer. The Rime stack is an alternative network stack that is intended to be used when the overhead of the IPv4 or IPv6 stacks is prohibitive. The Rime stack provides a set of communication primitives for low- power wireless systems. The default primitives are single-hop unicast, single-hop broadcast, multi-hop unicast, network \ufb02ooding, and address-free data collection. The primitives can be used on their own or combined to form more complex protocols and mechanisms. \n\n7.2.6.2 Low-power Operation Many Contiki systems are severely power-constrained. Battery oper- ated wireless sensors may need to provide years of unattended operation, often with no way to recharge or replace batteries. Contiki provides a set of mechanisms for reducing the power consumption of the system on which it runs. The default mechanism for attaining low-power operation of the radio is called ContikiMAC. With Con- tikiMAC, nodes can be running in low-power mode and still be able to receive and relay radio messages. \n\n7.2.6.3 Simulation The Contiki system includes a network simulator called Cooja (Figure 7.11). Cooja simulates networks of Contiki nodes. The nodes may belong to one of three classes: \n\n\u2022 emulated nodes, where the entire hardware of each node is emu- lated; \u2022 Cooja nodes, where the Contiki code for the node is compiled and executed on the simulation host; \u2022 Java nodes, where the behavior of the node must be reimplemented as a Java class. \n\nA single Cooja simulation may contain a mixture of nodes from any of the three classes. Emulated nodes can also be used, so as to include non-Contiki nodes in a simulated network. In Contiki 2.6, platforms with TI MSP430 and Atmel AVR microcon- trollers can be emulated. Cooja can be very useful because of its emu- lative functions, which help developers in testing applications. This speeds up the development process: without a simulator the developer would have to upload and test every new version of \ufb01rmware on real \n\n\n![Image](/src/assets/generated_images/iot_p337_i0.png)\n7.2 Software for the IoT 327 \n\n\nFigure 7.11 Screenshot of Cooja Contiki network simulation for an Ubuntu system with Contiki 2.6 running on 41 nodes forming an IPv6/RPL/6lowpan network. \n\nhardware. This would be a long process, because most motes can only be \ufb02ashed through a (slow) serial port. \n\n7.2.6.4 Programming Model To run e\ufb03ciently on memory-constrained systems, the Contiki programming model is based on protothreads. A protothread is a memory-e\ufb03cient programming abstraction that shares features of both multi-threading and event-driven programming to attain a low memory overhead. The kernel invokes the protothread of a process in response to an internal or external event. Examples of internal events are timers that \ufb01re, or messages being posted from other processes. Examples of external events are sensors that trigger, or incoming packets from a radio neighbor. Protothreads are cooperatively scheduled. This means that a Con- tiki process must always explicitly yield control back to the kernel at regular intervals. Contiki processes may use a special protothread con- struct to avoid waiting for events while yielding control to the kernel between each event invocation. \n\n328 7 The IoT in Practice \n\n7.2.6.5 Features Contiki supports per-process optional preemptive multi-threading, inter-process communication using message-passing events, and an optional GUI subsystem with either direct graphic support for locally connected terminals or networked virtual display with virtual network computing or over Telnet. A full installation of Contiki includes the following features: \n\n\u2022 multitasking kernel \u2022 optional per-application pre-emptive multithreading \u2022 protothreads \u2022 TCP/IP networking, including IPv6 \u2022 windowing system and GUI \u2022 networked remote display using virtual network computing \u2022 web browser (claimed to be the world\u2019s smallest). \n\n7.3 Vision and Architecture of a Testbed for the Web of Things \n\nWith the aim to foster the development and di\ufb00usion of the IoT, applications are starting to be built around the well-known web model, leading to the advent of the so-called Web of Things (WoT). The web-based approach has proved to be the driver for the wide di\ufb00usion of the Internet and there is a common feeling that this will apply also to the IoT [231]. WoT applications rely on speci\ufb01c web-oriented application-layer protocols, similar to HTTP, such as the Constrained Application Protocol (CoAP) [7] and, more generally, protocols complying with the REpresentational State Transfer (REST) architectural style. We present here the design and deployment of a heterogeneous and innovative WoT-based application-oriented testbed, called the Web of Things Testbed (WoTT). Its main goal is to allow developers to easily design and evaluate new WoT-oriented services and applications in a real IoT environment and to e\ufb00ectively test human\u2013object interac- tion mechanisms, which will play a fundamental role in broadening the range of IoT users. WoTT is particularly suited for this purpose because its architecture is completely based on standard protocols and mechanisms; it uses no custom or proprietary solutions that would jeopardize the interoperability among nodes. \n\n7.3 Vision and Architecture 329 \n\nThe main goals of the WoTT can be summarized as follows: \n\n\u2022 to hide low-level implementative details; \u2022 to enhance network self-con\ufb01guration, by minimizing human inter- vention; \u2022 to transparently manage, at the same time, multiple protocols and platforms; \u2022 to provide a platform for the design and testing of human-object interaction patterns. \n\nIn order to properly test new WoT-related applications, the WoTT consists of several types of node that di\ufb00er in terms of both computa- tional capabilities and radio access interfaces. Nonetheless, the nodes can be grouped into two main classes: constrained IoT (CIoT) nodes and single board computer (SBC) nodes. CIoT nodes are mainly based on the Contiki OS and correspond to Class 1 devices according to the terminology introduced in RFC7228 [229]. On the other hand, SBC nodes are more powerful nodes, typically running Linux and having multiple network interfaces. These correspond to Class 2 devices. No matter what the actual nodes really are, the standard communication protocols and mechanisms used in the testbed make it able to manage the diversity of nodes seamlessly, thus making it possible to treat each and every node simply as an IP-addressable host. Tables 7.9 and 7.10 show the details of the CIoT and SBC nodes used in the WoTT. \n\nTable 7.9 Constrained IoT nodes in the WoTT. \n\nConstrained IoT nodes \n\n# Node Hardware OS Network interfaces \n\n6 TelosB MCU: TI MSP430F1611 RAM: 10 kB ROM: 48 kB \n\nContiki IEEE 802.15.4 \n\n20 Zolertia Z1 MCU: TI MSP430F2617 RAM: 8 kB ROM: 92 kB \n\nContiki IEEE 802.15.4 \n\n10 OpenMote MCU: ARM Cortex-M3 RAM: 32kB ROM: 512 kB \n\nContiki IEEE 802.15.4 \n\n330 7 The IoT in Practice \n\nTable 7.10 Single board computer nodes in the WoTT. \n\nSBC nodes \n\n# Node Hardware OS Network interfaces \n\n20 Intel Galileo ",
  "createdAt": "2026-02-17"
}